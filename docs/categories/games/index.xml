<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>games on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/categories/games/</link>
    <description>Recent content in games on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/categories/games/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prelim: Strategic Games</title>
      <link>https://adityam.github.io/stochastic-control/games/strategic-games/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/games/strategic-games/</guid>
      <description>So far, we have considered models with a single decision maker. As mentioned in the notes on stochastic optimization, the simplest decision problem is as follows. A decision maker has to choose an action \(a \in \ALPHABET A\). Upon choosing the action \(a\), the decision maker incurs a cost \(c(a)\) (or, equivalently, receives a payoff or a utility \(u(a)\)). What action should the decision maker pick to minimize the cost (or, equivalently, maximize the payoff).</description>
    </item>
    
    <item>
      <title>Theory: Security and zero-sum games</title>
      <link>https://adityam.github.io/stochastic-control/games/zero-sum-games/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/games/zero-sum-games/</guid>
      <description>As we saw, the notion of rationalizability is attractive, but it makes strong assumptions about other players and does not always prescribe a solution. We will now describe a notion of rationality of a player that does not rely on rationality of other players, and even makes the most pessimistic assessment of their potential behavior.
As an example, consider the game shown below.
\(\mathsf{L}\) \(\mathsf{R}\) \(\mathsf{T}\) \(2\) \(1\) \(2\) \(-20\) \(\mathsf{M}\) \(3\) \(0\) \(-10\) \(1\) \(\mathsf{B}\) \(-100\) \(2\) \(3\) \(3\) In this game \(\mathsf{T}\) is an attractive strategy for the row player because it guarantees a payoff of \(2\) and also ensures that the “risky” payoffs of \(-10\) and \(-100\) are avoided.</description>
    </item>
    
    <item>
      <title>Example: Jamming Games</title>
      <link>https://adityam.github.io/stochastic-control/games/jamming/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/games/jamming/</guid>
      <description>Radio frequenccy (RF) jamming is the act of blocking or causing interference to radio or wireless communication by transmitting noise to decrease the signal to noise ration. Jamming of radio transmission originated in World War II and is even used today in military and civilian conflicts. See wikipedia article on jamming for details.
We will consider a simple model of jamming and obtain a using using tools from zero sum games.</description>
    </item>
    
    <item>
      <title>Theory: Nash Equilibrium</title>
      <link>https://adityam.github.io/stochastic-control/games/nash-equilibrium/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/games/nash-equilibrium/</guid>
      <description>So far, we have looked at two solution concepts: (i) rationalizable strategies, which don’t exist for all games, and (ii) optimal or minimax strategies for zero-sum games. Now, we look at the most popular solution concept in games, known as Nash Equilibrium.
Definition A Nash equilibrium (in pure strategies) of a strategic game \(\mathscr{G} = \langle \ALPHABET N, (\ALPHABET A_i)_{i \in \ALPHABET N}, (u_i)_{i \in \ALPHABET N} \rangle\) is a strategy profile \(a^* = (a^*_1, \dots, a^*_n) \in \ALPHABET A\) such that for each player \(i \in \ALPHABET N\), and each strategy \(a_i \in \ALPHABET A_i\), we have \[ u_i(a_i^*, a_{-i}^*) \ge u_i(a_i, a_{-i}^*).</description>
    </item>
    
    <item>
      <title>Theory: Evolutionary stable strategies</title>
      <link>https://adityam.github.io/stochastic-control/games/evolutionary-stable-strategies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/games/evolutionary-stable-strategies/</guid>
      <description>As we saw earlier, one of the interpretations of mixed strategy Nash equlibrium is that it determines the fraction of population playing a certain pure action. Maynard Smith and Price (1973) used this interpretation to propose an evolutionary mechanism via which agents can change their behavior across generations. For a facinating (non-technical) introduction to this area, see Maynard Smith (1982) and Dawkins (1976).
The key idea in what is now called Evolutionary Game theory is that of evolutionary stable strategies, which we discuss here.</description>
    </item>
    
  </channel>
</rss>
