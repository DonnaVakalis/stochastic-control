<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aditya Mahajan">
<meta name="dcterms.date" content="2023-07-17">
<meta name="keywords" content="MDPs, stochastic monotonicity, structural results">
<meta name="description" content="ECES 506 (Stochastic Control and Decision Theory)">

<title>Course Notes - 6&nbsp; Monotonicity of value function and optimal policies</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../mdps/power-delay-tradeoff.html" rel="next">
<link href="../mdps/inventory-management.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      IND: "\\mathbb{I}",
      ONES: "\\mathbb{1}",
      reals: "\\mathbb{R}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      BELLMAN: "\\mathcal{B}",
      MISMATCH: "\\mathcal{D}",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      NORM: ["\\left\\lVert #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert #1 \\right\\rvert", 1],
      GRAD: "\\nabla"
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="citation_title" content="[6]{.chapter-number}&nbsp; [Monotonicity of value function and optimal policies]{.chapter-title}">
<meta name="citation_keywords" content="MDPs,stochastic monotonicity,structural results">
<meta name="citation_author" content="Aditya Mahajan">
<meta name="citation_publication_date" content="2023-07-17">
<meta name="citation_cover_date" content="2023-07-17">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-07-17">
<meta name="citation_fulltext_html_url" content="https://adityam.github.io/stochastic-control//mdps/monotone-mdps.html">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Course notes for ECSE 506 (Stochastic Control and Decision Theorey)">
<meta name="citation_reference" content="citation_title=A new interpretation of information rate;,citation_author=John L. Kelly;,citation_publication_date=1956-07;,citation_cover_date=1956-07;,citation_year=1956;,citation_issue=4;,citation_doi=10.1002/j.1538-7305.1956.tb03809.x;,citation_volume=35;,citation_journal_title=Bell System Technical Journal;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic programming and gambling models;,citation_author=Sheldon M. Ross;,citation_publication_date=1974-09;,citation_cover_date=1974-09;,citation_year=1974;,citation_issue=3;,citation_doi=10.2307/1426236;,citation_volume=6;,citation_journal_title=Advances in Applied Probability;,citation_publisher=Applied Probability Trust;">
<meta name="citation_reference" content="citation_title=Optimal inventory policy;,citation_author=Kenneth J Arrow;,citation_author=Theodore Harris;,citation_author=Jacob Marschak;,citation_publication_date=1952-01;,citation_cover_date=1952-01;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/1907830;,citation_volume=20;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=On the optimal inventory equation;,citation_author=Richard Bellman;,citation_author=Irving Glicksberg;,citation_author=Oliver Gross;,citation_publication_date=1955-10;,citation_cover_date=1955-10;,citation_year=1955;,citation_issue=1;,citation_doi=10.1287/mnsc.2.1.83;,citation_volume=2;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Memoryless strategies in finite-stage dynamic programming;,citation_author=David Blackwell;,citation_publication_date=1964-06;,citation_cover_date=1964-06;,citation_year=1964;,citation_issue=2;,citation_doi=10.1214/aoms/1177703586;,citation_volume=35;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=On the structure of real-time source coders;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=6;,citation_volume=58;,citation_journal_title=Bell System Technical Journal;">
<meta name="citation_reference" content="citation_title=Contributions to the theory of optimal control;,citation_author=Rudolf Emil Kalman;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_volume=5;,citation_journal_title=Boletin de la Sociedad Matematica Mexicana;">
<meta name="citation_reference" content="citation_title=Dynamic programming under uncertainty with a quadratic criterion function;,citation_author=Herbert A Simon;,citation_publication_date=1956-01;,citation_cover_date=1956-01;,citation_year=1956;,citation_issue=1;,citation_doi=10.2307/1905261;,citation_volume=24;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Econometric models and welfare maximization;,citation_author=Henri Theil;,citation_publication_date=1954;,citation_cover_date=1954;,citation_year=1954;,citation_doi=10.1007/978-94-011-2410-2_1;,citation_volume=72;,citation_journal_title=Wirtschaftliches Archiv;">
<meta name="citation_reference" content="citation_title=A note on certainty equivalence in dynamic planning;,citation_author=Henri Theil;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_doi=10.1007/978-94-011-2410-2_3;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Power and delay trade-offs in fading channels;,citation_author=Randall Alexander Berry;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_fulltext_html_url=https://dspace.mit.edu/handle/1721.1/9290;,citation_dissertation_institution=Massachusetts Institute of Technology;">
<meta name="citation_reference" content="citation_title=Communication over fading channels with delay constraints;,citation_author=Randall A Berry;,citation_author=Robert G Gallager;,citation_publication_date=2002-05;,citation_cover_date=2002-05;,citation_year=2002;,citation_issue=5;,citation_doi=10.1109/18.995554;,citation_volume=48;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal power-delay tradeoffs in fading channels—small-delay asymptotics;,citation_author=Randall A Berry;,citation_publication_date=2013-06;,citation_cover_date=2013-06;,citation_year=2013;,citation_issue=6;,citation_doi=10.1109/TIT.2013.2253194;,citation_volume=59;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Evaluating a call option and optimal timing strategy in the stock market;,citation_author=Howard M. Taylor;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_fulltext_html_url=http://www.jstor.org/stable/2628546;,citation_issue=1;,citation_issn=00251909, 15265501;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Optimal stopping and applications;,citation_author=Thomas S. Ferguson;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_fulltext_html_url=http://www.math.ucla.edu/~tom/Stopping/Contents.html;">
<meta name="citation_reference" content="citation_title=Who solved the secretary problem?;,citation_author=Thomas S Ferguson;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_journal_title=Statistical science;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Characterizing the structure of optimal stopping policies;,citation_author=Sechan Oh;,citation_author=Özalp Özer;,citation_publication_date=2016-07;,citation_cover_date=2016-07;,citation_year=2016;,citation_issue=11;,citation_doi=10.1111/poms.12579;,citation_volume=25;,citation_journal_title=Production and Operations Management;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Markov decision processes: Discrete stochastic dynamic programming;,citation_author=Martin L Puterman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_doi=10.1002/9780470316887;">
<meta name="citation_reference" content="citation_title=Optimization over time: Dynamic programming and stochastic control. Vol. 1 and 2;,citation_author=Peter Whittle;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;">
<meta name="citation_reference" content="citation_title=Optimal control: Basics and beyond;,citation_author=Peter Whittle;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Dynamic programming and optimal control;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.athenasc.com/dpbook.html;,citation_volume=I and II;">
<meta name="citation_reference" content="citation_title=Abstract dynamic programming;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://web.mit.edu/dimitrib/www/abstractdp_MIT.html;">
<meta name="citation_reference" content="citation_title=Introduction to stochastic control theory;,citation_author=Karl J. Aström;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;">
<meta name="citation_reference" content="citation_title=Policy invariance under reward transformations: Theory and application to reward shaping;,citation_author=Andrew Y Ng;,citation_author=Daishi Harada;,citation_author=Stuart Russell;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf;,citation_volume=99;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Theoretical and empirical analysis of reward shaping in reinforcement learning;,citation_author=M. Grzes;,citation_author=D. Kudenko;,citation_publication_date=2009-12;,citation_cover_date=2009-12;,citation_year=2009;,citation_doi=10.1109/ICMLA.2009.33;,citation_conference_title=International conference on machine learning and applications;">
<meta name="citation_reference" content="citation_title=Potential based reward shaping tutorial;,citation_author=Sam Devlin;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf;">
<meta name="citation_reference" content="citation_title=How many parts to make at once;,citation_author=Ford W Harris;,citation_publication_date=1913-02;,citation_cover_date=1913-02;,citation_year=1913;,citation_issue=2;,citation_doi=10.1287/opre.38.6.947;,citation_volume=10;,citation_journal_title=The magazine of management;">
<meta name="citation_reference" content="citation_title=The mathematical theory of banking;,citation_author=Francis Y Edgeworth;,citation_publication_date=1888;,citation_cover_date=1888;,citation_year=1888;,citation_fulltext_html_url=https://www.jstor.org/stable/2979084;,citation_issue=1;,citation_volume=51;,citation_journal_title=Journal of the Royal Statistical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Methods of operations research;,citation_author=P. Morse;,citation_author=G. Kimball;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;">
<meta name="citation_reference" content="citation_title=The theory of inventory management;,citation_author=S. Whitin;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;">
<meta name="citation_reference" content="citation_title=Building intuition: Insights from basic operations management models and principles;,citation_author=Evan L. Porteus;,citation_editor=D. Chhajed;,citation_editor=T. J. Lowe;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=10.1007/978-0-387-73699-0;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Selling random wind;,citation_author=Eilyan Bitar;,citation_author=Kameshwar Poolla;,citation_author=Pramod Khargonekar;,citation_author=Ram Rajagopal;,citation_author=Pravin Varaiya;,citation_author=Felix Wu;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 45th hawaii international conference on system sciences;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Fundamental performance limits in cross-layer wireless optimization: Throughput, delay, and energy;,citation_author=Edmund M. Yeh;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_doi=10.1561/0100000014;,citation_issn=1567-2190;,citation_volume=9;,citation_journal_title=Foundations and Trends in Communications and Information Theory;">
<meta name="citation_reference" content="citation_title=Energy-efficient scheduling under delay constraints for wireless networks;,citation_author=Randall Berry;,citation_author=Eytan Modiano;,citation_author=Murtaza Zafer;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_doi=10.2200/S00443ED1V01Y201208CNT011;,citation_volume=5;,citation_journal_title=Synthesis Lectures on Communication Networks;">
<meta name="citation_reference" content="citation_title=Stochastic dominance: Investment decision making under uncertainty;,citation_author=Haim Levy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_doi=10.1007/978-3-319-21708-6;">
<meta name="citation_reference" content="citation_title=Stochastic dominance and expected utility: Survey and analysis;,citation_author=Haim Levy;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_doi=10.1287/mnsc.38.4.555;,citation_volume=38;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Stochastically monotone markov chains;,citation_author=D J Daley;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=4;,citation_doi=10.1007/BF00531852;,citation_volume=10;,citation_journal_title=Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Monotone matrices and monotone markov processes;,citation_author=Julian Keilson;,citation_author=Adri Kester;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=3;,citation_volume=5;,citation_journal_title=Stochastic Processes and their Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=On monotonicity of the optimal transmission policy in cross-layer adaptive m -QAM modulation;,citation_author=N. Ding;,citation_author=P. Sadeghi;,citation_author=R. A. Kennedy;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=9;,citation_doi=10.1109/TCOMM.2016.2590427;,citation_issn=1558-0857;,citation_volume=64;,citation_journal_title=IEEE Transactions on Communications;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity in economics: An elementary survey;,citation_author=Rabah Amir;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=3;,citation_doi=10.2307/20062066;,citation_issn=00384038;,citation_volume=71;,citation_journal_title=Southern Economic Journal;,citation_publisher=Southern Economic Association;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity;,citation_author=Donald M. Topkis;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_isbn=9780691032443;">
<meta name="citation_reference" content="citation_title=Sufficient conditions for the value function and optimal strategy to be even and quasi-convex;,citation_author=J. Chakravorty;,citation_author=A. Mahajan;,citation_publication_date=2018-11;,citation_cover_date=2018-11;,citation_year=2018;,citation_issue=11;,citation_doi=10.1109/TAC.2018.2800796;,citation_issn=2334-3303;,citation_volume=63;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=On the locality of action domination in sequential decision making;,citation_author=Emmanuel Rachelson;,citation_author=Michail G Lagoudakis;,citation_publication_date=2010-01;,citation_cover_date=2010-01;,citation_year=2010;,citation_fulltext_html_url=https://oatao.univ-toulouse.fr/17977/;,citation_conference_title=Proceedings of 11th international symposium on artificial intelligence and mathematics;">
<meta name="citation_reference" content="citation_title=Lipschitz continuity of value functions in Markovian decision processes;,citation_author=Karl Hinderer;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_doi=10.1007/s00186-005-0438-1;,citation_volume=62;,citation_journal_title=Mathematical Methods of Operations Research;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=DeepMDP: Learning continuous latent space models for representation learning;,citation_author=Carles Gelada;,citation_author=Saurabh Kumar;,citation_author=Jacob Buckman;,citation_author=Ofir Nachum;,citation_author=Marc G. Bellemare;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=http://proceedings.mlr.press/v97/gelada19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Convergence of discretization procedures in dynamic programming;,citation_author=Demitri Bertsekas;,citation_publication_date=1975-06;,citation_cover_date=1975-06;,citation_year=1975;,citation_issue=3;,citation_doi=10.1109/TAC.1975.1100984;,citation_issn=2334-3303;,citation_volume=20;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=Towards a unified theory of state abstraction for MDPs;,citation_author=Lihong Li;,citation_author=Thomas J Walsh;,citation_author=Michael L Littman;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://anytime.cs.umass.edu/aimath06/proceedings/P21.pdf;,citation_conference_title=ISAIM;">
<meta name="citation_reference" content="citation_title=Death and discounting;,citation_author=A. Shwartz;,citation_publication_date=2001-04;,citation_cover_date=2001-04;,citation_year=2001;,citation_fulltext_html_url=https://doi.org/10.1109/9.917668;,citation_issue=4;,citation_doi=10.1109/9.917668;,citation_volume=46;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Constrained markov decision processes;,citation_author=Eitan. Altman;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://www-sop.inria.fr/members/Eitan.Altman/TEMP/h.pdf;">
<meta name="citation_reference" content="citation_title=Optimal investment policies for the horse race model&amp;amp;amp;quot;;,citation_author=Thomas S. Ferguson;,citation_author=C. Zachary Gilstein;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=https://www.math.ucla.edu/~tom/papers/unpublished/Zach2.pdf;">
<meta name="citation_reference" content="citation_title=Discovery of the kalman filter as a practical tool for aerospace and;,citation_author=Stanley F. Mcgee;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_fulltext_html_url=https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19860003843.pdf;,citation_technical_report_institution=National Aeronautics; Space Administration;">
<meta name="citation_reference" content="citation_title=Stochastic systems: Estimation identification and adaptive control;,citation_author=P. R. Kumar;,citation_author=Pravin Varaiya;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;">
<meta name="citation_reference" content="citation_title=Stochastic dynamic programming and the control of queueing systems;,citation_author=Linn I. Sennott;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_isbn=0-471-16120-9;">
<meta name="citation_reference" content="citation_title=Discrete-time controlled Markov processes with average cost criterion - a survey;,citation_author=Aristotle Arapostathis;,citation_author=Vivek S. Borkar;,citation_author=Emmaneul Fernandez-Gaucherand;,citation_author=Mrinak K. Ghosh;,citation_author=Steven I. Marcus;,citation_publication_date=1993-03;,citation_cover_date=1993-03;,citation_year=1993;,citation_issue=2;,citation_volume=31;,citation_journal_title=SIAM Journal of Control and Optimization;">
<meta name="citation_reference" content="citation_title=The optimal control of partially observable markov processes over a finite horizon;,citation_author=Richard D. Smallwood;,citation_author=Edward J. Sondik;,citation_publication_date=1973-10;,citation_cover_date=1973-10;,citation_year=1973;,citation_issue=5;,citation_doi=10.1287/opre.21.5.1071;,citation_volume=21;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Convex analytic methods in markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_11;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=A convex analytic approach to markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=1988-08;,citation_cover_date=1988-08;,citation_year=1988;,citation_issue=4;,citation_doi=10.1007/bf00353877;,citation_volume=78;,citation_journal_title=Probability Theory and Related Fields;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Applications of markov decision processes in communication networks;,citation_author=Eitan Altman;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_16;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Water reservoir applications of markov decision processes;,citation_author=Bernard F. Lamond;,citation_author=Abdeslem Boukhtouta;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_17;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Asymptotically efficient adaptive allocation rules;,citation_author=T. L Lai;,citation_author=Herbert Robbins;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_issue=1;,citation_doi=http://dx.doi.org/10.1016/0196-8858(85)90002-8;,citation_issn=0196-8858;,citation_volume=6;,citation_journal_title=Advances in Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Dynamic programming;,citation_author=Richard Bellman;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;">
<meta name="citation_reference" content="citation_title=A dynamic allocation index for the discounted multiarmed bandit problem;,citation_author=J. C. Gittins;,citation_author=D. M. Jones;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_volume=9;,citation_inbook_title=Progress in statistics;">
<meta name="citation_reference" content="citation_title=Bandit processes and dynamic allocation indices;,citation_author=John C Gittins;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=2;,citation_volume=41;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits and the Gittins index;,citation_abstract=A plausible conjecture (C) has the implication that a relationship (12) holds between the maximal expected rewards for a multi-project process and for a one-project process (F and Ï&amp;amp;amp;lt;sub&amp;gt;i&amp;lt;/sub&amp;gt; respectively), if the option of retirement with reward M is available. The validity of this relation and optimality of Gittins’ index rule are verified simultaneously by dynamic programming methods. These results are partially extended to the case of so-called &amp;quot;bandit superprocesses&amp;quot;.;,citation_author=P. Whittle;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=2;,citation_issn=00359246;,citation_volume=42;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=[Royal Statistical Society, Wiley];">
<meta name="citation_reference" content="citation_title=Four proofs of Gittins’ multiarmed bandit theorem;,citation_abstract=We study four proofs that the Gittins index priority rule is optimal for alternative bandit processes. These include Gittins’ original exchange argument, Weber’s prevailing charge argument, Whittle’s Lagrangian dual approach, and Bertsimas and Niño-Mora’s proof based on the achievable region approach and generalized conservation laws. We extend the achievable region proof to infinite countable state spaces, by using infinite dimensional linear programming theory.;,citation_author=Esther Frostig;,citation_author=Gideon Weiss;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=http://dx.doi.org/10.1007/s10479-013-1523-0;,citation_issue=1;,citation_doi=10.1007/s10479-013-1523-0;,citation_issn=1572-9338;,citation_volume=241;,citation_journal_title=Annals of Operations Research;">
<meta name="citation_reference" content="citation_title=The multi-armed bandit problem: Decomposition and computation;,citation_author=Michael N Katehakis;,citation_author=Arthur F Veinott;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=2;,citation_volume=12;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits under general deprecation and commitment;,citation_author=Wesley Cowan;,citation_author=Michael N. Katehakis;,citation_publication_date=2015-10;,citation_cover_date=2015-10;,citation_year=2015;,citation_issue=1;,citation_doi=10.1017/s0269964814000217;,citation_volume=29;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Restless bandits: Activity allocation in a changing world;,citation_author=Peter Whittle;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=A;,citation_volume=25;,citation_journal_title=Journal of applied probability;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=Foundations and applications of sensor management;,citation_author=A. Mahajan;,citation_author=D. Teneketzis;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Two characterizations of optimality in dynamic programming;,citation_author=Ioannis Karatzas;,citation_author=William D. Sudderth;,citation_publication_date=2010-11;,citation_cover_date=2010-11;,citation_year=2010;,citation_issue=3;,citation_doi=10.1007/s00245-009-9093-x;,citation_volume=61;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Structural properties of stochastic dynamic programs;,citation_author=James E. Smith;,citation_author=Kevin F. McCardle;,citation_publication_date=2002-10;,citation_cover_date=2002-10;,citation_year=2002;,citation_issue=5;,citation_doi=10.1287/opre.50.5.796.365;,citation_volume=50;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Monotonicity in multidimensional markov decision processes for the batch dispatch problem;,citation_author=Katerina Papadaki;,citation_author=Warren B. Powell;,citation_publication_date=2007-03;,citation_cover_date=2007-03;,citation_year=2007;,citation_issue=2;,citation_doi=10.1016/j.orl.2006.03.013;,citation_volume=35;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Basic ideas for event-based optimization of markov systems;,citation_author=Xi-Ren Cao;,citation_publication_date=2005-06;,citation_cover_date=2005-06;,citation_year=2005;,citation_issue=2;,citation_doi=10.1007/s10626-004-6211-4;,citation_volume=15;,citation_journal_title=Discrete Event Dynamic Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Monotonicity in markov reward and decision chains: Theory and applications;,citation_author=Ger Koole;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_doi=10.1561/0900000002;,citation_volume=1;,citation_journal_title=Foundations and Trends in Stochastic Systems;,citation_publisher=Now Publishers;">
<meta name="citation_reference" content="citation_title=Stochastic learning and optimization;,citation_author=Xi-Ren Cao;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-0-387-69082-7;">
<meta name="citation_reference" content="citation_title=Optimality and approximation with policy gradient methods in markov decision processes;,citation_abstract=Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution (say with a sufficiently rich policy class); how they cope with approximation error due to using a restricted class of parametric policies; or their finite sample behavior. Such characterizations are important not only to compare these methods to their approximate value function counterparts (where such issues are relatively well understood, at least in the worst case), but also to help with more principled approaches to algorithm design. This work provides provable characterizations of computational, approximation, and sample size issues with regards to policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: 1) &amp;amp;amp;quot;tabular&amp;quot; policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy, and 2) restricted policy classes, which may not contain the optimal policy and where we provide agnostic learning results. One insight of this work is in formalizing the importance how a favorable initial state distribution provides a means to circumvent worst-case exploration issues. Overall, these results place policy gradient methods under a solid theoretical footing, analogous to the global convergence guarantees of iterative value function based algorithms.;,citation_author=Alekh Agarwal;,citation_author=Sham M. Kakade;,citation_author=Jason D. Lee;,citation_author=Gaurav Mahajan;,citation_publication_date=2019-08-01;,citation_cover_date=2019-08-01;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1908.00261v2;">
<meta name="citation_reference" content="citation_title=Analysis of stochastic dual dynamic programming method;,citation_author=Alexander Shapiro;,citation_publication_date=2011-02;,citation_cover_date=2011-02;,citation_year=2011;,citation_issue=1;,citation_doi=10.1016/j.ejor.2010.08.007;,citation_volume=209;,citation_journal_title=European Journal of Operational Research;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Multi-stage stochastic optimization applied to energy planning;,citation_author=M. V. F. Pereira;,citation_author=L. M. V. G. Pinto;,citation_publication_date=1991-05;,citation_cover_date=1991-05;,citation_year=1991;,citation_issue=1-3;,citation_doi=10.1007/bf01582895;,citation_volume=52;,citation_journal_title=Mathematical Programming;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Approximate information state for partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Aditya Mahajan;,citation_publication_date=2019-12;,citation_cover_date=2019-12;,citation_year=2019;,citation_doi=10.1109/cdc40024.2019.9029898;,citation_conference_title=2019 IEEE 58th conference on decision and control (CDC);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Approximate information state for approximate planning and reinforcement learning in partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Amit Sinha;,citation_author=Raihan Seraj;,citation_author=Aditya Mahajan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=http://jmlr.org/papers/v23/20-1165.html;,citation_issue=12;,citation_volume=23;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=On policy independence of conditional expectation;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_volume=28;,citation_journal_title=Information and Control;">
<meta name="citation_reference" content="citation_title=Incremental pruning: A simple, fast, exact method for partially observable Markov decision processes;,citation_author=Anthony Cassandra;,citation_author=Michael L. Littman;,citation_author=Nevin L. Zhang;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_conference_title=Proceedings of the thirteenth conference on uncertainty in artificial intelligence;">
<meta name="citation_reference" content="citation_title=Partially observable Markov decision processes: A geometric technique and analysis;,citation_author=H. Zhang;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Operations Research;">
<meta name="citation_reference" content="citation_title=Algorithms for partially observable markov decision processes;,citation_author=Hsien-Te Cheng;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_dissertation_institution=University of British Columbia;">
<meta name="citation_reference" content="citation_title=Acting optimally in partially observable stochastic domains;,citation_author=Anthony R Cassandra;,citation_author=Leslie Pack Kaelbling;,citation_author=Michael L Littman;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_volume=94;,citation_conference_title=AAAI;">
<meta name="citation_reference" content="citation_title=Planning in stochastic domains: Problem characteristics and approximation;,citation_author=N Zhang;,citation_author=W Liu;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_technical_report_institution=Hong Kong Univeristy of Science; Technology;,citation_technical_report_number=HKUST-CS96-31;">
<meta name="citation_reference" content="citation_title=Sequential tests of statistical hypotheses;,citation_author=A. Wald;,citation_publication_date=1945-06;,citation_cover_date=1945-06;,citation_year=1945;,citation_issue=2;,citation_doi=10.1214/aoms/1177731118;,citation_volume=16;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bayes and minimax solutions of sequential decision problems;,citation_author=K. J. Arrow;,citation_author=D. Blackwell;,citation_author=M. A. Girshick;,citation_publication_date=1949-07;,citation_cover_date=1949-07;,citation_year=1949;,citation_issue=3/4;,citation_doi=10.2307/1905525;,citation_volume=17;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Optimal statistical decisions;,citation_author=Morris DeGroot;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_isbn=047168029X;">
<meta name="citation_reference" content="citation_title=On a test whether two samples are from the same population;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1940-06;,citation_cover_date=1940-06;,citation_year=1940;,citation_issue=2;,citation_doi=10.1214/aoms/1177731909;,citation_volume=11;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Optimum character of the sequential probability ratio test;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1948-09;,citation_cover_date=1948-09;,citation_year=1948;,citation_issue=3;,citation_doi=10.1214/aoms/1177730197;,citation_volume=19;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=A stochastic sensor selection scheme for sequential hypothesis testing with multiple sensors;,citation_author=Cheng-Zong Bai;,citation_author=Vaibhav Katewa;,citation_author=Vijay Gupta;,citation_author=Yih-Fang Huang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=14;,citation_volume=63;,citation_journal_title=IEEE transactions on signal processing;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=A discrete markov chain representation of the sequential probability ratio test;,citation_author=Willam H. Woodall;,citation_author=Marion R. Reynolds;,citation_publication_date=1983-01;,citation_cover_date=1983-01;,citation_year=1983;,citation_issue=1;,citation_doi=10.1080/07474948308836025;,citation_volume=2;,citation_journal_title=Communications in Statistics. Part C: Sequential Analysis;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Mean-field games with a major player;,citation_author=Jean-Michel Lasry;,citation_author=Pierre-Louis Lions;,citation_publication_date=2018-08;,citation_cover_date=2018-08;,citation_year=2018;,citation_issue=8;,citation_doi=10.1016/j.crma.2018.06.001;,citation_volume=356;,citation_journal_title=Comptes Rendus Mathematique;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Remote estimation over a packet-drop channel with markovian state;,citation_author=Jhelum Chakravorty;,citation_author=Aditya Mahajan;,citation_publication_date=2020-05;,citation_cover_date=2020-05;,citation_year=2020;,citation_issue=5;,citation_doi=10.1109/tac.2019.2926160;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal state estimation in the presence of communication costs and packet drops;,citation_author=Gabriel M. Lipsa;,citation_author=Nuno C. Martins;,citation_publication_date=2009-09;,citation_cover_date=2009-09;,citation_year=2009;,citation_doi=10.1109/allerton.2009.5394899;,citation_conference_title=Annual allerton conference on communication, control, and computing (allerton);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Remote state estimation with communication costs for first-order LTI systems;,citation_author=G. M. Lipsa;,citation_author=N. C. Martins;,citation_publication_date=2011-09;,citation_cover_date=2011-09;,citation_year=2011;,citation_issue=9;,citation_doi=10.1109/tac.2011.2139370;,citation_volume=56;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Policy improvement and the newton-raphson algorithm;,citation_author=P. Whittle;,citation_author=N. Komarova;,citation_publication_date=1988-04;,citation_cover_date=1988-04;,citation_year=1988;,citation_issue=2;,citation_doi=10.1017/s0269964800000760;,citation_volume=2;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Optimal adaptive control of linear-quadratic-gaussian systems;,citation_author=P. R. Kumar;,citation_publication_date=1983-03;,citation_cover_date=1983-03;,citation_year=1983;,citation_issue=2;,citation_doi=10.1137/0321009;,citation_volume=21;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=The optimal inventory policy for batch ordering;,citation_author=Arthur F. Veinott;,citation_publication_date=1965-06;,citation_cover_date=1965-06;,citation_year=1965;,citation_issue=3;,citation_doi=10.1287/opre.13.3.424;,citation_volume=13;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Elements of game theory;,citation_author=Ye S. Venttsel;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_fulltext_html_url=https://archive.org/details/ElementsOfGameTheorylittleMathematicsLibrary/;">
<meta name="citation_reference" content="citation_title=Periodic review inventory systems with continuous demand and discrete order sizes;,citation_author=John N. Tsitsiklis;,citation_publication_date=1984-10;,citation_cover_date=1984-10;,citation_year=1984;,citation_issue=10;,citation_doi=10.1287/mnsc.30.10.1250;,citation_volume=30;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Risk sensitivity, A strangely pervasive concept;,citation_author=Peter Whittle;,citation_publication_date=2002-02;,citation_cover_date=2002-02;,citation_year=2002;,citation_issue=1;,citation_doi=10.1017/s1365100502027025;,citation_volume=6;,citation_journal_title=Macroeconomic Dynamics;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Risk-sensitive markov decision processes;,citation_author=Ronald A. Howard;,citation_author=James E. Matheson;,citation_publication_date=1972-03;,citation_cover_date=1972-03;,citation_year=1972;,citation_issue=7;,citation_doi=10.1287/mnsc.18.7.356;,citation_volume=18;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Inequalities: Theory of majorization and its applications;,citation_author=Albert W. Marshall;,citation_author=Ingram Olkin;,citation_author=Barry C. Arnold;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_doi=10.1007/978-0-387-68276-1;">
<meta name="citation_reference" content="citation_title=Risk sensitive control of markov processes in countable state space;,citation_author=Daniel Hernandez-Hernández;,citation_author=Steven I. Marcus;,citation_publication_date=1996-11;,citation_cover_date=1996-11;,citation_year=1996;,citation_issue=3;,citation_doi=10.1016/s0167-6911(96)00051-5;,citation_volume=29;,citation_journal_title=Systems &amp;amp;amp; Control Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Existence of risk-sensitive optimal stationary policies for controlled markov processes;,citation_author=D. Hernández-Hernández;,citation_publication_date=1999-11;,citation_cover_date=1999-11;,citation_year=1999;,citation_issue=3;,citation_doi=10.1007/s002459900126;,citation_volume=40;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Convex risk measures;,citation_author=Hans Föllmer;,citation_author=Alexander Schied;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470061602.eqf15003;,citation_doi=10.1002/9780470061602.eqf15003;,citation_isbn=9780470061602;,citation_inbook_title=Encyclopedia of quantitative finance;">
<meta name="citation_reference" content="citation_title=Updating the inverse of a matrix;,citation_author=William W. Hager;,citation_publication_date=1989-06;,citation_cover_date=1989-06;,citation_year=1989;,citation_issue=2;,citation_doi=10.1137/1031049;,citation_volume=31;,citation_journal_title=SIAM Review;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=A stochastic approximation method;,citation_author=Herbert Robbins;,citation_author=Sutton Monro;,citation_publication_date=1951-09;,citation_cover_date=1951-09;,citation_year=1951;,citation_issue=3;,citation_doi=10.1214/aoms/1177729586;,citation_volume=22;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=The o.d.e. Method for convergence of stochastic approximation and reinforcement learning;,citation_author=V. S. Borkar;,citation_author=S. P. Meyn;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=2;,citation_doi=10.1137/s0363012997331639;,citation_volume=38;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Q-learning;,citation_author=Christopher J. C. H. Watkins;,citation_author=Peter Dayan;,citation_publication_date=1992-05;,citation_cover_date=1992-05;,citation_year=1992;,citation_issue=3-4;,citation_doi=10.1007/bf00992698;,citation_volume=8;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Asynchronous stochastic approximation and q-learning;,citation_author=John N. Tsitsiklis;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993306;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=An analog scheme for fixed point computation. I. theory;,citation_author=V. S. Borkar;,citation_author=K. Soumyanatha;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=4;,citation_doi=10.1109/81.563625;,citation_volume=44;,citation_journal_title=IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the convergence of stochastic iterative dynamic programming algorithms;,citation_author=Tommi Jaakkola;,citation_author=Michael I. Jordan;,citation_author=Satinder P. Singh;,citation_publication_date=1994-11;,citation_cover_date=1994-11;,citation_year=1994;,citation_issue=6;,citation_doi=10.1162/neco.1994.6.6.1185;,citation_volume=6;,citation_journal_title=Neural Computation;,citation_publisher=MIT Press - Journals;">
<meta name="citation_reference" content="citation_title=Dynamic programming and markov processes;,citation_author=Ronald A. Howard;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and martingale inequalities: A survey;,citation_author=Fan Chung;,citation_author=Linyuan Lu;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=https://projecteuclid.org:443/euclid.im/1175266369;,citation_issue=1;,citation_volume=3;,citation_journal_title=Internet Math.;,citation_publisher=A K Peters, Ltd.;">
<meta name="citation_reference" content="citation_title=On the fenchel duality between strong convexity and lipschitz continuous gradient;,citation_abstract=We provide a simple proof for the Fenchel duality between strong convexity and Lipschitz continuous gradient. To this end, we first establish equivalent conditions of convexity for a general function that may not be differentiable. By utilizing these equivalent conditions, we can directly obtain equivalent conditions for strong convexity and Lipschitz continuous gradient. Based on these results, we can easily prove Fenchel duality. Beside this main result, we also identify several conditions that are implied by strong convexity or Lipschitz continuous gradient, but are not necessarily equivalent to them. This means that these conditions are more general than strong convexity or Lipschitz continuous gradient themselves.;,citation_author=Xingyu Zhou;,citation_publication_date=2018-03-17;,citation_cover_date=2018-03-17;,citation_year=2018;,citation_fulltext_html_url=https://arxiv.org/abs/1803.06573v1;">
<meta name="citation_reference" content="citation_title=Optimal control of markov processes with incomplete state information;,citation_author=K. J Åström;,citation_publication_date=1965-02;,citation_cover_date=1965-02;,citation_year=1965;,citation_issue=1;,citation_doi=10.1016/0022-247x(65)90154-x;,citation_volume=10;,citation_journal_title=Journal of Mathematical Analysis and Applications;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Dynamic service migration in mobile edge computing based on Markov decision process;,citation_author=Shiqiang Wang;,citation_author=Rahul Urgaonkar;,citation_author=Murtaza Zafer;,citation_author=Ting He;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_issue=3;,citation_doi=10.1109/tnet.2019.2916577;,citation_volume=27;,citation_journal_title=IEEE/ACM Transactions on Networking;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic service migration and workload scheduling in edge-clouds;,citation_author=Rahul Urgaonkar;,citation_author=Shiqiang Wang;,citation_author=Ting He;,citation_author=Murtaza Zafer;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_doi=10.1016/j.peva.2015.06.013;,citation_volume=91;,citation_journal_title=Performance Evaluation;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=The role and use of the stochastic linear-quadratic-gaussian problem in control system design;,citation_author=M. Athans;,citation_publication_date=1971-12;,citation_cover_date=1971-12;,citation_year=1971;,citation_issue=6;,citation_doi=10.1109/tac.1971.1099818;,citation_volume=16;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Complexity bounds for approximately solving discounted MDPs by value iterations;,citation_author=Eugene A. Feinberg;,citation_author=Gaojin He;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_doi=10.1016/j.orl.2020.07.001;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=How does the value function of a markov decision process depend on the transition probabilities?;,citation_author=Alfred Müller;,citation_publication_date=1997-11;,citation_cover_date=1997-11;,citation_year=1997;,citation_issue=4;,citation_doi=10.1287/moor.22.4.872;,citation_volume=22;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=What is RKHS?;,citation_author=Dino Sejdinovic;,citation_author=Arthur Gretton;,citation_fulltext_html_url=http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf;">
<meta name="citation_reference" content="citation_title=Martingale methods in stochastic control;,citation_author=M. H. A. Davis;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_doi=10.1007/bfb0009377;,citation_inbook_title=Stochastic control theory and stochastic differential systems;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and model selection;,citation_author=Jean Picard;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-3-540-48503-2;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Phillippe Rigollet;,citation_publication_date=2015-07;,citation_cover_date=2015-07;,citation_year=2015;,citation_fulltext_html_url=https://ocw.mit.edu/courses/mathematics/18-s997-high-dimensional-statistics-spring-2015/lecture-notes/;">
<meta name="citation_reference" content="citation_title=Subgaussian random variables: An expository note;,citation_author=Omar Rivasplata;,citation_publication_date=2012-11;,citation_cover_date=2012-11;,citation_year=2012;,citation_fulltext_html_url=http://stat.cmu.edu/~arinaldo/36788/subgaussians.pdf;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Martin J. Wainwright;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_doi=10.1017/9781108627771;">
<meta name="citation_reference" content="citation_title=Selecting computations: Theory and applications;,citation_author=Nicholas Hay;,citation_author=S. Russell;,citation_author=David Tolpin;,citation_author=S. E. Shimony;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=http://www.auai.org/uai2012/papers/123.pdf;,citation_conference_title=UAI;">
<meta name="citation_reference" content="citation_title=On linear control theory;,citation_author=D. Peter Joseph;,citation_author=T. Julius Tou;,citation_publication_date=1961;,citation_cover_date=1961;,citation_year=1961;,citation_issue=4;,citation_doi=10.1109/tai.1961.6371743;,citation_volume=80;,citation_journal_title=Transactions of the American Institute of Electrical Engineers, Part II: Applications and Industry;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the separation theorem of stochastic control;,citation_author=W. M. Wonham;,citation_publication_date=1968-05;,citation_cover_date=1968-05;,citation_year=1968;,citation_issue=2;,citation_doi=10.1137/0306023;,citation_volume=6;,citation_journal_title=SIAM Journal on Control;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Some comments on a theorem of Hardy and Littlewood;,citation_author=R. Sznajder;,citation_author=J. A. Filar;,citation_publication_date=1992-10;,citation_cover_date=1992-10;,citation_year=1992;,citation_issue=1;,citation_doi=10.1007/bf00939913;,citation_volume=75;,citation_journal_title=Journal of Optimization Theory and Applications;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Notes on the theory of series (XVI): Two Tauberian theorems;,citation_author=G. H. Hardy;,citation_author=J. E. Littlewood;,citation_publication_date=1931-10;,citation_cover_date=1931-10;,citation_year=1931;,citation_issue=4;,citation_doi=10.1112/jlms/s1-6.4.281;,citation_volume=s1-6;,citation_journal_title=Journal of the London Mathematical Society;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=The Hardy-Littlewood theorems;,citation_author=Jacob Korevaar;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_doi=10.1007/978-3-662-10225-1_1;,citation_inbook_title=Tauberian theory: A century of developments;">
<meta name="citation_reference" content="citation_title=Monotone optimal policies for markov decision processes;,citation_author=Richard F. Serfozo;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_doi=10.1007/bfb0120752;,citation_inbook_title=Mathematical programming studies;">
<meta name="citation_reference" content="citation_title=Cross-layer communication over fading channels with adaptive decision feedback;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_author=Edmund Yeh;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=International symposium on modeling and optimization in mobile, ad hoc, and wireless networks (WiOPT);">
<meta name="citation_reference" content="citation_title=Counterexamples on the monotonicity of delay optimal strategies for energy harvesting transmitters;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.1109/lwc.2020.2981066;,citation_journal_title=IEEE Wireless Communications Letters;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Q-learning for MDPs with general spaces: Convergence and near optimality via quantization under weak continuity;,citation_abstract=Reinforcement learning algorithms often require finiteness of state and action spaces in Markov decision processes (MDPs) and various efforts have been made in the literature towards the applicability of such algorithms for continuous state and action spaces. In this paper, we show that under very mild regularity conditions (in particular, involving only weak continuity of the transition kernel of an MDP), Q-learning for standard Borel MDPs via quantization of states and actions converge to a limit, and furthermore this limit satisfies an optimality equation which leads to near optimality with either explicit performance bounds or which are guaranteed to be asymptotically optimal. Our approach builds on (i) viewing quantization as a measurement kernel and thus a quantized MDP as a POMDP, (ii) utilizing near optimality and convergence results of Q-learning for POMDPs, and (iii) finally, near-optimality of finite state model approximations for MDPs with weakly continuous kernels which we show to correspond to the fixed point of the constructed POMDP. Thus, our paper presents a very general convergence and approximation result for the applicability of Q-learning for continuous MDPs.;,citation_author=Ali Devran Kara;,citation_author=Naci Saldi;,citation_author=Serdar Yüksel;,citation_publication_date=2021-11-12;,citation_cover_date=2021-11-12;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2111.06781v1;">
<meta name="citation_reference" content="citation_title=Bounds and transformations for discounted finite markov decision chains;,citation_author=Evan L. Porteus;,citation_publication_date=1975-08;,citation_cover_date=1975-08;,citation_year=1975;,citation_issue=4;,citation_doi=10.1287/opre.23.4.761;,citation_volume=23;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Calculus on MDPs: Potential shaping as a gradient;,citation_abstract=In reinforcement learning, different reward functions can be equivalent in terms of the optimal policies they induce. A particularly well-known and important example is potential shaping, a class of functions that can be added to any reward function without changing the optimal policy set under arbitrary transition dynamics. Potential shaping is conceptually similar to potentials, conservative vector fields and gauge transformations in math and physics, but this connection has not previously been formally explored. We develop a formalism for discrete calculus on graphs that abstract a Markov Decision Process, and show how potential shaping can be formally interpreted as a gradient within this framework. This allows us to strengthen results from Ng et al. (1999) describing conditions under which potential shaping is the only additive reward transformation to always preserve optimal policies. As an additional application of our formalism, we define a rule for picking a single unique reward function from each potential shaping equivalence class.;,citation_author=Erik Jenner;,citation_author=Herke Hoof;,citation_author=Adam Gleave;,citation_publication_date=2022-08-20;,citation_cover_date=2022-08-20;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2208.09570v1;">
<meta name="citation_reference" content="citation_title=Dynamic potential-based reward shaping;,citation_abstract=Potential-based reward shaping can significantly improve the time needed to learn an optimal policy and, in multi-agent systems, the performance of the final joint-policy. It has been proven to not alter the optimal policy of an agent learning alone or the Nash equilibria of multiple agents learning together.However, a limitation of existing proofs is the assumption that the potential of a state does not change dynamically during the learning. This assumption often is broken, especially if the reward-shaping function is generated automatically.In this paper we prove and demonstrate a method of extending potential-based reward shaping to allow dynamic shaping and maintain the guarantees of policy invariance in the single-agent case and consistent Nash equilibria in the multi-agent case.;,citation_author=Sam Devlin;,citation_author=Daniel Kudenko;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_isbn=0981738117;,citation_conference_title=Proceedings of the 11th international conference on autonomous agents and multiagent systems;,citation_conference=International Foundation for Autonomous Agents; Multiagent Systems;,citation_series_title=AAMAS ’12;">
<meta name="citation_reference" content="citation_title=Potential-based shaping and q-value initialization are equivalent;,citation_abstract=Shaping has proven to be a powerful but precarious means of improving reinforcement learning performance. Ng, Harada, and Russell (1999) proposed the potential-based shaping algorithm for adding shaping rewards in a way that guarantees the learner will learn optimal behavior.In this note, we prove certain similarities between this shaping algorithm and the initialization step required for several reinforcement learning algorithms. More specifically, we prove that a reinforcement learner with initial Q-values based on the shaping algorithm’s potential function make the same updates throughout learning as a learner receiving potential-based shaping rewards. We further prove that under a broad category of policies, the behavior of these two learners are indistinguishable. The comparison provides intuition on the theoretical properties of the shaping algorithm as well as a suggestion for a simpler method for capturing the algorithm’s benefit. In addition, the equivalence raises previously unaddressed issues concerning the efficiency of learning with potential-based shaping.;,citation_author=Eric Wiewiora;,citation_publication_date=2003-09;,citation_cover_date=2003-09;,citation_year=2003;,citation_issue=1;,citation_issn=1076-9757;,citation_volume=19;,citation_journal_title=Journal of Artificial Intelligence Research;,citation_publisher=AI Access Foundation;">
<meta name="citation_reference" content="citation_title=Behavior of organisms;,citation_author=B. F. Skinner;,citation_publication_date=1938;,citation_cover_date=1938;,citation_year=1938;,citation_isbn=9781583900079;">
<meta name="citation_reference" content="citation_title=John von Neumann’s conception of the minimax theorem: A journey through different mathematical contexts;,citation_author=Tinne Hoff Kjeldsen;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_fulltext_html_url=http://www.jstor.org/stable/41134130;,citation_issue=1;,citation_issn=00039519, 14320657;,citation_volume=56;,citation_journal_title=Archive for History of Exact Sciences;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in multiple independent Gaussian channels as a game;,citation_author=Michail Fasoulakis;,citation_author=Apostolos Traganitis;,citation_author=Anthony Ephremides;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1007/978-3-030-16989-3_1;,citation_inbook_title=Lecture notes of the institute for computer sciences, social informatics and telecommunications engineering;">
<meta name="citation_reference" content="citation_title=A jamming game in wireless networks with transmission cost;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2007-06;,citation_cover_date=2007-06;,citation_year=2007;,citation_fulltext_html_url=https://www-sop.inria.fr/members/Eitan.Altman/PAPERS/andrey-lncs.pdf;,citation_conference_title=EuroFGI international conference on network control and optimization (NET-COOP);,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Closed form solutions for symmetric water filling games;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=https://doi.org/10.1109/INFOCOM.2008.117;,citation_conference_title=IEEE INFOCOM conference on computer communications;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Closed form solutions for water-filling problems in optimization and game frameworks;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=47;,citation_journal_title=Telecommunication Systems;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in wireless networks: The case of several jammers;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=2009 international conference on game theory for networks;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Jamming game with incomplete information about the jammer;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the fourth international ICST conference on performance evaluation methodologies and tools;">
<meta name="citation_reference" content="citation_title=Equilibrium points in n -person games;,citation_author=John F. Nash;,citation_publication_date=1950-01;,citation_cover_date=1950-01;,citation_year=1950;,citation_issue=1;,citation_doi=10.1073/pnas.36.1.48;,citation_volume=36;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=Proceedings of the National Academy of Sciences;">
<meta name="citation_reference" content="citation_title=A further generalization of the Kakutani fixed point theorem, with application to nash equilibrium points;,citation_author=I. L. Glicksberg;,citation_publication_date=1952-02;,citation_cover_date=1952-02;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/2032478;,citation_volume=3;,citation_journal_title=Proceedings of the American Mathematical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=The logic of animal conflict;,citation_author=J Maynard Smith;,citation_author=G. R. Price;,citation_publication_date=1973-11;,citation_cover_date=1973-11;,citation_year=1973;,citation_issue=5427;,citation_doi=10.1038/246015a0;,citation_volume=246;,citation_journal_title=Nature;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Evolution and the theory of games;,citation_author=John Maynard Smith;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_isbn=0521246733;">
<meta name="citation_reference" content="citation_title=The selfish gene;,citation_author=Richard Dawkins;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_isbn=019857519X;">
<meta name="citation_reference" content="citation_title=Population games and evolutionary dynamics;,citation_author=William H. Sandholm;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_isbn=9780262195874;">
<meta name="citation_reference" content="citation_title=A note on evolutionary stable strategies and game dynamics;,citation_author=Josef Hofbauer;,citation_author=Peter Schuster;,citation_author=Karl Sigmund;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=3;,citation_volume=81;,citation_journal_title=Journal of Theoretical Biology;">
<meta name="citation_reference" content="citation_title=Evolutionary stable strategies and game dynamics;,citation_author=Peter D. Taylor;,citation_author=Leo B. Jonker;,citation_publication_date=1978-07;,citation_cover_date=1978-07;,citation_year=1978;,citation_issue=1-2;,citation_doi=10.1016/0025-5564(78)90077-9;,citation_volume=40;,citation_journal_title=Mathematical Biosciences;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium in a nutshell;,citation_author=Rabah Amir;,citation_author=Sergei Belkov;,citation_author=Igor V. Evstigneev;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_issue=4;,citation_doi=10.1007/s11238-017-9609-9;,citation_volume=83;,citation_journal_title=Theory and Decision;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium as an expression of bayesian rationality;,citation_author=Robert J. Aumann;,citation_publication_date=1987-01;,citation_cover_date=1987-01;,citation_year=1987;,citation_issue=1;,citation_doi=10.2307/1911154;,citation_volume=55;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Subjectivity and correlation in randomized strategies;,citation_author=Robert J. Aumann;,citation_publication_date=1974-03;,citation_cover_date=1974-03;,citation_year=1974;,citation_issue=1;,citation_doi=10.1016/0304-4068(74)90037-8;,citation_volume=1;,citation_journal_title=Journal of Mathematical Economics;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Agreeing to disagree;,citation_author=Robert J. Aumann;,citation_publication_date=1976-11;,citation_cover_date=1976-11;,citation_year=1976;,citation_issue=6;,citation_doi=10.1214/aos/1176343654;,citation_volume=4;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Computing correlated equilibria in multi-player games;,citation_author=Christos H. Papadimitriou;,citation_author=Tim Roughgarden;,citation_publication_date=2008-07;,citation_cover_date=2008-07;,citation_year=2008;,citation_issue=3;,citation_doi=10.1145/1379759.1379762;,citation_volume=55;,citation_journal_title=Journal of the ACM;,citation_publisher=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players, iIII part i. The basic model;,citation_author=John C. Harsanyi;,citation_publication_date=1967-11;,citation_cover_date=1967-11;,citation_year=1967;,citation_issue=3;,citation_doi=10.1287/mnsc.14.3.159;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players part II. Bayesian equilibrium points;,citation_author=John C. Harsanyi;,citation_publication_date=1968-01;,citation_cover_date=1968-01;,citation_year=1968;,citation_issue=5;,citation_doi=10.1287/mnsc.14.5.320;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by “bayesian” players, part III. The basic probability distribution of the game;,citation_author=John C. Harsanyi;,citation_publication_date=1968-03;,citation_cover_date=1968-03;,citation_year=1968;,citation_issue=7;,citation_doi=10.1287/mnsc.14.7.486;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Game theory for applied economists;,citation_author=Robert Gibbons;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_isbn=0691043086;">
<meta name="citation_reference" content="citation_title=Computer science theory for the information age;,citation_author=John Hopcroft;,citation_author=Ravi Kannan;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_fulltext_html_url=https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/hopcroft-kannan-feb2012.pdf;">
<meta name="citation_reference" content="citation_title=Theory of self-adaptive control systems;,citation_author=H. Kwakernaak;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Information pattern for linear discrete-time models with stochastic coefficients;,citation_author=T. Bohlin;,citation_publication_date=1970-02;,citation_cover_date=1970-02;,citation_year=1970;,citation_issue=1;,citation_volume=15;,citation_journal_title=IEEE Transactions on Automatic Control (TAC);">
<meta name="citation_reference" content="citation_title=Information states for linear stochastic systems;,citation_author=M. H. A Davis;,citation_author=P. P Varaiya;,citation_publication_date=1972-02;,citation_cover_date=1972-02;,citation_year=1972;,citation_issue=2;,citation_volume=37;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Sufficient statistics in the optimal control of stochastic systems;,citation_author=Charlotte Striebel;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=12;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Some remarks on the concept of state;,citation_author=Hans S. Witsenhausen;,citation_editor=Y. C. Ho;,citation_editor=S. K. Mitter;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_inbook_title=Directions in large-scale systems;">
<meta name="citation_reference" content="citation_title=Linear automaton transformations;,citation_author=A. Nerode;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_volume=9;,citation_journal_title=Proceedings of American Mathematical Society;">
<meta name="citation_reference" content="citation_title=A convergence theorem for non-negative almost supermartingales and some applications;,citation_author=H. Robbins;,citation_author=D. Siegmund;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_doi=10.1016/b978-0-12-604550-5.50015-8;,citation_inbook_title=Optimizing methods in statistics;">
<meta name="citation_reference" content="citation_title=Discrete parameter martingales;,citation_author=J. Neveu;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;">
<meta name="citation_reference" content="citation_title=A user’s guide to measure theoretic probability;,citation_author=David Pollard;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Convergence of stochastic approximation via martingale and converse Lyapunov methods;,citation_author=M. Vidyasagar;,citation_publication_date=2023-01;,citation_cover_date=2023-01;,citation_year=2023;,citation_issue=2;,citation_doi=10.1007/s00498-023-00342-9;,citation_volume=35;,citation_journal_title=Mathematics of Control, Signals, and Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=On stochastic approximation;,citation_author=E. G. Gladyshev;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=2;,citation_doi=10.1137/1110031;,citation_volume=10;,citation_journal_title=Theory of Probability and Its Applications;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Gradient convergence in gradient methods with errors;,citation_author=Dimitri P. Bertsekas;,citation_author=John N. Tsitsiklis;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=3;,citation_doi=10.1137/s1052623497331063;,citation_volume=10;,citation_journal_title=SIAM Journal on Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Stochastic processes;,citation_author=Joseph T. Chang;,citation_publication_date=2007-02;,citation_cover_date=2007-02;,citation_year=2007;,citation_fulltext_html_url=http://www.stat.yale.edu/~pollard/Courses/251.spring2013/Handouts/Chang-notes.pdf;">
<meta name="citation_reference" content="citation_title=Lyapunov criterion for stochastic systems and its applications in distributed computation;,citation_author=Yuzhen Qin;,citation_author=Ming Cao;,citation_author=Brian D. O. Anderson;,citation_publication_date=2020-02;,citation_cover_date=2020-02;,citation_year=2020;,citation_issue=2;,citation_doi=10.1109/tac.2019.2910948;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=An upper bound on the loss from approximate optimal-value functions;,citation_author=Satinder P. Singh;,citation_author=Richard C. Yee;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993308;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Feature-based methods for large scale dynamic programming;,citation_author=John N. Tsitsiklis;,citation_author=Benjamin Roy;,citation_publication_date=1996-03;,citation_cover_date=1996-03;,citation_year=1996;,citation_issue=1-3;,citation_doi=10.1007/bf00114724;,citation_volume=22;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=A graphical derivation of the legendre transform;,citation_author=Sam Kennerly;,citation_publication_date=2011-04;,citation_cover_date=2011-04;,citation_year=2011;,citation_fulltext_html_url=http://einstein.drexel.edu/~skennerly/maths/Legendre.pdf;">
<meta name="citation_reference" content="citation_title=Variational analysis;,citation_author=R Tyrrell Rockafellar;,citation_author=Roger J-B Wets;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=317;">
<meta name="citation_reference" content="citation_title=Entropy, large deviations, and statistical mechanics;,citation_author=Richard S. Ellis;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_doi=10.1007/978-1-4613-8533-2;">
<meta name="citation_reference" content="citation_title=A theory of regularized Markov decision processes;,citation_abstract=Many recent successful (deep) reinforcement learning algorithms make use of regularization, generally based on entropy or Kullback-Leibler divergence. We propose a general theory of regularized Markov Decision Processes that generalizes these approaches in two directions: we consider a larger class of regularizers, and we consider the general modified policy iteration approach, encompassing both policy iteration and value iteration. The core building blocks of this theory are a notion of regularized Bellman operator and the Legendre-Fenchel transform, a classical tool of convex optimization. This approach allows for error propagation analyses of general algorithmic schemes of which (possibly variants of) classical algorithms such as Trust Region Policy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic Policy Programming are special cases. This also draws connections to proximal convex optimization, especially to Mirror Descent.;,citation_author=Matthieu Geist;,citation_author=Bruno Scherrer;,citation_author=Olivier Pietquin;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://proceedings.mlr.press/v97/geist19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Stochastic approximation;,citation_author=Vivek S. Borkar;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=10.1007/978-93-86279-38-5;">
<meta name="citation_reference" content="citation_title=Increasing returns and path dependence in the economy;,citation_author=W. Brian Arthur;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_doi=10.3998/mpub.10029;">
<meta name="citation_reference" content="citation_title=Stochastic approximation: Invited paper;,citation_author=Tze Leung Lai;,citation_publication_date=2003-04;,citation_cover_date=2003-04;,citation_year=2003;,citation_issue=2;,citation_doi=10.1214/aos/1051027873;,citation_volume=31;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Probabilities and potential B: Theory of martingales;,citation_author=Claude Dellacherie;,citation_author=Paul-André Meyer;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../stochastic-control/index.html" rel="" target="">
 <span class="menu-text">Stochastic Control</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../multi-agent-systems/index.html" rel="" target="">
 <span class="menu-text">Multi-Agent Systems</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/adityam/stochastic-control" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../mdps/intro.html">MDPs</a></li><li class="breadcrumb-item"><a href="../mdps/monotone-mdps.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the course</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Stochastic Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/newsvendor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The newsvendor problem</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/gambling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Optimal gambling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inventory Management</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/monotone-mdps.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/power-delay-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/reward-shaping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reward Shaping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inf-horizon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mdp-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">MDP algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management-revisited.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Inventory management (revisted)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mobile-edge-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Service Migration in Mobile edge computing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/computational-complexity-vi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Computational complexity of value interation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/linear-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Linear programming formulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/lipschitz-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">POMDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/sequential-hypothesis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Approx DP</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/approx-DP.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Approximate dynamic programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/policy-loss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Upper bounds on policy loss</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/model-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Risk sensitive MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-utility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Risk Sensitive Utility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Risk Sensitive MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">LQ systems</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">RL</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rl/stochastic-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Stochastic approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Probability Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Convergence of random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/sub-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Sub-Gaussian random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/change-of-measure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Change of Measure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/martingales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Martingales</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/stochastic-stability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Stochastic stability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Linear Algebra Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/postive-definite-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Positive definite matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/svd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Singular value decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/rkhs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Reproducing Kernel Hilbert Space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Convexity Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/convexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Convex sets and convex functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/duality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Duality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 1</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#stochastic-dominance" id="toc-stochastic-dominance" class="nav-link active" data-scroll-target="#stochastic-dominance"><span class="header-section-number">6.1</span> Stochastic dominance</a></li>
  <li><a href="#stochastic-monotonicity" id="toc-stochastic-monotonicity" class="nav-link" data-scroll-target="#stochastic-monotonicity"><span class="header-section-number">6.2</span> Stochastic monotonicity</a></li>
  <li><a href="#monotonicity-of-value-functions" id="toc-monotonicity-of-value-functions" class="nav-link" data-scroll-target="#monotonicity-of-value-functions"><span class="header-section-number">6.3</span> Monotonicity of value functions</a></li>
  <li><a href="#submodularity" id="toc-submodularity" class="nav-link" data-scroll-target="#submodularity"><span class="header-section-number">6.4</span> Submodularity</a></li>
  <li><a href="#monotonicity-of-optimal-policy" id="toc-monotonicity-of-optimal-policy" class="nav-link" data-scroll-target="#monotonicity-of-optimal-policy"><span class="header-section-number">6.5</span> Monotonicity of optimal policy</a></li>
  <li><a href="#constraints-on-actions" id="toc-constraints-on-actions" class="nav-link" data-scroll-target="#constraints-on-actions"><span class="header-section-number">6.6</span> Constraints on actions</a></li>
  <li><a href="#monotone-dynamic-programming" id="toc-monotone-dynamic-programming" class="nav-link" data-scroll-target="#monotone-dynamic-programming"><span class="header-section-number">6.7</span> Monotone dynamic programming</a></li>
  <li><a href="#example-a-machine-replacement-model" id="toc-example-a-machine-replacement-model" class="nav-link" data-scroll-target="#example-a-machine-replacement-model"><span class="header-section-number">6.8</span> Example: A machine replacement model</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/adityam/stochastic-control/edit/quarto/mdps/monotone-mdps.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="http://www.cim.mcgill.ca/~adityam">Aditya Mahajan</a> </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="http://www.mcgill.ca/ece">
            McGill University
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 17, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="bi bi-journal-text text-primary"></i> Summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>In many applications, it is useful to know if the value function and the optimal policy is weakly increasing (or weakly decreasing) in state. Sufficient conditions are presented under which such monotonicity properties hold. These properties are useful because they makes it easy to search and implement the optimal policy.</p>
</div>
</div>
<p>Consider a manufacturing process, where the machine used for manufacturing deteriorates over time. Let <span class="math inline">\(\ALPHABET S = \{0, 1, \dots n \}\)</span> represent the condition of the machine. The higher the value of <span class="math inline">\(s\)</span>, the worse the condition of the equipment.</p>
<p>A decision maker observes the state of the machine and has two options: continue operating the machine or replace it with a a new and identical piece of equipment. Operating the machine is state <span class="math inline">\(s\)</span> costs <span class="math inline">\(h(s)\)</span>, where <span class="math inline">\(h(⋅)\)</span> is a weakly increasing function; replace the machine costs a constant amount <span class="math inline">\(K\)</span>.</p>
<p>When the machine is operated, it’s state deteriorates according to <span class="math display">\[
  S_{t+1} = \min( S_t + W_t , n)
\]</span> where <span class="math inline">\(\{W_t\}_{t \ge 1}\)</span> is an i.i.d.&nbsp;process with PMF <span class="math inline">\(μ\)</span>.</p>
<p>We model the above model as an MDP with state space <span class="math inline">\(\ALPHABET S\)</span> and action space <span class="math inline">\(\ALPHABET A = \{0, 1\}\)</span> where <span class="math inline">\(0\)</span> means operating the machine and <span class="math inline">\(1\)</span> means replacing the machine.</p>
<p>We compute the optimal policy for this model when <span class="math inline">\(W \sim \text{Binom}(n,p)\)</span> when <span class="math inline">\(n = 10\)</span>, <span class="math inline">\(T = 20\)</span>, <span class="math inline">\(h(s) = 2s\)</span>, and <span class="math inline">\(K=20\)</span> for different values of <span class="math inline">\(p\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb1" data-startfrom="31" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 30;"><span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="kw">function</span>(s) { <span class="cf">return</span> c<span class="op">*</span>s }</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>Pw <span class="op">=</span> {</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> points <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>(n<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> cumulative <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> probability <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(<span class="kw">var</span> k <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> k <span class="op">&lt;=</span> n<span class="op">;</span> k<span class="op">++</span>) {</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    probability <span class="op">=</span> <span class="fu">binomial</span>(n<span class="op">,</span>k<span class="op">,</span>p)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    cumulative <span class="op">+=</span> probability</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    points[k] <span class="op">=</span> { <span class="dt">probability</span><span class="op">:</span> probability<span class="op">,</span> <span class="dt">cumulative</span><span class="op">:</span> cumulative }</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> points</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>binomial <span class="op">=</span> {</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>  <span class="co">// From https://stackoverflow.com/a/37715980/193149</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> logf <span class="op">=</span> [<span class="dv">0</span><span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="fl">0.6931471805599453</span><span class="op">,</span> <span class="fl">1.791759469228055</span><span class="op">,</span> <span class="fl">3.1780538303479458</span><span class="op">,</span> <span class="fl">4.787491742782046</span><span class="op">,</span> <span class="fl">6.579251212010101</span><span class="op">,</span> <span class="fl">8.525161361065415</span><span class="op">,</span> <span class="fl">10.60460290274525</span><span class="op">,</span> <span class="fl">12.801827480081469</span><span class="op">,</span> <span class="fl">15.104412573075516</span><span class="op">,</span> <span class="fl">17.502307845873887</span><span class="op">,</span> <span class="fl">19.987214495661885</span><span class="op">,</span> <span class="fl">22.552163853123425</span><span class="op">,</span> <span class="fl">25.19122118273868</span><span class="op">,</span> <span class="fl">27.89927138384089</span><span class="op">,</span> <span class="fl">30.671860106080672</span><span class="op">,</span> <span class="fl">33.50507345013689</span><span class="op">,</span> <span class="fl">36.39544520803305</span><span class="op">,</span> <span class="fl">39.339884187199495</span><span class="op">,</span> <span class="fl">42.335616460753485</span><span class="op">,</span> <span class="fl">45.38013889847691</span><span class="op">,</span> <span class="fl">48.47118135183523</span><span class="op">,</span> <span class="fl">51.60667556776438</span><span class="op">,</span> <span class="fl">54.78472939811232</span><span class="op">,</span> <span class="fl">58.00360522298052</span><span class="op">,</span> <span class="fl">61.261701761002</span><span class="op">,</span> <span class="fl">64.55753862700634</span><span class="op">,</span> <span class="fl">67.88974313718154</span><span class="op">,</span> <span class="fl">71.25703896716801</span><span class="op">,</span> <span class="fl">74.65823634883016</span><span class="op">,</span> <span class="fl">78.0922235533153</span><span class="op">,</span> <span class="fl">81.55795945611504</span><span class="op">,</span> <span class="fl">85.05446701758152</span><span class="op">,</span> <span class="fl">88.58082754219768</span><span class="op">,</span> <span class="fl">92.1361756036871</span><span class="op">,</span> <span class="fl">95.7196945421432</span><span class="op">,</span> <span class="fl">99.33061245478743</span><span class="op">,</span> <span class="fl">102.96819861451381</span><span class="op">,</span> <span class="fl">106.63176026064346</span><span class="op">,</span> <span class="fl">110.32063971475739</span><span class="op">,</span> <span class="fl">114.0342117814617</span><span class="op">,</span> <span class="fl">117.77188139974507</span><span class="op">,</span> <span class="fl">121.53308151543864</span><span class="op">,</span> <span class="fl">125.3172711493569</span><span class="op">,</span> <span class="fl">129.12393363912722</span><span class="op">,</span> <span class="fl">132.95257503561632</span><span class="op">,</span> <span class="fl">136.80272263732635</span><span class="op">,</span> <span class="fl">140.67392364823425</span><span class="op">,</span> <span class="fl">144.5657439463449</span><span class="op">,</span> <span class="fl">148.47776695177302</span><span class="op">,</span> <span class="fl">152.40959258449735</span><span class="op">,</span> <span class="fl">156.3608363030788</span><span class="op">,</span> <span class="fl">160.3311282166309</span><span class="op">,</span> <span class="fl">164.32011226319517</span><span class="op">,</span> <span class="fl">168.32744544842765</span><span class="op">,</span>  <span class="fl">172.3527971391628</span><span class="op">,</span> <span class="fl">176.39584840699735</span><span class="op">,</span> <span class="fl">180.45629141754378</span><span class="op">,</span> <span class="fl">184.53382886144948</span><span class="op">,</span> <span class="fl">188.6281734236716</span><span class="op">,</span> <span class="fl">192.7390472878449</span><span class="op">,</span> <span class="fl">196.86618167289</span><span class="op">,</span> <span class="fl">201.00931639928152</span><span class="op">,</span> <span class="fl">205.1681994826412</span><span class="op">,</span> <span class="fl">209.34258675253685</span><span class="op">,</span> <span class="fl">213.53224149456327</span><span class="op">,</span> <span class="fl">217.73693411395422</span><span class="op">,</span> <span class="fl">221.95644181913033</span><span class="op">,</span> <span class="fl">226.1905483237276</span><span class="op">,</span> <span class="fl">230.43904356577696</span><span class="op">,</span> <span class="fl">234.70172344281826</span><span class="op">,</span> <span class="fl">238.97838956183432</span><span class="op">,</span> <span class="fl">243.2688490029827</span><span class="op">,</span> <span class="fl">247.57291409618688</span><span class="op">,</span> <span class="fl">251.8904022097232</span><span class="op">,</span> <span class="fl">256.22113555000954</span><span class="op">,</span> <span class="fl">260.5649409718632</span><span class="op">,</span> <span class="fl">264.9216497985528</span><span class="op">,</span> <span class="fl">269.2910976510198</span><span class="op">,</span> <span class="fl">273.6731242856937</span><span class="op">,</span> <span class="fl">278.0675734403661</span><span class="op">,</span> <span class="fl">282.4742926876304</span><span class="op">,</span> <span class="fl">286.893133295427</span><span class="op">,</span> <span class="fl">291.3239500942703</span><span class="op">,</span> <span class="fl">295.76660135076065</span><span class="op">,</span> <span class="fl">300.22094864701415</span><span class="op">,</span> <span class="fl">304.6868567656687</span><span class="op">,</span> <span class="fl">309.1641935801469</span><span class="op">,</span> <span class="fl">313.65282994987905</span><span class="op">,</span> <span class="fl">318.1526396202093</span><span class="op">,</span> <span class="fl">322.66349912672615</span><span class="op">,</span> <span class="fl">327.1852877037752</span><span class="op">,</span> <span class="fl">331.7178871969285</span><span class="op">,</span> <span class="fl">336.26118197919845</span><span class="op">,</span> <span class="fl">340.815058870799</span><span class="op">,</span> <span class="fl">345.37940706226686</span><span class="op">,</span> <span class="fl">349.95411804077025</span><span class="op">,</span> <span class="fl">354.5390855194408</span><span class="op">,</span> <span class="fl">359.1342053695754</span><span class="op">,</span> <span class="fl">363.73937555556347</span>]</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="kw">function</span>(n<span class="op">,</span> k<span class="op">,</span> p) {</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">exp</span>(logf[n] <span class="op">-</span> logf[n<span class="op">-</span>k] <span class="op">-</span> logf[k]) <span class="op">*</span> p<span class="op">**</span>k <span class="op">*</span> (<span class="dv">1</span><span class="op">-</span>p)<span class="op">**</span>(n<span class="op">-</span>k)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>DP <span class="op">=</span> {</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> DP <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>()</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> V <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>(n<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> Q0 <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>(n<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> Q1 <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>(n<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> a <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>  <span class="kw">var</span> val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Initialize the terminal value function</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">var</span> s <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> s <span class="op">&lt;=</span> n<span class="op">;</span> s<span class="op">++</span>) {</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>    V[<span class="dv">1</span><span class="op">+</span>s] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Dynamic Programming</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">var</span> t <span class="op">=</span> T<span class="op">;</span> t <span class="op">&gt;=</span> <span class="dv">1</span><span class="op">;</span> t<span class="op">--</span>) {</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Q0[s] = h[s] + E[ V(s+W) ]</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Q1[s] = K + E[ V(W) ]</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (<span class="kw">var</span> s <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> s <span class="op">&lt;=</span> n<span class="op">;</span> s<span class="op">++</span>) {</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>      Q0[<span class="dv">1</span><span class="op">+</span>s] <span class="op">=</span> <span class="fu">h</span>(s)</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>      Q1[<span class="dv">1</span><span class="op">+</span>s] <span class="op">=</span> K</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (<span class="kw">var</span> w<span class="op">=</span><span class="dv">0</span><span class="op">;</span> w <span class="op">&lt;=</span> n<span class="op">;</span> w<span class="op">++</span>) {</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> s_next <span class="op">=</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">min</span>(s<span class="op">+</span>w<span class="op">,</span> n)</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>        Q0[<span class="dv">1</span><span class="op">+</span>s] <span class="op">+=</span> V[ <span class="dv">1</span> <span class="op">+</span> s_next ]<span class="op">*</span>Pw[w]<span class="op">.</span><span class="at">probability</span> </span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>        Q1[<span class="dv">1</span><span class="op">+</span>s] <span class="op">+=</span> V[ <span class="dv">1</span> <span class="op">+</span> w ]<span class="op">*</span>Pw[w]<span class="op">.</span><span class="at">probability</span> </span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (<span class="kw">var</span> s <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> s <span class="op">&lt;=</span> n<span class="op">;</span> s<span class="op">++</span>) {</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (Q0[<span class="dv">1</span><span class="op">+</span>s] <span class="op">&lt;=</span> Q1[<span class="dv">1</span><span class="op">+</span>s]) {</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>         a <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>         val <span class="op">=</span> Q0[<span class="dv">1</span><span class="op">+</span>s]</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>      } <span class="cf">else</span> {</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>         a <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>         val <span class="op">=</span> Q1[<span class="dv">1</span><span class="op">+</span>s]</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>      DP[idx<span class="op">++</span>] <span class="op">=</span> { <span class="dt">time</span><span class="op">:</span> t<span class="op">,</span> <span class="dt">state</span><span class="op">:</span> s<span class="op">,</span> <span class="dt">value</span><span class="op">:</span> val<span class="op">,</span> <span class="dt">action</span><span class="op">:</span> a }</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>      V[<span class="dv">1</span><span class="op">+</span>s] <span class="op">=</span> val</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> DP<span class="op">;</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-6" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-7" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-8" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb2" data-startfrom="109" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 108;"><span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>viewof p <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="fl">0.1</span><span class="op">,</span> <span class="fl">0.95</span>]<span class="op">,</span> {<span class="dt">label</span><span class="op">:</span> <span class="st">"p"</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="fl">0.1</span>})</span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-2" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div>
<div class="sourceCode cell-code hidden" id="cb3" data-startfrom="121" data-source-offset="-1"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 120;"><span id="cb3-121"><a href="#cb3-121" aria-hidden="true" tabindex="-1"></a>value_plot <span class="op">=</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true" tabindex="-1"></a>  <span class="dt">grid</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span></span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true" tabindex="-1"></a>  <span class="dt">y</span><span class="op">:</span> {<span class="dt">domain</span><span class="op">:</span> [<span class="dv">120</span><span class="op">,</span><span class="dv">380</span>]}<span class="op">,</span></span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true" tabindex="-1"></a>  <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Axes</span></span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true" tabindex="-1"></a>    Plot<span class="op">.</span><span class="fu">ruleX</span>([<span class="dv">0</span>])<span class="op">,</span></span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Plot.ruleY([0]),</span></span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Data</span></span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true" tabindex="-1"></a>    Plot<span class="op">.</span><span class="fu">line</span>(DP<span class="op">.</span><span class="fu">filter</span>(d <span class="kw">=&gt;</span> d<span class="op">.</span><span class="at">time</span> <span class="op">==</span> time)<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span><span class="st">"state"</span><span class="op">,</span> <span class="dt">y</span><span class="op">:</span><span class="st">"value"</span><span class="op">,</span> <span class="dt">curve</span><span class="op">:</span><span class="st">"step-after"</span>})</span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb3-131"><a href="#cb3-131" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb3-132"><a href="#cb3-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-133"><a href="#cb3-133" aria-hidden="true" tabindex="-1"></a>action_plot <span class="op">=</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb3-134"><a href="#cb3-134" aria-hidden="true" tabindex="-1"></a>  <span class="dt">grid</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span></span>
<span id="cb3-135"><a href="#cb3-135" aria-hidden="true" tabindex="-1"></a>  <span class="dt">y</span> <span class="op">:</span> {<span class="dt">ticks</span><span class="op">:</span> <span class="dv">1</span> }<span class="op">,</span></span>
<span id="cb3-136"><a href="#cb3-136" aria-hidden="true" tabindex="-1"></a>  <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb3-137"><a href="#cb3-137" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Axes</span></span>
<span id="cb3-138"><a href="#cb3-138" aria-hidden="true" tabindex="-1"></a>    Plot<span class="op">.</span><span class="fu">ruleX</span>([<span class="dv">0</span>])<span class="op">,</span></span>
<span id="cb3-139"><a href="#cb3-139" aria-hidden="true" tabindex="-1"></a>    Plot<span class="op">.</span><span class="fu">ruleY</span>([<span class="dv">0</span>])<span class="op">,</span></span>
<span id="cb3-140"><a href="#cb3-140" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Data</span></span>
<span id="cb3-141"><a href="#cb3-141" aria-hidden="true" tabindex="-1"></a>    Plot<span class="op">.</span><span class="fu">ruleX</span>(DP<span class="op">.</span><span class="fu">filter</span>(d <span class="kw">=&gt;</span> d<span class="op">.</span><span class="at">time</span> <span class="op">==</span> time)<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> <span class="st">"state"</span><span class="op">,</span> <span class="dt">y</span><span class="op">:</span> <span class="st">"action"</span><span class="op">,</span> <span class="dt">strokeWidth</span><span class="op">:</span> <span class="dv">2</span>})<span class="op">,</span></span>
<span id="cb3-142"><a href="#cb3-142" aria-hidden="true" tabindex="-1"></a>    Plot<span class="op">.</span><span class="fu">dot</span>(DP<span class="op">.</span><span class="fu">filter</span>(d <span class="kw">=&gt;</span> d<span class="op">.</span><span class="at">time</span> <span class="op">==</span> time)<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> <span class="st">"state"</span><span class="op">,</span> <span class="dt">y</span><span class="op">:</span> <span class="st">"action"</span><span class="op">,</span> <span class="dt">fill</span><span class="op">:</span> <span class="st">"currentColor"</span><span class="op">,</span> <span class="dt">r</span><span class="op">:</span> <span class="dv">4</span>})</span>
<span id="cb3-143"><a href="#cb3-143" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb3-144"><a href="#cb3-144" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-machine-replacement" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="fig-machine-replacement-1" class="quarto-figure quarto-figure-center anchored" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<div id="ojs-cell-3-1" data-nodetype="declaration">

</div>
<figcaption class="figure-caption">(a) Value function</figcaption>
</figure>
</div>
<div id="fig-machine-replacement-2" class="quarto-figure quarto-figure-center anchored" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<div id="ojs-cell-3-2" data-nodetype="declaration">

</div>
<figcaption class="figure-caption">(b) Optimal policy</figcaption>
</figure>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;6.1: Solution of the machine repair problem</figcaption><p></p>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="bi bi-patch-question text-warning"></i> Qualitative property of optimal policy
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the machine replacement problem shown in <a href="#fig-machine-replacement">Figure&nbsp;<span>6.1</span></a>, the optimal policy satisfies a qualitative property: <em>the optimal policy is monotone</em>, that is if <span class="math inline">\(s &lt; s'\)</span> then <span class="math inline">\(π_t(s) &lt; π_t(s')\)</span>. Intuitively, it makes sense. But how can we establish that this is the case for other choices of problem parameters as well?</p>
</div>
</div>
<section id="stochastic-dominance" class="level2 page-columns page-full" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="stochastic-dominance"><span class="header-section-number">6.1</span> Stochastic dominance</h2>
<div class="page-columns page-full"><p> Let <span class="math inline">\(\ALPHABET S\)</span> be a totally ordered finite set, say <span class="math inline">\(\{1, \dots, n\}\)</span>.</p><div class="no-row-height column-margin column-container"><span class="">Stochastic dominance is a partial order on random variables defined on totally ordered sets</span></div></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
(First order) stochastic dominance
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose <span class="math inline">\(S^1\)</span> and <span class="math inline">\(S^2\)</span> are <span class="math inline">\(\ALPHABET S\)</span> valued random variables where <span class="math inline">\(S^1 \sim \mu^1\)</span> and <span class="math inline">\(S^2 \sim \mu^2\)</span>. We say <span class="math inline">\(S^1\)</span> <em>stochastically dominates</em> <span class="math inline">\(S^2\)</span> if for any <span class="math inline">\(s \in \ALPHABET S\)</span>, <span class="math display">\[\begin{equation}\label{eq:inc-prob}
  \PR(S^1 \ge s) \ge \PR(S^2 \ge s).
\end{equation}\]</span></p>
<p>Stochastic domination is denoted by <span class="math inline">\(S^1 \succeq_s S^2\)</span> or <span class="math inline">\(\mu^1 \succeq_s \mu^2\)</span>.</p>
</div>
</div>
<p>Let <span class="math inline">\({\rm M}^1\)</span> and <span class="math inline">\({\rm M}^2\)</span> denote the CDF of <span class="math inline">\(\mu^1\)</span> and <span class="math inline">\(\mu^2\)</span>. Then \eqref{eq:inc-prob} is equivalent to the following: <span class="math display">\[\begin{equation}\label{eq:cdf}
  {\rm M}^1_s \le {\rm M}^2_s, \quad \forall s \in \ALPHABET S.
\end{equation}\]</span> Thus, visually, <span class="math inline">\(S^1 \succeq_s S^2\)</span> means that the CDF of <span class="math inline">\(S^1\)</span> <em>lies below</em> the CDF of <span class="math inline">\(S^2\)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\left[0, \frac 14, \frac 14, \frac 12\right] \succeq_s \left[\frac 14, 0, \frac 14, \frac 12 \right] \succeq_s \left[\frac 14, \frac 14, \frac 14, \frac 14 \right].\)</span></p>
</div>
</div>
<p>Stochastic dominance is important due to the following property.</p>
<div id="thm-stochastic-dominance" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.1 </strong></span>Let <span class="math inline">\(f \colon \ALPHABET S \to \reals\)</span> be a (weakly) increasing function and <span class="math inline">\(S^1 \sim \mu^1\)</span> and <span class="math inline">\(S^2 \sim \mu^2\)</span> are random variables defined on <span class="math inline">\(\ALPHABET S\)</span>. Then <span class="math inline">\(S^1 \succeq_s S^2\)</span> if and only if <span class="math display">\[\begin{equation}\label{eq:inc-fun}
  \EXP[f(S^1)] \ge \EXP[f(S^2)].
\end{equation}\]</span></p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Abel’s lemma or summation by parts
</div>
</div>
<div class="callout-body-container callout-body">
<p>For any two sequences <span class="math inline">\(\{f_k\}_{k \ge 1}\)</span> and <span class="math inline">\(\{g_k\}_{k \ge 1}\)</span>, <span class="math display">\[\sum_{k=m}^n f_k(g_{k+1} - g_{k}) =
(f_n g_{n+1} - f_m g_m) + \sum_{k=m+1}^n g_k(f_{k+1} - f_k).\]</span></p>
<p>Summation by parts may be viewed as the discrete analog of integration by parts: <span class="math display">\[
\int_a^b f(x) g'(x) dx = f(x) g(x)\Big|_{a}^{b} - \int_{a}^{b} f'(x)g(x)dx.
\]</span> An alternative form which is sometimes useful is: <span class="math display">\[
f_n g_n - f_m g_m =
\sum_{k=m}^{n-1} f_k \Delta g_k
+
\sum_{k=m}^{n-1} g_k \Delta f_k
+
\sum_{k=m}^{n-1} \Delta f_k \Delta g_k.
\]</span></p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof (stochastic dominance implies monotone expectations)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For the ease of notation, let <span class="math inline">\(f_i\)</span> to denote <span class="math inline">\(f(i)\)</span> and define <span class="math inline">\({\rm M}^1_0 = {\rm M}^2_0 = 0\)</span>. Consider the following: <span class="math display">\[\begin{align*}
    \sum_{i=1}^n f_i \mu^1_i
    &amp;= \sum_{i=1}^n f_i ({\rm M}^1_i - {\rm M}^1_{i-1})
    \\
    &amp;\stackrel{(a)}= \sum_{i=1}^n {\rm M}^1_{i-1} (f_{i-1} - f_{i}) + f_n {\rm M}^1_n
    \\
    &amp;\stackrel{(b)}{\ge}
    \sum_{i=1}^n {\rm M}^2_{i-1} (f_{i-1} - f_{i}) + f_n {\rm M}^2_n
    \\
    &amp;\stackrel{(a)}= \sum_{i=1}^n f_i ({\rm M}^2_i - {\rm M}^2_{i-1})
    \\
    &amp;= \sum_{i=1}^n f_i \mu_i,
\end{align*}\]</span> which completes the proof. In the above equations, both steps marked <span class="math inline">\((a)\)</span> use summation by parts and <span class="math inline">\((b)\)</span> uses the following facts:</p>
<ol type="1">
<li>For any <span class="math inline">\(i\)</span>, <span class="math inline">\({\rm M}^1_{i-1} \le {\rm M}^2_{i-1}\)</span> (because of \eqref{eq:cdf}) and <span class="math inline">\(f_{i-1} - f_{i} &lt; 0\)</span> (because <span class="math inline">\(f\)</span> is increasing function). Thus, <span class="math display">\[{\rm M}^1_{i-1}(f_{i-1} - f_i) \ge {\rm M}^2_{i-1}(f_{i-1} - f_i). \]</span></li>
<li><span class="math inline">\({\rm M}^1_n = {\rm M}^2_n = 1\)</span>.</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof (monotone expectations implies stochastic monotonicity)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Suppose for any increasing function <span class="math inline">\(f\)</span>, \eqref{eq:inc-fun} holds. Given any <span class="math inline">\(i \in \{1, \dots, n\}\)</span>, define the function <span class="math inline">\(f_i(k) = \IND\{k &gt; i\}\)</span>, which is an increasing function of <span class="math inline">\(k\)</span>. Then, <span class="math display">\[ \EXP[f_i(S)] = \sum_{k=1}^n f_i(k) \mu^1_k = \sum_{k &gt; i} \mu^1_k = 1 - {\rm M}^1_i.
\]</span> By a similar argument, we have <span class="math display">\[ \EXP[f_i(S^2)] = 1 - {\rm M}^2_i. \]</span> Since <span class="math inline">\(\EXP[f_i(S)] \ge \EXP[f_i(S^2)]\)</span>, we have that <span class="math inline">\({\rm M}^1_i \le {\rm M}^2_i\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="stochastic-monotonicity" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="stochastic-monotonicity"><span class="header-section-number">6.2</span> Stochastic monotonicity</h2>
<p>Stochastic monotonicity extends the notion of stochastic dominance to Markov chains. Suppose <span class="math inline">\(\ALPHABET S\)</span> is a totally ordered set and <span class="math inline">\(\{S_t\}_{t \ge 1}\)</span> is a time-homogeneous Markov chain on <span class="math inline">\(\ALPHABET S\)</span> with transition probability matrix <span class="math inline">\(P\)</span>. Let <span class="math inline">\(P_i\)</span> denote the <span class="math inline">\(i\)</span>-th row of <span class="math inline">\(P\)</span>. Note that <span class="math inline">\(P_i\)</span> is a PMF.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stochastic monotonicity
</div>
</div>
<div class="callout-body-container callout-body">
<p>A Markov chain with transition matrix <span class="math inline">\(P\)</span> is stochastically monotone if <span class="math display">\[ P_i \succeq_s P_j, \quad \forall i &gt; j. \]</span></p>
</div>
</div>
<p>An immediate implication is the following.</p>
<div id="thm-stochastic-monotonicity" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.2 </strong></span>Let <span class="math inline">\(\{S_t\}_{t \ge 1}\)</span> be a Markov chain with transition matrix <span class="math inline">\(P\)</span> and <span class="math inline">\(f \colon \ALPHABET S \to \reals\)</span> is a weakly increasing function. Then, for any <span class="math inline">\(s^1, s^2 \in \ALPHABET S\)</span> such that <span class="math inline">\(s^1 &gt; s^2\)</span>, <span class="math display">\[ \EXP[f(S_{t+1}) | S_t = s^1] \ge \EXP[ f(S_{t+1}) | S_t = s^2], \]</span> if and only if <span class="math inline">\(P\)</span> is stochatically monotone.</p>
</div>
</section>
<section id="monotonicity-of-value-functions" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="monotonicity-of-value-functions"><span class="header-section-number">6.3</span> Monotonicity of value functions</h2>
<div id="thm-monotone-value" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.3 </strong></span>Consider an MDP where the state space <span class="math inline">\(\ALPHABET S\)</span> is totally ordered. Suppose the following conditions are satisfied.</p>
<p>C1. For every <span class="math inline">\(a \in \ALPHABET A\)</span>, the per-step cost <span class="math inline">\(c_t(s,a)\)</span> is weakly inceasing in <span class="math inline">\(s\)</span>.</p>
<p>C2. For every <span class="math inline">\(a \in \ALPHABET A\)</span>, the transition matrix <span class="math inline">\(P(a)\)</span> is stochastically monotone.</p>
<p>Then, the value function <span class="math inline">\(V_t(s)\)</span> is weakly increasing in <span class="math inline">\(s\)</span>.</p>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The result above also applies to models with continuous (and totally ordered) state space provided the measurable selection conditions hold so that the arg min at each step of the dynamic program is attained.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We proceed by backward induction. By definition, <span class="math inline">\(V_{T+1}(s) = 0\)</span>, which is weakly increasing. This forms the basis of induction. Assume that <span class="math inline">\(V_{t+1}(s)\)</span> is weakly increasing. Now consider, <span class="math display">\[Q_t(s,a) = c_t(s,a) + \EXP[V_{t+1}(S_{t+1}) | S_t = s, A_t = a].\]</span> For any <span class="math inline">\(a \in \ALPHABET A\)</span>, <span class="math inline">\(Q_t(s,a)\)</span> is a sum of two weakly increasing functions in <span class="math inline">\(s\)</span>; hence <span class="math inline">\(Q_t(s,a)\)</span> is weakly increasing in <span class="math inline">\(s\)</span>.</p>
<p>Now consider <span class="math inline">\(s_1, s_2 \in \ALPHABET S\)</span> such that <span class="math inline">\(s_1 &gt; s_2\)</span>. Suppose <span class="math inline">\(a_1^*\)</span> is the optimal action at state <span class="math inline">\(s_1\)</span>. Then <span class="math display">\[
  V_t(s^1) = Q_t(s^1, a_1^*) \stackrel{(a)}\ge Q_t(s^2,a_1^*) \stackrel{(b)}\ge V_t(s_2),
\]</span> where <span class="math inline">\((a)\)</span> follows because <span class="math inline">\(Q_t(\cdot, u^*)\)</span> is weakly increasing and <span class="math inline">\((b)\)</span> follows from the definition of the value function.</p>
</div>
</div>
</div>
</section>
<section id="submodularity" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="submodularity"><span class="header-section-number">6.4</span> Submodularity</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Submodularity
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\(\ALPHABET X\)</span> and <span class="math inline">\(\ALPHABET Y\)</span> be partially ordered sets. A function <span class="math inline">\(f \colon \ALPHABET X \times \ALPHABET Y \to \reals\)</span> is called <em>submodular</em> if for any <span class="math inline">\(x^+ \ge x^-\)</span> and <span class="math inline">\(y^+ \ge y^-\)</span>, we have <span class="math display">\[\begin{equation}\label{eq:submodular}
  f(x^+, y^+) + f(x^-, y^-) \le f(x^+, y^-) + f(x^-, y^+).
\end{equation}\]</span></p>
<p>The function is called <em>supermodular</em> if the inequality in \eqref{eq:submodular} is reversed.</p>
</div>
</div>
<p>A continuous and differentiable function on <span class="math inline">\(\reals^2\)</span> is submodular iff <span class="math display">\[ \frac{ \partial^2 f(x,y) }{ \partial x \partial y } \le 0,
  \quad \forall x,y.
\]</span> If the inequality is reversed, then the function is supermodular.</p>
<p>Submodularity is a useful property because it implies monotonicity of the arg min.</p>
<div id="thm-submodular" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.4 </strong></span>Let <span class="math inline">\(\ALPHABET X\)</span> be a partially ordered set, <span class="math inline">\(\ALPHABET Y\)</span> be a totally ordered set, and <span class="math inline">\(f \colon \ALPHABET X \times \ALPHABET Y \to \reals\)</span> be a <em>submodular</em> function. Suppose that for all <span class="math inline">\(x\)</span>, <span class="math inline">\(\arg \min_{y \in \ALPHABET Y} f(x,y)\)</span> exists. Then, <span class="math display">\[
  π(x) := \max \{ y^* \in \arg \min_{y \in \ALPHABET Y} f(x,y) \}
\]</span> is weakly <em>increasing</em> in <span class="math inline">\(x\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Consider <span class="math inline">\(x^+, x^- \in \ALPHABET X\)</span> such that <span class="math inline">\(x^+ \ge x^-\)</span>. Since <span class="math inline">\(f\)</span> is submodular, for any <span class="math inline">\(y \le π(x^-)\)</span>, we have <span class="math display">\[\begin{equation}\label{eq:1}
  f(x^+, π(x^-)) - f(x^+, y) \le f(x^-, π(x^-)) - f(x^-, y) \le 0,
\end{equation}\]</span> where the last inequality follows because <span class="math inline">\(π(x^-)\)</span> is the arg min of <span class="math inline">\(f(x^-, y)\)</span>. Eq. \eqref{eq:1} implies that for all <span class="math inline">\(y \le π(x^-)\)</span>, <span class="math display">\[
  f(x^+, π(x^-)) \le f(x^+, y).
\]</span> Thus, <span class="math inline">\(π(x^+) \ge π(x^-)\)</span>.</p>
</div>
</div>
</div>
<p>The analogue of <a href="#thm-submodular">Theorem&nbsp;<span>6.4</span></a> for supermodular functions is as follows.</p>
<div id="thm-supermodular" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.5 </strong></span>Let <span class="math inline">\(\ALPHABET X\)</span> be a partially ordered set, <span class="math inline">\(\ALPHABET Y\)</span> be a totally ordered set, and <span class="math inline">\(f \colon \ALPHABET X \times \ALPHABET Y \to \reals\)</span> be a <em>supermodular</em> function. Suppose that for all <span class="math inline">\(x\)</span>, <span class="math inline">\(\arg \min_{y \in \ALPHABET Y} f(x,y)\)</span> exists. Then, <span class="math display">\[
  π(x) := \min \{ y^* \in \arg \min_{y \in \ALPHABET Y} f(x,y) \}
\]</span> is weakly <em>decreasing</em> in <span class="math inline">\(x\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof is similar to <a href="#thm-submodular">Theorem&nbsp;<span>6.4</span></a>.</p>
<p>Consider <span class="math inline">\(x^+, x^- \in \ALPHABET X\)</span> such that <span class="math inline">\(x^+ \ge x^-\)</span>. Since <span class="math inline">\(f\)</span> is supermodular, for any <span class="math inline">\(y \ge π(x^-)\)</span>, we have <span class="math display">\[\begin{equation}\label{eq:2}
  f(x^+, y) - f(x^+, π(x^-)) \ge f(x^-, y) - f(x^-, π(x^-)) \ge 0,
\end{equation}\]</span> where the last inequality follows because <span class="math inline">\(π(x^-)\)</span> is the arg min of <span class="math inline">\(f(x^-, y)\)</span>. Eq. \eqref{eq:2} implies that for all <span class="math inline">\(y \ge π(x^-)\)</span>, <span class="math display">\[
  f(x^+, y) \ge f(x^+, π(x^-)).
\]</span> Thus, <span class="math inline">\(π(x^+) \le π(x^-)\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="monotonicity-of-optimal-policy" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="monotonicity-of-optimal-policy"><span class="header-section-number">6.5</span> Monotonicity of optimal policy</h2>
<div id="thm-increasing-policy" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.6 </strong></span>Consider an MDP where the state space <span class="math inline">\(\ALPHABET S\)</span> and the action space <span class="math inline">\(\ALPHABET A\)</span> are totally ordered. Suppose that, in addition to (C1) and (C2), the following condition is satisfied.</p>
<p>C3. For any weakly increasing function <span class="math inline">\(v\)</span>, <span class="math display">\[ c_t(s,a) + \EXP[ v(S_{t+1}) | S_t = s, A_t = a]\]</span> is submodular in <span class="math inline">\((s,a)\)</span>.</p>
<p>Let <span class="math inline">\(π^*_t(s) = \max\{ a^* \in \arg \min_{a \in \ALPHABET A} Q_t(s,a) \}\)</span>. Then, <span class="math inline">\(π^*(s)\)</span> is weakly increasing in <span class="math inline">\(s\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Conditions (C1) and (C2) imply that the value function <span class="math inline">\(V_{t+1}(s)\)</span> is weakly increasing. Therefore, condition (C3) implies that <span class="math inline">\(Q_t(s,a)\)</span> is submodular in <span class="math inline">\((s,a)\)</span>. Therefore, the arg min is weakly increasing in <span class="math inline">\(x\)</span></p>
</div>
</div>
</div>
<p>It is difficult to verify condition (C3). The following conditions are sufficient for (C3).</p>
<div id="lem-sufficient-C3" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 6.1 </strong></span>Consider an MDP with totally ordered state and action spaces. Suppose</p>
<ol type="a">
<li><span class="math inline">\(c_t(s,a)\)</span> is submodular in <span class="math inline">\((s,a)\)</span>.</li>
<li>For all <span class="math inline">\(s' \in \ALPHABET S\)</span>, <span class="math inline">\(H(s' | s,a) = 1 - \sum_{z \le s'} P_{sz}(a)\)</span> is submodular in <span class="math inline">\((s,a)\)</span>.</li>
</ol>
<p>The condition (C3) of the previous theorem holds.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Consider <span class="math inline">\(s^+, s^- \in \ALPHABET S\)</span> and <span class="math inline">\(a^+, a^- \in \ALPHABET A\)</span> such that <span class="math inline">\(s^+ &gt; s^-\)</span> and <span class="math inline">\(a^+ &gt; a^-\)</span>. Define</p>
<p><span class="math display">\[\begin{align*}
  μ_1(s) &amp;= \tfrac 12 P_{s^- s}(a^-) + \tfrac 12 P_{s^+ s}(a^+), \\
  μ_2(s) &amp;= \tfrac 12 P_{s^- s}(a^+) + \tfrac 12 P_{s^+ s}(a^-).
\end{align*}\]</span> Since <span class="math inline">\(H(s' | s,a)\)</span> is submodular, we have <span class="math display">\[ H(s' | s^+, a^+) + H(s' | s^-, a^-) \le H(s' | s^+, a^-) + H(s' | s^-, a^+) \]</span> or equivalently, <span class="math display">\[\sum_{z \le s'} \big[ P_{s^+ z}(a^+) + P_{s^- z}(a^-) \big]
  \ge
  \sum_{z \le s'} \big[ P_{s^+ z}(a^-) + P_{s^- z}(a^+) \big]. \]</span> which implies <span class="math display">\[ M_1(s') \ge M_2(s')\]</span> where <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> are the CDFs of <span class="math inline">\(μ_1\)</span> and <span class="math inline">\(μ_2\)</span>. Thus, <span class="math inline">\(μ_1 \preceq_s μ_2\)</span>.</p>
<p>Hence, for any weakly increasing function <span class="math inline">\(v \colon \ALPHABET S \to \reals\)</span>, <span class="math display">\[ \sum_{s' \in \ALPHABET S} μ_1(s') v(s') \le
   \sum_{s' \in \ALPHABET S} μ_2(s') v(s').\]</span> Or, equivalently, <span class="math display">\[H(s^+, a^+) + H(s^-, a^-) \le H(s^-, a^+) + H(s^+, a^-)\]</span> where <span class="math inline">\(H(s,a) = \EXP[ v(X_{t+1}) | X_t = s, U_t = a]\)</span>.</p>
<p>Therefore, <span class="math inline">\(c_t(s,a) + H_t(s,a)\)</span> is submodular in <span class="math inline">\((s,a)\)</span>.</p>
</div>
</div>
</div>
<p>The analogue of <a href="#thm-increasing-policy">Theorem&nbsp;<span>6.6</span></a> for supermodular functions is as follows.</p>
<div id="thm-decreasing-policy" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.7 </strong></span>Consider an MDP where the state space <span class="math inline">\(\ALPHABET S\)</span> and the action space <span class="math inline">\(\ALPHABET A\)</span> are totally ordered. Suppose that, in addition to (C1) and (C2), the following condition is satisfied.</p>
<p>C4. For any weakly increasing function <span class="math inline">\(v\)</span>, <span class="math display">\[ c_t(s,a) + \EXP[ v(S_{t+1}) | S_t = s, A_t = a]\]</span> is supermodular in <span class="math inline">\((s,a)\)</span>.</p>
<p>Let <span class="math inline">\(π^*_t(s) = \min\{ a^* \in \arg \min_{a \in \ALPHABET S} Q_t(s,a) \}\)</span>. Then, <span class="math inline">\(π^*(s)\)</span> is weakly decreasing in <span class="math inline">\(s\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Conditions (C1) and (C2) imply that the value function <span class="math inline">\(V_{t+1}(s)\)</span> is weakly increasing. Therefore, condition (C4) implies that <span class="math inline">\(Q_t(s,a)\)</span> is supermodular in <span class="math inline">\((s,a)\)</span>. Therefore, the arg min is decreasing in <span class="math inline">\(s\)</span></p>
</div>
</div>
</div>
<p>It is difficult to verify condition (C4). The following conditions are sufficient for (C4).</p>
<div id="lem-sufficient-C4" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 6.2 </strong></span>Consider an MDP with totally ordered state and action spaces. Suppose</p>
<ol type="a">
<li><span class="math inline">\(c_t(s,a)\)</span> is supermodular in <span class="math inline">\((s,a)\)</span>.</li>
<li>For all <span class="math inline">\(s' \in \ALPHABET S\)</span>, <span class="math inline">\(H(s' | s,a) = 1 - \sum_{z \le s'} P_{sz}(a)\)</span> is supermodular in <span class="math inline">\((s,a)\)</span>.</li>
</ol>
<p>The condition (C4) of the previous theorem holds.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Consider <span class="math inline">\(s^+, s^- \in \ALPHABET S\)</span> and <span class="math inline">\(a^+, a^- \in \ALPHABET A\)</span> such that <span class="math inline">\(s^+ &gt; s^-\)</span> and <span class="math inline">\(a^+ &gt; a^-\)</span>. Define</p>
<p><span class="math display">\[\begin{align*}
  μ_1(s) &amp;= \tfrac 12 P_{s^- s}(a^-) + \tfrac 12 P_{s^+ s}(a^+), \\
  μ_2(s) &amp;= \tfrac 12 P_{s^- s}(a^+) + \tfrac 12 P_{s^+ s}(a^-).
\end{align*}\]</span> Since <span class="math inline">\(H(s' | s,a)\)</span> is supermodular, we have <span class="math display">\[ H(s' | s^+, a^+) + H(s' | s^-, a^-) \ge H(s' | s^+, a^-) + H(s' | s^-, a^+) \]</span> or equivalently, <span class="math display">\[\sum_{s' \le s'} \big[ P_{s^+ s'}(a^+) + P_{s^- s'}(a^-) \big]
  \le
  \sum_{s' \le s'} \big[ P_{s^+ s'}(a^-) + P_{s^- s'}(a^+) \big]. \]</span> which implies <span class="math display">\[ M_1(s') \le M_2(s')\]</span> where <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> are the CDFs of <span class="math inline">\(μ_1\)</span> and <span class="math inline">\(μ_2\)</span>. Thus, <span class="math inline">\(μ_1 \succeq_s μ_2\)</span>.</p>
<p>Hence, for any weakly increasing function <span class="math inline">\(v \colon \ALPHABET S \to \reals\)</span>, <span class="math display">\[ \sum_{s' \in \ALPHABET S} μ_1(s') v(s') \ge
   \sum_{s' \in \ALPHABET S} μ_2(s') v(s').\]</span> Or, equivalently, <span class="math display">\[H(s^+, a^+) + H(s^-, a^-) \ge H(s^-, a^+) + H(s^+, a^-)\]</span> where <span class="math inline">\(H(s,a) = \EXP[ v(X_{t+1}) | X_t = s, U_t = a]\)</span>.</p>
<p>Therefore, <span class="math inline">\(c_t(s,a) + H_t(s,a)\)</span> is supermodular in <span class="math inline">\((s,a)\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="constraints-on-actions" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="constraints-on-actions"><span class="header-section-number">6.6</span> Constraints on actions</h2>
<p>In the results above, we have assumed that the action set <span class="math inline">\(\ALPHABET A\)</span> is the same for all states. The results also extend to the case when the action at state <span class="math inline">\(s\)</span> must belong to some set <span class="math inline">\(\ALPHABET A(s)\)</span> provided the following conditions are satisfied:</p>
<ol type="1">
<li>For any <span class="math inline">\(s \ge s'\)</span>, <span class="math inline">\(\ALPHABET A(s) \supseteq \ALPHABET A(s')\)</span></li>
<li>For any <span class="math inline">\(s \in \ALPHABET S\)</span> and <span class="math inline">\(a \in \ALPHABET A(s)\)</span>, <span class="math inline">\(a' &lt; a\)</span> implies that <span class="math inline">\(a' \in \ALPHABET A(s)\)</span>.</li>
</ol>
</section>
<section id="monotone-dynamic-programming" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="monotone-dynamic-programming"><span class="header-section-number">6.7</span> Monotone dynamic programming</h2>
<p>If we can establish that the optimal policy is monontone, then we can use this structure to implement the dynamic program more efficient. Suppose <span class="math inline">\(\ALPHABET S = \{1, \dots, n\}\)</span> and <span class="math inline">\(\ALPHABET A = \{1, \dots. m\}\)</span>. The main idea is as follows. Suppose <span class="math inline">\(V_{t+1}(\cdot)\)</span> has been caclulated. Insead of computing <span class="math inline">\(Q_t(s,a)\)</span> and <span class="math inline">\(V_t(s)\)</span>, proceed as follows:</p>
<ol type="1">
<li><p>Set <span class="math inline">\(s = 1\)</span> and <span class="math inline">\(α = 1\)</span>.</p></li>
<li><p>For all <span class="math inline">\(u \in \{α, \dots, m\}\)</span>, compute <span class="math inline">\(Q_t(s,a)\)</span> as usual.</p></li>
<li><p>Compute</p>
<p><span class="math display">\[V_t(s) = \min_{ α \le a \le m } Q_t(s,a)\]</span></p>
<p>and set</p>
<p><span class="math display">\[π_t^*(s) = \max \{ a \in \{α, \dots, m\} : V_t(s) = Q_t(s,a) \}.\]</span></p></li>
<li><p>If <span class="math inline">\(s = n\)</span>, then stop. Otherwise, set <span class="math inline">\(α = π_t^*(s)\)</span> and <span class="math inline">\(s = s+1\)</span> and go to step&nbsp;2.</p></li>
</ol>
</section>
<section id="example-a-machine-replacement-model" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="example-a-machine-replacement-model"><span class="header-section-number">6.8</span> Example: A machine replacement model</h2>
<p>Let’s revisit the machine replacement problem presented at the beginning of this section. For simplicity, we’ll assume that <span class="math inline">\(n = ∞\)</span>, i.e., the state space is countable. In this case, the transition matrices are given by <span class="math display">\[ P_{sz}(0) = \begin{cases}
  0, &amp; z &lt; s \\
  μ_{z - s}, &amp; z \ge s
\end{cases}
\quad\text{and}\quad
P_sz(1) = μ_z.
\]</span> where <span class="math inline">\(μ\)</span> is the PMF of <span class="math inline">\(W\)</span>.</p>
<div id="prp-machine-replacement" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 6.1 </strong></span>For the machine replacement problem, there exist a series of thresholds <span class="math inline">\(\{s^*_t\}_{t = 1}^T\)</span> such that the optimal policy at time <span class="math inline">\(t\)</span> is a threshold policy with threshold <span class="math inline">\(s_t\)</span>, i.e., <span class="math display">\[
  π_t(s) = \begin{cases}
  0 &amp; \text{if $s &lt; s_t^*$} \\
  1 &amp; \text{otherwise}
\end{cases}\]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We prove the result by verifying conditions (C1)–(C4) to establish that the optimal policy is monotone.</p>
<p>C1. For <span class="math inline">\(a = 0\)</span>, <span class="math inline">\(c(s,0) = h(s)\)</span>, which is weakly increasing by assumption. For <span class="math inline">\(a = 1\)</span>, <span class="math inline">\(c(s,1) = K\)</span>, which is trivially weakly increasing.</p>
<p>C2. For <span class="math inline">\(a = 0\)</span>, <span class="math inline">\(P(0)\)</span> is stochastically monotone (because the CDF of <span class="math inline">\(P(\cdot | s, 0)\)</span> lies above the CDF of <span class="math inline">\(P(\cdot | s+1, 0)\)</span>). For <span class="math inline">\(a = 1\)</span>, all rows of <span class="math inline">\(P(1)\)</span> are the same; therefore <span class="math inline">\(P(1)\)</span> is stochastically monotone.</p>
<p>Since (C1) and (C2) are satisfied, by <a href="#thm-monotone-value">Theorem&nbsp;<span>6.3</span></a>, we can assert that the value function is weakly increasing.</p>
<p>C3. <span class="math inline">\(c(s,1) - c(s,0) = K - h(s)\)</span>, which is weakly decreasing in <span class="math inline">\(s\)</span>. Therefore, <span class="math inline">\(c(s,a)\)</span> is submodular in <span class="math inline">\((s,a)\)</span>.</p>
<p>C4. Recall that <span class="math inline">\(H(s'|s,a) = 1 - \sum_{z \le s'} P_{sz}(a).\)</span> Therefore,</p>
<p><span class="math display">\[H(s'|s,0) = 1 - \sum_{z = s}^{s'} μ_{z -s} = 1 - \sum_{k = 0}^{s' - s} μ_k
= 1 - M_{s' - s},\]</span> where <span class="math inline">\(M\)</span> is the CMF of <span class="math inline">\(μ\)</span>, and <span class="math display">\[H(s'|s,1) = 1 - \sum_{z \le s'} μ_z = 1 - M_{s'},\]</span></p>
<p>Therefore, <span class="math inline">\(H(s'|s,1) - H(s'|s,0) = M_{s'-s} - M_{s'}\)</span>. For any fixed <span class="math inline">\(s'\)</span>, <span class="math inline">\(H(s'|s,1) - H(s'|s,0)\)</span> is weakly decreasing in <span class="math inline">\(s\)</span>. There <span class="math inline">\(H(s'|s,a)\)</span> is submodular in <span class="math inline">\((s,a)\)</span>.</p>
<p>Since (C1)–(C4) are satisfied, the optimal policy is weakly increasing in~<span class="math inline">\(s\)</span>. Since there are only two actions, it means that for every time, there exists a state <span class="math inline">\(s^*_t\)</span> with the property that if <span class="math inline">\(s\)</span> exceeds <span class="math inline">\(s^*_t\)</span>, the optimal decision is to replace the machine; and if <span class="math inline">\(s \le s^*_t\)</span>, then the optimal decision is to operate the machine for another period.</p>
</div>
</div>
</div>
<hr>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div id="exr-sd-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.1 </strong></span>Let <span class="math inline">\(T\)</span> denote a upper triangular matrix with 1’s on or below the diagonal and 0’s above the diagonal. Then <span class="math display">\[ T^{-1}_{ij} = \begin{cases}
  1, &amp; \text{if } i = j, \\
-1, &amp; \text{if } i = j + 1, \\
  0, &amp; \text{otherwise}.
\end{cases}\]</span></p>
<p>For example, for a <span class="math inline">\(4 \times 4\)</span> matrix <span class="math display">\[
  T = \MATRIX{1 &amp; 1 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1},
  \quad
  T^{-1} = \MATRIX{1 &amp; -1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; -1 \\
  0 &amp; 0 &amp; 0 &amp; 1 }.
\]</span></p>
<p>Show the following:</p>
<ol type="a">
<li>For any two PMFs <span class="math inline">\(μ^1\)</span> and <span class="math inline">\(μ^2\)</span>, <span class="math inline">\(\mu^1 \succeq_s \mu^2\)</span> iff <span class="math inline">\(\mu^1 T \ge \mu^2 T\)</span>.</li>
<li>A Markov transition matrix <span class="math inline">\(P\)</span> is stochastic monotone iff <span class="math inline">\(T^{-1} P T \ge 0\)</span>.</li>
</ol>
</div>
<div id="exr-sd-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.2 </strong></span>Show that the following are equivalent:</p>
<ol type="a">
<li>A transition matrix <span class="math inline">\(P\)</span> is stochastically monotone</li>
<li>For any two PMFs <span class="math inline">\(μ^1\)</span> and <span class="math inline">\(μ^2\)</span>, if <span class="math inline">\(\mu^1 \succeq_s \mu^2\)</span> then <span class="math inline">\(\mu^1P \succeq_s \mu^2P\)</span>.</li>
</ol>
</div>
<div id="exr-sd-3" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.3 </strong></span>Show that if two transition matrices <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> have the same dimensions and are stochastically monotone, then so are:</p>
<ol type="a">
<li><span class="math inline">\(\lambda P + (1 - \lambda) Q\)</span>, where <span class="math inline">\(\lambda \in (0,1)\)</span>.</li>
<li><span class="math inline">\(P Q\)</span></li>
<li><span class="math inline">\(P^k\)</span>, for <span class="math inline">\(k \in \integers_{&gt; 0}\)</span>.</li>
</ol>
</div>
<div id="exr-sd-4" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.4 </strong></span>Let <span class="math inline">\(\mu_t\)</span> denote the distribution of a Markov chain at time <span class="math inline">\(t\)</span>. Suppose <span class="math inline">\(\mu_0 \succeq_s \mu_1\)</span>. Then <span class="math inline">\(\mu_t \succeq_s \mu_{t+1}\)</span>.</p>
</div>
<!--FIXME-->
<div id="exr-monotone-machine-repair" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.5 </strong></span>Consider the example of machine repair presented in notes on <a href="../mdp-matrix#an-example-machine-repair">matrix formulation of MDPs</a>. Prove that the optimal policy for that model is weakly increasing.</p>
</div>
<div id="exr-folded-monotonicity" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 6.6 </strong></span>Suppose the state space <span class="math inline">\(\ALPHABET S\)</span> is a symmetric subset of integers of the form <span class="math inline">\(\{-L, -L + 1, \dots, L-1, L\}\)</span> and the action space <span class="math inline">\(\ALPHABET A\)</span> is discrete. Let <span class="math inline">\(\ALPHABET X_{\ge 0}\)</span> denote the set <span class="math inline">\(\{0, \dots, L\}\)</span>.</p>
<p>Let <span class="math inline">\(P(a)\)</span> denote the controlled transition matrix and <span class="math inline">\(c_t(s,a)\)</span> denote the per-step cost. To avoid ambiguity, we define the optimal policy as <span class="math display">\[
π^*_t(s) = \begin{cases}
    \max\bigl\{ a' \in \arg\min_{a \in \ALPHABET A} Q_t(s,a) \bigr\},
    &amp; \text{if } s \ge 0 \\
    \min\bigl\{ a' \in \arg\min_{a \in \ALPHABET A} Q_t(s,a) \bigr\},
    &amp; \text{if } s &lt; 0
\end{cases}\]</span> The purpose of this exercise is to identify conditions under which the value function and the optimal policy are even and <a href="https://en.wikipedia.org/wiki/Quasiconvex_function">:quasi-convex</a>. We do so using the following steps.</p>
<ol type="a">
<li>We say that the transition probability matrix <span class="math inline">\(P(a)\)</span> is even if for all <span class="math inline">\(s, s' \in \ALPHABET S\)</span>, <span class="math inline">\(P(s'|s,a) = P(-s'|-s,a)\)</span>. Prove the following result.</li>
</ol>
<div id="prp-even-value" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 6.2 </strong></span>Suppose the MDP satisfies the following properties:</p>
<p>(A1) For every <span class="math inline">\(t\)</span> and <span class="math inline">\(a \in \ALPHABET A\)</span>, <span class="math inline">\(c_t(s,a)\)</span> is even function of <span class="math inline">\(s\)</span>.</p>
<p>(A2) For every <span class="math inline">\(a \in \ALPHABET A\)</span>, <span class="math inline">\(P(a)\)</span> is even.</p>
<p>Then, for all <span class="math inline">\(t\)</span>, <span class="math inline">\(V_t\)</span> and <span class="math inline">\(π_t\)</span> are even functions.</p>
</div>
<ol start="2" type="a">
<li>Given any probability mass function <span class="math inline">\(μ\)</span> on <span class="math inline">\(\ALPHABET S\)</span>, define the <em>folded</em> probability mass function <span class="math inline">\(\tilde μ\)</span> on <span class="math inline">\(\ALPHABET X_{\ge 0}\)</span> as follows: <span class="math display">\[ \tilde μ(s) = \begin{cases}
   μ(0), &amp; \text{if } s = 0 \\
   μ(s) + μ(-s), &amp; \text{if } s &gt; 0.
\end{cases} \]</span></li>
</ol>
<p>For ease of notation, we use <span class="math inline">\(\tilde μ = \mathcal F μ\)</span> to denote this folding operation. Note that an immediate consequence of the definition is the following (you don’t have to prove this).</p>
<div id="lem-folded-sum" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 6.3 </strong></span>If <span class="math inline">\(f \colon \ALPHABET S \to \reals\)</span> is even, then for any probability mass function <span class="math inline">\(μ\)</span> on <span class="math inline">\(\ALPHABET S\)</span> and <span class="math inline">\(\tilde μ = \mathcal F μ\)</span>, we have <span class="math display">\[
  \sum_{s \in \ALPHABET S} f(s) μ(s) =
  \sum_{s \in \ALPHABET X_{\ge 0}} f(s) \tilde μ(s). \]</span></p>
</div>
<p>Thus, the expectation of the function <span class="math inline">\(f \colon \ALPHABET S \to \reals\)</span> with respect to the PMF <span class="math inline">\(μ\)</span> is equal to the expectation of the function <span class="math inline">\(f \colon \ALPHABET X_{\ge 0} \to \reals\)</span> with respect to the PMF <span class="math inline">\(\tilde μ = \mathcal F μ\)</span>.</p>
<p>Now given any probability transition matrix <span class="math inline">\(P\)</span> on <span class="math inline">\(\ALPHABET S\)</span>, we can define a probability transition matrix <span class="math inline">\(\tilde P\)</span> on <span class="math inline">\(\ALPHABET X_{\ge 0}\)</span> as follows: for any <span class="math inline">\(s \in \ALPHABET S\)</span>, <span class="math inline">\(\tilde P_s = \mathcal F P_s\)</span>, where <span class="math inline">\(P_s\)</span> denotes the <span class="math inline">\(s\)</span>-th row of <span class="math inline">\(P\)</span>. For ease of notation, we use <span class="math inline">\(\tilde P = \mathcal F P\)</span> to denote this relationship.</p>
<p>Now prove the following:</p>
<div id="prp-folded-monotonicity" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 6.3 </strong></span>Given the MDP <span class="math inline">\((\ALPHABET S, \ALPHABET A, P, \{c_t\})\)</span>, define the <em>folded</em> MDP as <span class="math inline">\((\ALPHABET S_{\ge 0}, \ALPHABET A, \tilde P, \{c_t\})\)</span>, where <span class="math inline">\(\tilde P(a) = \mathcal F P(a)\)</span> for all <span class="math inline">\(a \in \ALPHABET A\)</span>. Let <span class="math inline">\(\tilde Q_t \colon \ALPHABET S_{\ge 0} \times \ALPHABET A \to \reals\)</span>, <span class="math inline">\(\tilde V_t \colon \ALPHABET S_{\ge 0} \to \reals\)</span> and <span class="math inline">\(\tilde π_t^* \colon \ALPHABET S_{\ge 0} \to \ALPHABET A\)</span> denote the action-value function, value function and the policy of the folded MDP. Then, if the original MDP satisfies conditions (A1) and (A2) then, for any <span class="math inline">\(s \in \ALPHABET S\)</span> and <span class="math inline">\(a \in \ALPHABET A\)</span>, <span class="math display">\[ Q_t(s,a) = \tilde Q_t(|s|, a),
\quad
  V_t(s) = \tilde V_t(|s|),
\quad
  π_t^*(s) = \tilde π_t^*(|s|).
\]</span></p>
</div>
<ol start="3" type="a">
<li><p>The result of the previous part implies that if the value function <span class="math inline">\(\tilde V_t\)</span> and the policy <span class="math inline">\(\tilde π^*_t\)</span> are monotone increasing, then the value function <span class="math inline">\(V_t\)</span> and the policy <span class="math inline">\(π^*_t\)</span> are even and quasi-convex. This gives us a method to verify if the value function and optimal policy are even and quasi-convex.</p>
<p>Now, recall the model of the Internet of Things presented in Q2 of <a href="../../assignments/03">Assignment 3</a>. The numerical experiments that you did in Assignment 3 suggest that the value function and the optimal policy are even and quasi-convex. Prove that this is indeed the case.</p></li>
<li><p>Now suppose the distribution of <span class="math inline">\(W_t\)</span> is not Gaussian but is some general probability density <span class="math inline">\(\varphi(\cdot)\)</span> and the cost function is <span class="math display">\[ c(e,a) = \lambda a + (1 - a) d(e). \]</span> Find conditions on <span class="math inline">\(\varphi\)</span> and <span class="math inline">\(d\)</span> such that the value function and optimal policy are even and quasi-convex.</p></li>
</ol>
</div>
</section>
<section id="notes" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="notes">Notes</h2>
<p>Stochastic dominance has been employed in various areas of economics, finance, and statistics since the 1930s. See <span class="citation" data-cites="Levy1992">Levy (<a href="../references.html#ref-Levy1992" role="doc-biblioref">1992</a>)</span> and <span class="citation" data-cites="Levy2015">Levy (<a href="../references.html#ref-Levy2015" role="doc-biblioref">2015</a>)</span> for detailed overviews. The notion of stochastic monotonicity for Markov chains is due to <span class="citation" data-cites="Daley1968">Daley (<a href="../references.html#ref-Daley1968" role="doc-biblioref">1968</a>)</span>. For a generalization of stochastic monotonicity to continuous state spaces, see <span class="citation" data-cites="Serfozo1976">Serfozo (<a href="../references.html#ref-Serfozo1976" role="doc-biblioref">1976</a>)</span>. The characterization of stochastic monotonicity in <a href="#exr-sd-1">Exercise&nbsp;<span>6.1</span></a>–<a href="#exr-sd-4">Exercise&nbsp;<span>6.4</span></a> are due to <span class="citation" data-cites="Keilson1977">Keilson and Kester (<a href="../references.html#ref-Keilson1977" role="doc-biblioref">1977</a>)</span>.</p>
<p><span class="citation" data-cites="Ross1974">Ross (<a href="../references.html#ref-Ross1974" role="doc-biblioref">1974</a>)</span> has an early treatment of monotonicity of optimal policies. The general theory was developed by <span class="citation" data-cites="Topkis1998">Topkis (<a href="../references.html#ref-Topkis1998" role="doc-biblioref">1998</a>)</span>. The presentation here follows <span class="citation" data-cites="Puterman2014">Puterman (<a href="../references.html#ref-Puterman2014" role="doc-biblioref">2014</a>)</span>. <a href="#exr-folded-monotonicity">Exercise&nbsp;<span>6.6</span></a> is from <span class="citation" data-cites="Chakravorty2018">Chakravorty and Mahajan (<a href="../references.html#ref-Chakravorty2018" role="doc-biblioref">2018</a>)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Chakravorty2018" class="csl-entry" role="listitem">
<span class="smallcaps">Chakravorty, J. and Mahajan, A.</span> 2018. Sufficient conditions for the value function and optimal strategy to be even and quasi-convex. <em>IEEE Transactions on Automatic Control</em> <em>63</em>, 11, 3858–3864. DOI: <a href="https://doi.org/10.1109/TAC.2018.2800796">10.1109/TAC.2018.2800796</a>.
</div>
<div id="ref-Daley1968" class="csl-entry" role="listitem">
<span class="smallcaps">Daley, D.J.</span> 1968. Stochastically monotone markov chains. <em>Zeitschrift f<span>ü</span>r Wahrscheinlichkeitstheorie und verwandte Gebiete</em> <em>10</em>, 4, 305–317. DOI: <a href="https://doi.org/10.1007/BF00531852">10.1007/BF00531852</a>.
</div>
<div id="ref-Keilson1977" class="csl-entry" role="listitem">
<span class="smallcaps">Keilson, J. and Kester, A.</span> 1977. Monotone matrices and monotone markov processes. <em>Stochastic Processes and their Applications</em> <em>5</em>, 3, 231–241.
</div>
<div id="ref-Levy1992" class="csl-entry" role="listitem">
<span class="smallcaps">Levy, H.</span> 1992. Stochastic dominance and expected utility: Survey and analysis. <em>Management Science</em> <em>38</em>, 4, 555–593. DOI: <a href="https://doi.org/10.1287/mnsc.38.4.555">10.1287/mnsc.38.4.555</a>.
</div>
<div id="ref-Levy2015" class="csl-entry" role="listitem">
<span class="smallcaps">Levy, H.</span> 2015. <em>Stochastic dominance: Investment decision making under uncertainty</em>. Springer. DOI: <a href="https://doi.org/10.1007/978-3-319-21708-6">10.1007/978-3-319-21708-6</a>.
</div>
<div id="ref-Puterman2014" class="csl-entry" role="listitem">
<span class="smallcaps">Puterman, M.L.</span> 2014. <em>Markov decision processes: Discrete stochastic dynamic programming</em>. John Wiley &amp; Sons. DOI: <a href="https://doi.org/10.1002/9780470316887">10.1002/9780470316887</a>.
</div>
<div id="ref-Ross1974" class="csl-entry" role="listitem">
<span class="smallcaps">Ross, S.M.</span> 1974. Dynamic programming and gambling models. <em>Advances in Applied Probability</em> <em>6</em>, 3, 593–606. DOI: <a href="https://doi.org/10.2307/1426236">10.2307/1426236</a>.
</div>
<div id="ref-Serfozo1976" class="csl-entry" role="listitem">
<span class="smallcaps">Serfozo, R.F.</span> 1976. Monotone optimal policies for markov decision processes. In: <em>Mathematical programming studies</em>. Springer Berlin Heidelberg, 202–215. DOI: <a href="https://doi.org/10.1007/bfb0120752">10.1007/bfb0120752</a>.
</div>
<div id="ref-Topkis1998" class="csl-entry" role="listitem">
<span class="smallcaps">Topkis, D.M.</span> 1998. <em>Supermodularity and complementarity</em>. Princeton University Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
{"contents":[{"methodName":"interpret","cellName":"ojs-cell-1","inline":false,"source":"T = 20\nn = 10\nc = 2\nK = 20\nh = function(s) { return c*s }\n\nPw = {\n  const n = 10\n  \n  var points = new Array(n+1)\n  var cumulative = 0\n  var probability = 0\n\n  for(var k = 0; k <= n; k++) {\n    probability = binomial(n,k,p)\n    cumulative += probability\n    points[k] = { probability: probability, cumulative: cumulative }\n  }\n\n  return points\n}\n\nbinomial = {\n  // From https://stackoverflow.com/a/37715980/193149\n  const logf = [0, 0, 0.6931471805599453, 1.791759469228055, 3.1780538303479458, 4.787491742782046, 6.579251212010101, 8.525161361065415, 10.60460290274525, 12.801827480081469, 15.104412573075516, 17.502307845873887, 19.987214495661885, 22.552163853123425, 25.19122118273868, 27.89927138384089, 30.671860106080672, 33.50507345013689, 36.39544520803305, 39.339884187199495, 42.335616460753485, 45.38013889847691, 48.47118135183523, 51.60667556776438, 54.78472939811232, 58.00360522298052, 61.261701761002, 64.55753862700634, 67.88974313718154, 71.25703896716801, 74.65823634883016, 78.0922235533153, 81.55795945611504, 85.05446701758152, 88.58082754219768, 92.1361756036871, 95.7196945421432, 99.33061245478743, 102.96819861451381, 106.63176026064346, 110.32063971475739, 114.0342117814617, 117.77188139974507, 121.53308151543864, 125.3172711493569, 129.12393363912722, 132.95257503561632, 136.80272263732635, 140.67392364823425, 144.5657439463449, 148.47776695177302, 152.40959258449735, 156.3608363030788, 160.3311282166309, 164.32011226319517, 168.32744544842765,  172.3527971391628, 176.39584840699735, 180.45629141754378, 184.53382886144948, 188.6281734236716, 192.7390472878449, 196.86618167289, 201.00931639928152, 205.1681994826412, 209.34258675253685, 213.53224149456327, 217.73693411395422, 221.95644181913033, 226.1905483237276, 230.43904356577696, 234.70172344281826, 238.97838956183432, 243.2688490029827, 247.57291409618688, 251.8904022097232, 256.22113555000954, 260.5649409718632, 264.9216497985528, 269.2910976510198, 273.6731242856937, 278.0675734403661, 282.4742926876304, 286.893133295427, 291.3239500942703, 295.76660135076065, 300.22094864701415, 304.6868567656687, 309.1641935801469, 313.65282994987905, 318.1526396202093, 322.66349912672615, 327.1852877037752, 331.7178871969285, 336.26118197919845, 340.815058870799, 345.37940706226686, 349.95411804077025, 354.5390855194408, 359.1342053695754, 363.73937555556347]\n\n  return function(n, k, p) {\n      return Math.exp(logf[n] - logf[n-k] - logf[k]) * p**k * (1-p)**(n-k)\n  }\n}\n\nDP = {\n  var DP = new Array()\n  var idx = 0\n\n  var V = new Array(n+1)\n  var Q0 = new Array(n+1)\n  var Q1 = new Array(n+1)\n\n  var a = 0\n  var val = 0\n\n  // Initialize the terminal value function\n  for (var s = 0; s <= n; s++) {\n    V[1+s] = 0\n  }\n\n  // Dynamic Programming\n  for (var t = T; t >= 1; t--) {\n    //Q0[s] = h[s] + E[ V(s+W) ]\n    //Q1[s] = K + E[ V(W) ]\n    for (var s = 0; s <= n; s++) {\n      Q0[1+s] = h(s)\n      Q1[1+s] = K\n      for (var w=0; w <= n; w++) {\n        var s_next = Math.min(s+w, n)\n        Q0[1+s] += V[ 1 + s_next ]*Pw[w].probability \n        Q1[1+s] += V[ 1 + w ]*Pw[w].probability \n      }\n    }\n\n    for (var s = 0; s <= n; s++) {\n      if (Q0[1+s] <= Q1[1+s]) {\n         a = 0\n         val = Q0[1+s]\n      } else {\n         a = 1\n         val = Q1[1+s]\n      }\n      DP[idx++] = { time: t, state: s, value: val, action: a }\n      V[1+s] = val\n    }\n  }\n\n  return DP;\n}\n"},{"methodName":"interpret","cellName":"ojs-cell-2","inline":false,"source":"viewof p = Inputs.range([0.1, 0.95], {label: \"p\", step: 0.1})\ntime = 1\n"},{"methodName":"interpret","cellName":"ojs-cell-3","inline":false,"source":"\nvalue_plot = Plot.plot({\n  grid: true,\n  y: {domain: [120,380]},\n  marks: [\n    // Axes\n    Plot.ruleX([0]),\n    // Plot.ruleY([0]),\n    // Data\n    Plot.line(DP.filter(d => d.time == time), {x:\"state\", y:\"value\", curve:\"step-after\"})\n  ]\n})\n\naction_plot = Plot.plot({\n  grid: true,\n  y : {ticks: 1 },\n  marks: [\n    // Axes\n    Plot.ruleX([0]),\n    Plot.ruleY([0]),\n    // Data\n    Plot.ruleX(DP.filter(d => d.time == time), {x: \"state\", y: \"action\", strokeWidth: 2}),\n    Plot.dot(DP.filter(d => d.time == time), {x: \"state\", y: \"action\", fill: \"currentColor\", r: 4})\n  ]\n})\n"},{"methodName":"interpretQuiet","source":"shinyInput('p')"}]}
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../mdps";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../mdps/inventory-management.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inventory Management</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../mdps/power-delay-tradeoff.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>