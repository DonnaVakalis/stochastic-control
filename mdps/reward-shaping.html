<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aditya Mahajan">
<meta name="dcterms.date" content="2023-08-03">
<meta name="keywords" content="reward shaping">
<meta name="description" content="ECES 506 (Stochastic Control and Decision Theory)">

<title>Course Notes - 8&nbsp; Reward Shaping</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../mdps/inf-horizon.html" rel="next">
<link href="../mdps/power-delay-tradeoff.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      IND: "\\mathbb{I}",
      ONES: "\\mathbb{1}",
      reals: "\\mathbb{R}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      BELLMAN: "\\mathcal{B}",
      MISMATCH: "\\mathcal{D}",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      NORM: ["\\left\\lVert #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert #1 \\right\\rvert", 1],
      GRAD: "\\nabla"
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="citation_title" content="[8]{.chapter-number}&nbsp; [Reward Shaping]{.chapter-title}">
<meta name="citation_keywords" content="reward shaping">
<meta name="citation_author" content="Aditya Mahajan">
<meta name="citation_publication_date" content="2023-08-03">
<meta name="citation_cover_date" content="2023-08-03">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-08-03">
<meta name="citation_fulltext_html_url" content="https://adityam.github.io/stochastic-control//mdps/reward-shaping.html">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Course notes for ECSE 506 (Stochastic Control and Decision Theorey)">
<meta name="citation_reference" content="citation_title=A new interpretation of information rate;,citation_author=John L. Kelly;,citation_publication_date=1956-07;,citation_cover_date=1956-07;,citation_year=1956;,citation_issue=4;,citation_doi=10.1002/j.1538-7305.1956.tb03809.x;,citation_volume=35;,citation_journal_title=Bell System Technical Journal;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic programming and gambling models;,citation_author=Sheldon M. Ross;,citation_publication_date=1974-09;,citation_cover_date=1974-09;,citation_year=1974;,citation_issue=3;,citation_doi=10.2307/1426236;,citation_volume=6;,citation_journal_title=Advances in Applied Probability;,citation_publisher=Applied Probability Trust;">
<meta name="citation_reference" content="citation_title=Optimal inventory policy;,citation_author=Kenneth J Arrow;,citation_author=Theodore Harris;,citation_author=Jacob Marschak;,citation_publication_date=1952-01;,citation_cover_date=1952-01;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/1907830;,citation_volume=20;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=On the optimal inventory equation;,citation_author=Richard Bellman;,citation_author=Irving Glicksberg;,citation_author=Oliver Gross;,citation_publication_date=1955-10;,citation_cover_date=1955-10;,citation_year=1955;,citation_issue=1;,citation_doi=10.1287/mnsc.2.1.83;,citation_volume=2;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Memoryless strategies in finite-stage dynamic programming;,citation_author=David Blackwell;,citation_publication_date=1964-06;,citation_cover_date=1964-06;,citation_year=1964;,citation_issue=2;,citation_doi=10.1214/aoms/1177703586;,citation_volume=35;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=On the structure of real-time source coders;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=6;,citation_volume=58;,citation_journal_title=Bell System Technical Journal;">
<meta name="citation_reference" content="citation_title=Contributions to the theory of optimal control;,citation_author=Rudolf Emil Kalman;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_volume=5;,citation_journal_title=Boletin de la Sociedad Matematica Mexicana;">
<meta name="citation_reference" content="citation_title=Dynamic programming under uncertainty with a quadratic criterion function;,citation_author=Herbert A Simon;,citation_publication_date=1956-01;,citation_cover_date=1956-01;,citation_year=1956;,citation_issue=1;,citation_doi=10.2307/1905261;,citation_volume=24;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Econometric models and welfare maximization;,citation_author=Henri Theil;,citation_publication_date=1954;,citation_cover_date=1954;,citation_year=1954;,citation_doi=10.1007/978-94-011-2410-2_1;,citation_volume=72;,citation_journal_title=Wirtschaftliches Archiv;">
<meta name="citation_reference" content="citation_title=A note on certainty equivalence in dynamic planning;,citation_author=Henri Theil;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_doi=10.1007/978-94-011-2410-2_3;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Power and delay trade-offs in fading channels;,citation_author=Randall Alexander Berry;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_fulltext_html_url=https://dspace.mit.edu/handle/1721.1/9290;,citation_dissertation_institution=Massachusetts Institute of Technology;">
<meta name="citation_reference" content="citation_title=Communication over fading channels with delay constraints;,citation_author=Randall A Berry;,citation_author=Robert G Gallager;,citation_publication_date=2002-05;,citation_cover_date=2002-05;,citation_year=2002;,citation_issue=5;,citation_doi=10.1109/18.995554;,citation_volume=48;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal power-delay tradeoffs in fading channels—small-delay asymptotics;,citation_author=Randall A Berry;,citation_publication_date=2013-06;,citation_cover_date=2013-06;,citation_year=2013;,citation_issue=6;,citation_doi=10.1109/TIT.2013.2253194;,citation_volume=59;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Evaluating a call option and optimal timing strategy in the stock market;,citation_author=Howard M. Taylor;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_fulltext_html_url=http://www.jstor.org/stable/2628546;,citation_issue=1;,citation_issn=00251909, 15265501;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Optimal stopping and applications;,citation_author=Thomas S. Ferguson;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_fulltext_html_url=http://www.math.ucla.edu/~tom/Stopping/Contents.html;">
<meta name="citation_reference" content="citation_title=Who solved the secretary problem?;,citation_author=Thomas S Ferguson;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_journal_title=Statistical science;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Characterizing the structure of optimal stopping policies;,citation_author=Sechan Oh;,citation_author=Özalp Özer;,citation_publication_date=2016-07;,citation_cover_date=2016-07;,citation_year=2016;,citation_issue=11;,citation_doi=10.1111/poms.12579;,citation_volume=25;,citation_journal_title=Production and Operations Management;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Markov decision processes: Discrete stochastic dynamic programming;,citation_author=Martin L Puterman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_doi=10.1002/9780470316887;">
<meta name="citation_reference" content="citation_title=Optimization over time: Dynamic programming and stochastic control. Vol. 1 and 2;,citation_author=Peter Whittle;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;">
<meta name="citation_reference" content="citation_title=Optimal control: Basics and beyond;,citation_author=Peter Whittle;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Dynamic programming and optimal control;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.athenasc.com/dpbook.html;,citation_volume=I and II;">
<meta name="citation_reference" content="citation_title=Abstract dynamic programming;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://web.mit.edu/dimitrib/www/abstractdp_MIT.html;">
<meta name="citation_reference" content="citation_title=Introduction to stochastic control theory;,citation_author=Karl J. Aström;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;">
<meta name="citation_reference" content="citation_title=Policy invariance under reward transformations: Theory and application to reward shaping;,citation_author=Andrew Y Ng;,citation_author=Daishi Harada;,citation_author=Stuart Russell;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf;,citation_volume=99;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Theoretical and empirical analysis of reward shaping in reinforcement learning;,citation_author=M. Grzes;,citation_author=D. Kudenko;,citation_publication_date=2009-12;,citation_cover_date=2009-12;,citation_year=2009;,citation_doi=10.1109/ICMLA.2009.33;,citation_conference_title=International conference on machine learning and applications;">
<meta name="citation_reference" content="citation_title=Potential based reward shaping tutorial;,citation_author=Sam Devlin;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf;">
<meta name="citation_reference" content="citation_title=How many parts to make at once;,citation_author=Ford W Harris;,citation_publication_date=1913-02;,citation_cover_date=1913-02;,citation_year=1913;,citation_issue=2;,citation_doi=10.1287/opre.38.6.947;,citation_volume=10;,citation_journal_title=The magazine of management;">
<meta name="citation_reference" content="citation_title=The mathematical theory of banking;,citation_author=Francis Y Edgeworth;,citation_publication_date=1888;,citation_cover_date=1888;,citation_year=1888;,citation_fulltext_html_url=https://www.jstor.org/stable/2979084;,citation_issue=1;,citation_volume=51;,citation_journal_title=Journal of the Royal Statistical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Methods of operations research;,citation_author=P. Morse;,citation_author=G. Kimball;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;">
<meta name="citation_reference" content="citation_title=The theory of inventory management;,citation_author=S. Whitin;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;">
<meta name="citation_reference" content="citation_title=Building intuition: Insights from basic operations management models and principles;,citation_author=Evan L. Porteus;,citation_editor=D. Chhajed;,citation_editor=T. J. Lowe;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=10.1007/978-0-387-73699-0;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Selling random wind;,citation_author=Eilyan Bitar;,citation_author=Kameshwar Poolla;,citation_author=Pramod Khargonekar;,citation_author=Ram Rajagopal;,citation_author=Pravin Varaiya;,citation_author=Felix Wu;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 45th hawaii international conference on system sciences;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Fundamental performance limits in cross-layer wireless optimization: Throughput, delay, and energy;,citation_author=Edmund M. Yeh;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_doi=10.1561/0100000014;,citation_issn=1567-2190;,citation_volume=9;,citation_journal_title=Foundations and Trends in Communications and Information Theory;">
<meta name="citation_reference" content="citation_title=Energy-efficient scheduling under delay constraints for wireless networks;,citation_author=Randall Berry;,citation_author=Eytan Modiano;,citation_author=Murtaza Zafer;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_doi=10.2200/S00443ED1V01Y201208CNT011;,citation_volume=5;,citation_journal_title=Synthesis Lectures on Communication Networks;">
<meta name="citation_reference" content="citation_title=Stochastic dominance: Investment decision making under uncertainty;,citation_author=Haim Levy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_doi=10.1007/978-3-319-21708-6;">
<meta name="citation_reference" content="citation_title=Stochastic dominance and expected utility: Survey and analysis;,citation_author=Haim Levy;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_doi=10.1287/mnsc.38.4.555;,citation_volume=38;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Stochastically monotone markov chains;,citation_author=D J Daley;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=4;,citation_doi=10.1007/BF00531852;,citation_volume=10;,citation_journal_title=Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Monotone matrices and monotone markov processes;,citation_author=Julian Keilson;,citation_author=Adri Kester;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=3;,citation_volume=5;,citation_journal_title=Stochastic Processes and their Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=On monotonicity of the optimal transmission policy in cross-layer adaptive m -QAM modulation;,citation_author=N. Ding;,citation_author=P. Sadeghi;,citation_author=R. A. Kennedy;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=9;,citation_doi=10.1109/TCOMM.2016.2590427;,citation_issn=1558-0857;,citation_volume=64;,citation_journal_title=IEEE Transactions on Communications;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity in economics: An elementary survey;,citation_author=Rabah Amir;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=3;,citation_doi=10.2307/20062066;,citation_issn=00384038;,citation_volume=71;,citation_journal_title=Southern Economic Journal;,citation_publisher=Southern Economic Association;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity;,citation_author=Donald M. Topkis;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_isbn=9780691032443;">
<meta name="citation_reference" content="citation_title=Sufficient conditions for the value function and optimal strategy to be even and quasi-convex;,citation_author=J. Chakravorty;,citation_author=A. Mahajan;,citation_publication_date=2018-11;,citation_cover_date=2018-11;,citation_year=2018;,citation_issue=11;,citation_doi=10.1109/TAC.2018.2800796;,citation_issn=2334-3303;,citation_volume=63;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=On the locality of action domination in sequential decision making;,citation_author=Emmanuel Rachelson;,citation_author=Michail G Lagoudakis;,citation_publication_date=2010-01;,citation_cover_date=2010-01;,citation_year=2010;,citation_fulltext_html_url=https://oatao.univ-toulouse.fr/17977/;,citation_conference_title=Proceedings of 11th international symposium on artificial intelligence and mathematics;">
<meta name="citation_reference" content="citation_title=Lipschitz continuity of value functions in Markovian decision processes;,citation_author=Karl Hinderer;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_doi=10.1007/s00186-005-0438-1;,citation_volume=62;,citation_journal_title=Mathematical Methods of Operations Research;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=DeepMDP: Learning continuous latent space models for representation learning;,citation_author=Carles Gelada;,citation_author=Saurabh Kumar;,citation_author=Jacob Buckman;,citation_author=Ofir Nachum;,citation_author=Marc G. Bellemare;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=http://proceedings.mlr.press/v97/gelada19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Convergence of discretization procedures in dynamic programming;,citation_author=Demitri Bertsekas;,citation_publication_date=1975-06;,citation_cover_date=1975-06;,citation_year=1975;,citation_issue=3;,citation_doi=10.1109/TAC.1975.1100984;,citation_issn=2334-3303;,citation_volume=20;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=Towards a unified theory of state abstraction for MDPs;,citation_author=Lihong Li;,citation_author=Thomas J Walsh;,citation_author=Michael L Littman;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://anytime.cs.umass.edu/aimath06/proceedings/P21.pdf;,citation_conference_title=ISAIM;">
<meta name="citation_reference" content="citation_title=Death and discounting;,citation_author=A. Shwartz;,citation_publication_date=2001-04;,citation_cover_date=2001-04;,citation_year=2001;,citation_fulltext_html_url=https://doi.org/10.1109/9.917668;,citation_issue=4;,citation_doi=10.1109/9.917668;,citation_volume=46;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Constrained markov decision processes;,citation_author=Eitan. Altman;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://www-sop.inria.fr/members/Eitan.Altman/TEMP/h.pdf;">
<meta name="citation_reference" content="citation_title=Optimal investment policies for the horse race model&amp;amp;amp;quot;;,citation_author=Thomas S. Ferguson;,citation_author=C. Zachary Gilstein;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=https://www.math.ucla.edu/~tom/papers/unpublished/Zach2.pdf;">
<meta name="citation_reference" content="citation_title=Discovery of the kalman filter as a practical tool for aerospace and;,citation_author=Stanley F. Mcgee;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_fulltext_html_url=https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19860003843.pdf;,citation_technical_report_institution=National Aeronautics; Space Administration;">
<meta name="citation_reference" content="citation_title=Stochastic systems: Estimation identification and adaptive control;,citation_author=P. R. Kumar;,citation_author=Pravin Varaiya;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;">
<meta name="citation_reference" content="citation_title=Stochastic dynamic programming and the control of queueing systems;,citation_author=Linn I. Sennott;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_isbn=0-471-16120-9;">
<meta name="citation_reference" content="citation_title=Discrete-time controlled Markov processes with average cost criterion - a survey;,citation_author=Aristotle Arapostathis;,citation_author=Vivek S. Borkar;,citation_author=Emmaneul Fernandez-Gaucherand;,citation_author=Mrinak K. Ghosh;,citation_author=Steven I. Marcus;,citation_publication_date=1993-03;,citation_cover_date=1993-03;,citation_year=1993;,citation_issue=2;,citation_volume=31;,citation_journal_title=SIAM Journal of Control and Optimization;">
<meta name="citation_reference" content="citation_title=The optimal control of partially observable markov processes over a finite horizon;,citation_author=Richard D. Smallwood;,citation_author=Edward J. Sondik;,citation_publication_date=1973-10;,citation_cover_date=1973-10;,citation_year=1973;,citation_issue=5;,citation_doi=10.1287/opre.21.5.1071;,citation_volume=21;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Convex analytic methods in markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_11;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=A convex analytic approach to markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=1988-08;,citation_cover_date=1988-08;,citation_year=1988;,citation_issue=4;,citation_doi=10.1007/bf00353877;,citation_volume=78;,citation_journal_title=Probability Theory and Related Fields;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Applications of markov decision processes in communication networks;,citation_author=Eitan Altman;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_16;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Water reservoir applications of markov decision processes;,citation_author=Bernard F. Lamond;,citation_author=Abdeslem Boukhtouta;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_17;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Asymptotically efficient adaptive allocation rules;,citation_author=T. L Lai;,citation_author=Herbert Robbins;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_issue=1;,citation_doi=http://dx.doi.org/10.1016/0196-8858(85)90002-8;,citation_issn=0196-8858;,citation_volume=6;,citation_journal_title=Advances in Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Dynamic programming;,citation_author=Richard Bellman;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;">
<meta name="citation_reference" content="citation_title=A dynamic allocation index for the discounted multiarmed bandit problem;,citation_author=J. C. Gittins;,citation_author=D. M. Jones;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_volume=9;,citation_inbook_title=Progress in statistics;">
<meta name="citation_reference" content="citation_title=Bandit processes and dynamic allocation indices;,citation_author=John C Gittins;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=2;,citation_volume=41;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits and the Gittins index;,citation_abstract=A plausible conjecture (C) has the implication that a relationship (12) holds between the maximal expected rewards for a multi-project process and for a one-project process (F and Ï&amp;amp;amp;lt;sub&amp;gt;i&amp;lt;/sub&amp;gt; respectively), if the option of retirement with reward M is available. The validity of this relation and optimality of Gittins’ index rule are verified simultaneously by dynamic programming methods. These results are partially extended to the case of so-called &amp;quot;bandit superprocesses&amp;quot;.;,citation_author=P. Whittle;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=2;,citation_issn=00359246;,citation_volume=42;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=[Royal Statistical Society, Wiley];">
<meta name="citation_reference" content="citation_title=Four proofs of Gittins’ multiarmed bandit theorem;,citation_abstract=We study four proofs that the Gittins index priority rule is optimal for alternative bandit processes. These include Gittins’ original exchange argument, Weber’s prevailing charge argument, Whittle’s Lagrangian dual approach, and Bertsimas and Niño-Mora’s proof based on the achievable region approach and generalized conservation laws. We extend the achievable region proof to infinite countable state spaces, by using infinite dimensional linear programming theory.;,citation_author=Esther Frostig;,citation_author=Gideon Weiss;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=http://dx.doi.org/10.1007/s10479-013-1523-0;,citation_issue=1;,citation_doi=10.1007/s10479-013-1523-0;,citation_issn=1572-9338;,citation_volume=241;,citation_journal_title=Annals of Operations Research;">
<meta name="citation_reference" content="citation_title=The multi-armed bandit problem: Decomposition and computation;,citation_author=Michael N Katehakis;,citation_author=Arthur F Veinott;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=2;,citation_volume=12;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits under general deprecation and commitment;,citation_author=Wesley Cowan;,citation_author=Michael N. Katehakis;,citation_publication_date=2015-10;,citation_cover_date=2015-10;,citation_year=2015;,citation_issue=1;,citation_doi=10.1017/s0269964814000217;,citation_volume=29;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Restless bandits: Activity allocation in a changing world;,citation_author=Peter Whittle;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=A;,citation_volume=25;,citation_journal_title=Journal of applied probability;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=Foundations and applications of sensor management;,citation_author=A. Mahajan;,citation_author=D. Teneketzis;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Two characterizations of optimality in dynamic programming;,citation_author=Ioannis Karatzas;,citation_author=William D. Sudderth;,citation_publication_date=2010-11;,citation_cover_date=2010-11;,citation_year=2010;,citation_issue=3;,citation_doi=10.1007/s00245-009-9093-x;,citation_volume=61;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Structural properties of stochastic dynamic programs;,citation_author=James E. Smith;,citation_author=Kevin F. McCardle;,citation_publication_date=2002-10;,citation_cover_date=2002-10;,citation_year=2002;,citation_issue=5;,citation_doi=10.1287/opre.50.5.796.365;,citation_volume=50;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Monotonicity in multidimensional markov decision processes for the batch dispatch problem;,citation_author=Katerina Papadaki;,citation_author=Warren B. Powell;,citation_publication_date=2007-03;,citation_cover_date=2007-03;,citation_year=2007;,citation_issue=2;,citation_doi=10.1016/j.orl.2006.03.013;,citation_volume=35;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Basic ideas for event-based optimization of markov systems;,citation_author=Xi-Ren Cao;,citation_publication_date=2005-06;,citation_cover_date=2005-06;,citation_year=2005;,citation_issue=2;,citation_doi=10.1007/s10626-004-6211-4;,citation_volume=15;,citation_journal_title=Discrete Event Dynamic Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Monotonicity in markov reward and decision chains: Theory and applications;,citation_author=Ger Koole;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_doi=10.1561/0900000002;,citation_volume=1;,citation_journal_title=Foundations and Trends in Stochastic Systems;,citation_publisher=Now Publishers;">
<meta name="citation_reference" content="citation_title=Stochastic learning and optimization;,citation_author=Xi-Ren Cao;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-0-387-69082-7;">
<meta name="citation_reference" content="citation_title=Optimality and approximation with policy gradient methods in markov decision processes;,citation_abstract=Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution (say with a sufficiently rich policy class); how they cope with approximation error due to using a restricted class of parametric policies; or their finite sample behavior. Such characterizations are important not only to compare these methods to their approximate value function counterparts (where such issues are relatively well understood, at least in the worst case), but also to help with more principled approaches to algorithm design. This work provides provable characterizations of computational, approximation, and sample size issues with regards to policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: 1) &amp;amp;amp;quot;tabular&amp;quot; policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy, and 2) restricted policy classes, which may not contain the optimal policy and where we provide agnostic learning results. One insight of this work is in formalizing the importance how a favorable initial state distribution provides a means to circumvent worst-case exploration issues. Overall, these results place policy gradient methods under a solid theoretical footing, analogous to the global convergence guarantees of iterative value function based algorithms.;,citation_author=Alekh Agarwal;,citation_author=Sham M. Kakade;,citation_author=Jason D. Lee;,citation_author=Gaurav Mahajan;,citation_publication_date=2019-08-01;,citation_cover_date=2019-08-01;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1908.00261v2;">
<meta name="citation_reference" content="citation_title=Analysis of stochastic dual dynamic programming method;,citation_author=Alexander Shapiro;,citation_publication_date=2011-02;,citation_cover_date=2011-02;,citation_year=2011;,citation_issue=1;,citation_doi=10.1016/j.ejor.2010.08.007;,citation_volume=209;,citation_journal_title=European Journal of Operational Research;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Multi-stage stochastic optimization applied to energy planning;,citation_author=M. V. F. Pereira;,citation_author=L. M. V. G. Pinto;,citation_publication_date=1991-05;,citation_cover_date=1991-05;,citation_year=1991;,citation_issue=1-3;,citation_doi=10.1007/bf01582895;,citation_volume=52;,citation_journal_title=Mathematical Programming;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Approximate information state for partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Aditya Mahajan;,citation_publication_date=2019-12;,citation_cover_date=2019-12;,citation_year=2019;,citation_doi=10.1109/cdc40024.2019.9029898;,citation_conference_title=2019 IEEE 58th conference on decision and control (CDC);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Approximate information state for approximate planning and reinforcement learning in partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Amit Sinha;,citation_author=Raihan Seraj;,citation_author=Aditya Mahajan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=http://jmlr.org/papers/v23/20-1165.html;,citation_issue=12;,citation_volume=23;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=On policy independence of conditional expectation;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_volume=28;,citation_journal_title=Information and Control;">
<meta name="citation_reference" content="citation_title=Incremental pruning: A simple, fast, exact method for partially observable Markov decision processes;,citation_author=Anthony Cassandra;,citation_author=Michael L. Littman;,citation_author=Nevin L. Zhang;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_conference_title=Proceedings of the thirteenth conference on uncertainty in artificial intelligence;">
<meta name="citation_reference" content="citation_title=Partially observable Markov decision processes: A geometric technique and analysis;,citation_author=H. Zhang;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Operations Research;">
<meta name="citation_reference" content="citation_title=Algorithms for partially observable markov decision processes;,citation_author=Hsien-Te Cheng;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_dissertation_institution=University of British Columbia;">
<meta name="citation_reference" content="citation_title=Acting optimally in partially observable stochastic domains;,citation_author=Anthony R Cassandra;,citation_author=Leslie Pack Kaelbling;,citation_author=Michael L Littman;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_volume=94;,citation_conference_title=AAAI;">
<meta name="citation_reference" content="citation_title=Planning in stochastic domains: Problem characteristics and approximation;,citation_author=N Zhang;,citation_author=W Liu;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_technical_report_institution=Hong Kong Univeristy of Science; Technology;,citation_technical_report_number=HKUST-CS96-31;">
<meta name="citation_reference" content="citation_title=Sequential tests of statistical hypotheses;,citation_author=A. Wald;,citation_publication_date=1945-06;,citation_cover_date=1945-06;,citation_year=1945;,citation_issue=2;,citation_doi=10.1214/aoms/1177731118;,citation_volume=16;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bayes and minimax solutions of sequential decision problems;,citation_author=K. J. Arrow;,citation_author=D. Blackwell;,citation_author=M. A. Girshick;,citation_publication_date=1949-07;,citation_cover_date=1949-07;,citation_year=1949;,citation_issue=3/4;,citation_doi=10.2307/1905525;,citation_volume=17;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Optimal statistical decisions;,citation_author=Morris DeGroot;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_isbn=047168029X;">
<meta name="citation_reference" content="citation_title=On a test whether two samples are from the same population;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1940-06;,citation_cover_date=1940-06;,citation_year=1940;,citation_issue=2;,citation_doi=10.1214/aoms/1177731909;,citation_volume=11;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Optimum character of the sequential probability ratio test;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1948-09;,citation_cover_date=1948-09;,citation_year=1948;,citation_issue=3;,citation_doi=10.1214/aoms/1177730197;,citation_volume=19;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=A stochastic sensor selection scheme for sequential hypothesis testing with multiple sensors;,citation_author=Cheng-Zong Bai;,citation_author=Vaibhav Katewa;,citation_author=Vijay Gupta;,citation_author=Yih-Fang Huang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=14;,citation_volume=63;,citation_journal_title=IEEE transactions on signal processing;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=A discrete markov chain representation of the sequential probability ratio test;,citation_author=Willam H. Woodall;,citation_author=Marion R. Reynolds;,citation_publication_date=1983-01;,citation_cover_date=1983-01;,citation_year=1983;,citation_issue=1;,citation_doi=10.1080/07474948308836025;,citation_volume=2;,citation_journal_title=Communications in Statistics. Part C: Sequential Analysis;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Mean-field games with a major player;,citation_author=Jean-Michel Lasry;,citation_author=Pierre-Louis Lions;,citation_publication_date=2018-08;,citation_cover_date=2018-08;,citation_year=2018;,citation_issue=8;,citation_doi=10.1016/j.crma.2018.06.001;,citation_volume=356;,citation_journal_title=Comptes Rendus Mathematique;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Remote estimation over a packet-drop channel with markovian state;,citation_author=Jhelum Chakravorty;,citation_author=Aditya Mahajan;,citation_publication_date=2020-05;,citation_cover_date=2020-05;,citation_year=2020;,citation_issue=5;,citation_doi=10.1109/tac.2019.2926160;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal state estimation in the presence of communication costs and packet drops;,citation_author=Gabriel M. Lipsa;,citation_author=Nuno C. Martins;,citation_publication_date=2009-09;,citation_cover_date=2009-09;,citation_year=2009;,citation_doi=10.1109/allerton.2009.5394899;,citation_conference_title=Annual allerton conference on communication, control, and computing (allerton);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Remote state estimation with communication costs for first-order LTI systems;,citation_author=G. M. Lipsa;,citation_author=N. C. Martins;,citation_publication_date=2011-09;,citation_cover_date=2011-09;,citation_year=2011;,citation_issue=9;,citation_doi=10.1109/tac.2011.2139370;,citation_volume=56;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Policy improvement and the newton-raphson algorithm;,citation_author=P. Whittle;,citation_author=N. Komarova;,citation_publication_date=1988-04;,citation_cover_date=1988-04;,citation_year=1988;,citation_issue=2;,citation_doi=10.1017/s0269964800000760;,citation_volume=2;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Optimal adaptive control of linear-quadratic-gaussian systems;,citation_author=P. R. Kumar;,citation_publication_date=1983-03;,citation_cover_date=1983-03;,citation_year=1983;,citation_issue=2;,citation_doi=10.1137/0321009;,citation_volume=21;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=The optimal inventory policy for batch ordering;,citation_author=Arthur F. Veinott;,citation_publication_date=1965-06;,citation_cover_date=1965-06;,citation_year=1965;,citation_issue=3;,citation_doi=10.1287/opre.13.3.424;,citation_volume=13;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Elements of game theory;,citation_author=Ye S. Venttsel;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_fulltext_html_url=https://archive.org/details/ElementsOfGameTheorylittleMathematicsLibrary/;">
<meta name="citation_reference" content="citation_title=Periodic review inventory systems with continuous demand and discrete order sizes;,citation_author=John N. Tsitsiklis;,citation_publication_date=1984-10;,citation_cover_date=1984-10;,citation_year=1984;,citation_issue=10;,citation_doi=10.1287/mnsc.30.10.1250;,citation_volume=30;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Risk sensitivity, A strangely pervasive concept;,citation_author=Peter Whittle;,citation_publication_date=2002-02;,citation_cover_date=2002-02;,citation_year=2002;,citation_issue=1;,citation_doi=10.1017/s1365100502027025;,citation_volume=6;,citation_journal_title=Macroeconomic Dynamics;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Risk-sensitive markov decision processes;,citation_author=Ronald A. Howard;,citation_author=James E. Matheson;,citation_publication_date=1972-03;,citation_cover_date=1972-03;,citation_year=1972;,citation_issue=7;,citation_doi=10.1287/mnsc.18.7.356;,citation_volume=18;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Inequalities: Theory of majorization and its applications;,citation_author=Albert W. Marshall;,citation_author=Ingram Olkin;,citation_author=Barry C. Arnold;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_doi=10.1007/978-0-387-68276-1;">
<meta name="citation_reference" content="citation_title=Risk sensitive control of markov processes in countable state space;,citation_author=Daniel Hernandez-Hernández;,citation_author=Steven I. Marcus;,citation_publication_date=1996-11;,citation_cover_date=1996-11;,citation_year=1996;,citation_issue=3;,citation_doi=10.1016/s0167-6911(96)00051-5;,citation_volume=29;,citation_journal_title=Systems &amp;amp;amp; Control Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Existence of risk-sensitive optimal stationary policies for controlled markov processes;,citation_author=D. Hernández-Hernández;,citation_publication_date=1999-11;,citation_cover_date=1999-11;,citation_year=1999;,citation_issue=3;,citation_doi=10.1007/s002459900126;,citation_volume=40;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Convex risk measures;,citation_author=Hans Föllmer;,citation_author=Alexander Schied;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470061602.eqf15003;,citation_doi=10.1002/9780470061602.eqf15003;,citation_isbn=9780470061602;,citation_inbook_title=Encyclopedia of quantitative finance;">
<meta name="citation_reference" content="citation_title=Updating the inverse of a matrix;,citation_author=William W. Hager;,citation_publication_date=1989-06;,citation_cover_date=1989-06;,citation_year=1989;,citation_issue=2;,citation_doi=10.1137/1031049;,citation_volume=31;,citation_journal_title=SIAM Review;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=A stochastic approximation method;,citation_author=Herbert Robbins;,citation_author=Sutton Monro;,citation_publication_date=1951-09;,citation_cover_date=1951-09;,citation_year=1951;,citation_issue=3;,citation_doi=10.1214/aoms/1177729586;,citation_volume=22;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=The o.d.e. Method for convergence of stochastic approximation and reinforcement learning;,citation_author=V. S. Borkar;,citation_author=S. P. Meyn;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=2;,citation_doi=10.1137/s0363012997331639;,citation_volume=38;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Q-learning;,citation_author=Christopher J. C. H. Watkins;,citation_author=Peter Dayan;,citation_publication_date=1992-05;,citation_cover_date=1992-05;,citation_year=1992;,citation_issue=3-4;,citation_doi=10.1007/bf00992698;,citation_volume=8;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Asynchronous stochastic approximation and q-learning;,citation_author=John N. Tsitsiklis;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993306;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=An analog scheme for fixed point computation. I. theory;,citation_author=V. S. Borkar;,citation_author=K. Soumyanatha;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=4;,citation_doi=10.1109/81.563625;,citation_volume=44;,citation_journal_title=IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the convergence of stochastic iterative dynamic programming algorithms;,citation_author=Tommi Jaakkola;,citation_author=Michael I. Jordan;,citation_author=Satinder P. Singh;,citation_publication_date=1994-11;,citation_cover_date=1994-11;,citation_year=1994;,citation_issue=6;,citation_doi=10.1162/neco.1994.6.6.1185;,citation_volume=6;,citation_journal_title=Neural Computation;,citation_publisher=MIT Press - Journals;">
<meta name="citation_reference" content="citation_title=Dynamic programming and markov processes;,citation_author=Ronald A. Howard;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and martingale inequalities: A survey;,citation_author=Fan Chung;,citation_author=Linyuan Lu;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=https://projecteuclid.org:443/euclid.im/1175266369;,citation_issue=1;,citation_volume=3;,citation_journal_title=Internet Math.;,citation_publisher=A K Peters, Ltd.;">
<meta name="citation_reference" content="citation_title=On the fenchel duality between strong convexity and lipschitz continuous gradient;,citation_abstract=We provide a simple proof for the Fenchel duality between strong convexity and Lipschitz continuous gradient. To this end, we first establish equivalent conditions of convexity for a general function that may not be differentiable. By utilizing these equivalent conditions, we can directly obtain equivalent conditions for strong convexity and Lipschitz continuous gradient. Based on these results, we can easily prove Fenchel duality. Beside this main result, we also identify several conditions that are implied by strong convexity or Lipschitz continuous gradient, but are not necessarily equivalent to them. This means that these conditions are more general than strong convexity or Lipschitz continuous gradient themselves.;,citation_author=Xingyu Zhou;,citation_publication_date=2018-03-17;,citation_cover_date=2018-03-17;,citation_year=2018;,citation_fulltext_html_url=https://arxiv.org/abs/1803.06573v1;">
<meta name="citation_reference" content="citation_title=Optimal control of markov processes with incomplete state information;,citation_author=K. J Åström;,citation_publication_date=1965-02;,citation_cover_date=1965-02;,citation_year=1965;,citation_issue=1;,citation_doi=10.1016/0022-247x(65)90154-x;,citation_volume=10;,citation_journal_title=Journal of Mathematical Analysis and Applications;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Dynamic service migration in mobile edge computing based on Markov decision process;,citation_author=Shiqiang Wang;,citation_author=Rahul Urgaonkar;,citation_author=Murtaza Zafer;,citation_author=Ting He;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_issue=3;,citation_doi=10.1109/tnet.2019.2916577;,citation_volume=27;,citation_journal_title=IEEE/ACM Transactions on Networking;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic service migration and workload scheduling in edge-clouds;,citation_author=Rahul Urgaonkar;,citation_author=Shiqiang Wang;,citation_author=Ting He;,citation_author=Murtaza Zafer;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_doi=10.1016/j.peva.2015.06.013;,citation_volume=91;,citation_journal_title=Performance Evaluation;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=The role and use of the stochastic linear-quadratic-gaussian problem in control system design;,citation_author=M. Athans;,citation_publication_date=1971-12;,citation_cover_date=1971-12;,citation_year=1971;,citation_issue=6;,citation_doi=10.1109/tac.1971.1099818;,citation_volume=16;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Complexity bounds for approximately solving discounted MDPs by value iterations;,citation_author=Eugene A. Feinberg;,citation_author=Gaojin He;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_doi=10.1016/j.orl.2020.07.001;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=How does the value function of a markov decision process depend on the transition probabilities?;,citation_author=Alfred Müller;,citation_publication_date=1997-11;,citation_cover_date=1997-11;,citation_year=1997;,citation_issue=4;,citation_doi=10.1287/moor.22.4.872;,citation_volume=22;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=What is RKHS?;,citation_author=Dino Sejdinovic;,citation_author=Arthur Gretton;,citation_fulltext_html_url=http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf;">
<meta name="citation_reference" content="citation_title=Martingale methods in stochastic control;,citation_author=M. H. A. Davis;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_doi=10.1007/bfb0009377;,citation_inbook_title=Stochastic control theory and stochastic differential systems;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and model selection;,citation_author=Jean Picard;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-3-540-48503-2;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Phillippe Rigollet;,citation_publication_date=2015-07;,citation_cover_date=2015-07;,citation_year=2015;,citation_fulltext_html_url=https://ocw.mit.edu/courses/mathematics/18-s997-high-dimensional-statistics-spring-2015/lecture-notes/;">
<meta name="citation_reference" content="citation_title=Subgaussian random variables: An expository note;,citation_author=Omar Rivasplata;,citation_publication_date=2012-11;,citation_cover_date=2012-11;,citation_year=2012;,citation_fulltext_html_url=http://stat.cmu.edu/~arinaldo/36788/subgaussians.pdf;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Martin J. Wainwright;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_doi=10.1017/9781108627771;">
<meta name="citation_reference" content="citation_title=Selecting computations: Theory and applications;,citation_author=Nicholas Hay;,citation_author=S. Russell;,citation_author=David Tolpin;,citation_author=S. E. Shimony;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=http://www.auai.org/uai2012/papers/123.pdf;,citation_conference_title=UAI;">
<meta name="citation_reference" content="citation_title=On linear control theory;,citation_author=D. Peter Joseph;,citation_author=T. Julius Tou;,citation_publication_date=1961;,citation_cover_date=1961;,citation_year=1961;,citation_issue=4;,citation_doi=10.1109/tai.1961.6371743;,citation_volume=80;,citation_journal_title=Transactions of the American Institute of Electrical Engineers, Part II: Applications and Industry;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the separation theorem of stochastic control;,citation_author=W. M. Wonham;,citation_publication_date=1968-05;,citation_cover_date=1968-05;,citation_year=1968;,citation_issue=2;,citation_doi=10.1137/0306023;,citation_volume=6;,citation_journal_title=SIAM Journal on Control;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Some comments on a theorem of Hardy and Littlewood;,citation_author=R. Sznajder;,citation_author=J. A. Filar;,citation_publication_date=1992-10;,citation_cover_date=1992-10;,citation_year=1992;,citation_issue=1;,citation_doi=10.1007/bf00939913;,citation_volume=75;,citation_journal_title=Journal of Optimization Theory and Applications;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Notes on the theory of series (XVI): Two Tauberian theorems;,citation_author=G. H. Hardy;,citation_author=J. E. Littlewood;,citation_publication_date=1931-10;,citation_cover_date=1931-10;,citation_year=1931;,citation_issue=4;,citation_doi=10.1112/jlms/s1-6.4.281;,citation_volume=s1-6;,citation_journal_title=Journal of the London Mathematical Society;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=The Hardy-Littlewood theorems;,citation_author=Jacob Korevaar;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_doi=10.1007/978-3-662-10225-1_1;,citation_inbook_title=Tauberian theory: A century of developments;">
<meta name="citation_reference" content="citation_title=Monotone optimal policies for markov decision processes;,citation_author=Richard F. Serfozo;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_doi=10.1007/bfb0120752;,citation_inbook_title=Mathematical programming studies;">
<meta name="citation_reference" content="citation_title=Cross-layer communication over fading channels with adaptive decision feedback;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_author=Edmund Yeh;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=International symposium on modeling and optimization in mobile, ad hoc, and wireless networks (WiOPT);">
<meta name="citation_reference" content="citation_title=Counterexamples on the monotonicity of delay optimal strategies for energy harvesting transmitters;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.1109/lwc.2020.2981066;,citation_journal_title=IEEE Wireless Communications Letters;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Q-learning for MDPs with general spaces: Convergence and near optimality via quantization under weak continuity;,citation_abstract=Reinforcement learning algorithms often require finiteness of state and action spaces in Markov decision processes (MDPs) and various efforts have been made in the literature towards the applicability of such algorithms for continuous state and action spaces. In this paper, we show that under very mild regularity conditions (in particular, involving only weak continuity of the transition kernel of an MDP), Q-learning for standard Borel MDPs via quantization of states and actions converge to a limit, and furthermore this limit satisfies an optimality equation which leads to near optimality with either explicit performance bounds or which are guaranteed to be asymptotically optimal. Our approach builds on (i) viewing quantization as a measurement kernel and thus a quantized MDP as a POMDP, (ii) utilizing near optimality and convergence results of Q-learning for POMDPs, and (iii) finally, near-optimality of finite state model approximations for MDPs with weakly continuous kernels which we show to correspond to the fixed point of the constructed POMDP. Thus, our paper presents a very general convergence and approximation result for the applicability of Q-learning for continuous MDPs.;,citation_author=Ali Devran Kara;,citation_author=Naci Saldi;,citation_author=Serdar Yüksel;,citation_publication_date=2021-11-12;,citation_cover_date=2021-11-12;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2111.06781v1;">
<meta name="citation_reference" content="citation_title=Bounds and transformations for discounted finite markov decision chains;,citation_author=Evan L. Porteus;,citation_publication_date=1975-08;,citation_cover_date=1975-08;,citation_year=1975;,citation_issue=4;,citation_doi=10.1287/opre.23.4.761;,citation_volume=23;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Calculus on MDPs: Potential shaping as a gradient;,citation_abstract=In reinforcement learning, different reward functions can be equivalent in terms of the optimal policies they induce. A particularly well-known and important example is potential shaping, a class of functions that can be added to any reward function without changing the optimal policy set under arbitrary transition dynamics. Potential shaping is conceptually similar to potentials, conservative vector fields and gauge transformations in math and physics, but this connection has not previously been formally explored. We develop a formalism for discrete calculus on graphs that abstract a Markov Decision Process, and show how potential shaping can be formally interpreted as a gradient within this framework. This allows us to strengthen results from Ng et al. (1999) describing conditions under which potential shaping is the only additive reward transformation to always preserve optimal policies. As an additional application of our formalism, we define a rule for picking a single unique reward function from each potential shaping equivalence class.;,citation_author=Erik Jenner;,citation_author=Herke Hoof;,citation_author=Adam Gleave;,citation_publication_date=2022-08-20;,citation_cover_date=2022-08-20;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2208.09570v1;">
<meta name="citation_reference" content="citation_title=Dynamic potential-based reward shaping;,citation_abstract=Potential-based reward shaping can significantly improve the time needed to learn an optimal policy and, in multi-agent systems, the performance of the final joint-policy. It has been proven to not alter the optimal policy of an agent learning alone or the Nash equilibria of multiple agents learning together.However, a limitation of existing proofs is the assumption that the potential of a state does not change dynamically during the learning. This assumption often is broken, especially if the reward-shaping function is generated automatically.In this paper we prove and demonstrate a method of extending potential-based reward shaping to allow dynamic shaping and maintain the guarantees of policy invariance in the single-agent case and consistent Nash equilibria in the multi-agent case.;,citation_author=Sam Devlin;,citation_author=Daniel Kudenko;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_isbn=0981738117;,citation_conference_title=Proceedings of the 11th international conference on autonomous agents and multiagent systems;,citation_conference=International Foundation for Autonomous Agents; Multiagent Systems;,citation_series_title=AAMAS ’12;">
<meta name="citation_reference" content="citation_title=Potential-based shaping and q-value initialization are equivalent;,citation_abstract=Shaping has proven to be a powerful but precarious means of improving reinforcement learning performance. Ng, Harada, and Russell (1999) proposed the potential-based shaping algorithm for adding shaping rewards in a way that guarantees the learner will learn optimal behavior.In this note, we prove certain similarities between this shaping algorithm and the initialization step required for several reinforcement learning algorithms. More specifically, we prove that a reinforcement learner with initial Q-values based on the shaping algorithm’s potential function make the same updates throughout learning as a learner receiving potential-based shaping rewards. We further prove that under a broad category of policies, the behavior of these two learners are indistinguishable. The comparison provides intuition on the theoretical properties of the shaping algorithm as well as a suggestion for a simpler method for capturing the algorithm’s benefit. In addition, the equivalence raises previously unaddressed issues concerning the efficiency of learning with potential-based shaping.;,citation_author=Eric Wiewiora;,citation_publication_date=2003-09;,citation_cover_date=2003-09;,citation_year=2003;,citation_issue=1;,citation_issn=1076-9757;,citation_volume=19;,citation_journal_title=Journal of Artificial Intelligence Research;,citation_publisher=AI Access Foundation;">
<meta name="citation_reference" content="citation_title=Behavior of organisms;,citation_author=B. F. Skinner;,citation_publication_date=1938;,citation_cover_date=1938;,citation_year=1938;,citation_isbn=9781583900079;">
<meta name="citation_reference" content="citation_title=John von Neumann’s conception of the minimax theorem: A journey through different mathematical contexts;,citation_author=Tinne Hoff Kjeldsen;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_fulltext_html_url=http://www.jstor.org/stable/41134130;,citation_issue=1;,citation_issn=00039519, 14320657;,citation_volume=56;,citation_journal_title=Archive for History of Exact Sciences;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in multiple independent Gaussian channels as a game;,citation_author=Michail Fasoulakis;,citation_author=Apostolos Traganitis;,citation_author=Anthony Ephremides;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1007/978-3-030-16989-3_1;,citation_inbook_title=Lecture notes of the institute for computer sciences, social informatics and telecommunications engineering;">
<meta name="citation_reference" content="citation_title=A jamming game in wireless networks with transmission cost;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2007-06;,citation_cover_date=2007-06;,citation_year=2007;,citation_fulltext_html_url=https://www-sop.inria.fr/members/Eitan.Altman/PAPERS/andrey-lncs.pdf;,citation_conference_title=EuroFGI international conference on network control and optimization (NET-COOP);,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Closed form solutions for symmetric water filling games;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=https://doi.org/10.1109/INFOCOM.2008.117;,citation_conference_title=IEEE INFOCOM conference on computer communications;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Closed form solutions for water-filling problems in optimization and game frameworks;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=47;,citation_journal_title=Telecommunication Systems;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in wireless networks: The case of several jammers;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=2009 international conference on game theory for networks;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Jamming game with incomplete information about the jammer;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the fourth international ICST conference on performance evaluation methodologies and tools;">
<meta name="citation_reference" content="citation_title=Equilibrium points in n -person games;,citation_author=John F. Nash;,citation_publication_date=1950-01;,citation_cover_date=1950-01;,citation_year=1950;,citation_issue=1;,citation_doi=10.1073/pnas.36.1.48;,citation_volume=36;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=Proceedings of the National Academy of Sciences;">
<meta name="citation_reference" content="citation_title=A further generalization of the Kakutani fixed point theorem, with application to nash equilibrium points;,citation_author=I. L. Glicksberg;,citation_publication_date=1952-02;,citation_cover_date=1952-02;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/2032478;,citation_volume=3;,citation_journal_title=Proceedings of the American Mathematical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=The logic of animal conflict;,citation_author=J Maynard Smith;,citation_author=G. R. Price;,citation_publication_date=1973-11;,citation_cover_date=1973-11;,citation_year=1973;,citation_issue=5427;,citation_doi=10.1038/246015a0;,citation_volume=246;,citation_journal_title=Nature;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Evolution and the theory of games;,citation_author=John Maynard Smith;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_isbn=0521246733;">
<meta name="citation_reference" content="citation_title=The selfish gene;,citation_author=Richard Dawkins;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_isbn=019857519X;">
<meta name="citation_reference" content="citation_title=Population games and evolutionary dynamics;,citation_author=William H. Sandholm;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_isbn=9780262195874;">
<meta name="citation_reference" content="citation_title=A note on evolutionary stable strategies and game dynamics;,citation_author=Josef Hofbauer;,citation_author=Peter Schuster;,citation_author=Karl Sigmund;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=3;,citation_volume=81;,citation_journal_title=Journal of Theoretical Biology;">
<meta name="citation_reference" content="citation_title=Evolutionary stable strategies and game dynamics;,citation_author=Peter D. Taylor;,citation_author=Leo B. Jonker;,citation_publication_date=1978-07;,citation_cover_date=1978-07;,citation_year=1978;,citation_issue=1-2;,citation_doi=10.1016/0025-5564(78)90077-9;,citation_volume=40;,citation_journal_title=Mathematical Biosciences;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium in a nutshell;,citation_author=Rabah Amir;,citation_author=Sergei Belkov;,citation_author=Igor V. Evstigneev;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_issue=4;,citation_doi=10.1007/s11238-017-9609-9;,citation_volume=83;,citation_journal_title=Theory and Decision;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium as an expression of bayesian rationality;,citation_author=Robert J. Aumann;,citation_publication_date=1987-01;,citation_cover_date=1987-01;,citation_year=1987;,citation_issue=1;,citation_doi=10.2307/1911154;,citation_volume=55;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Subjectivity and correlation in randomized strategies;,citation_author=Robert J. Aumann;,citation_publication_date=1974-03;,citation_cover_date=1974-03;,citation_year=1974;,citation_issue=1;,citation_doi=10.1016/0304-4068(74)90037-8;,citation_volume=1;,citation_journal_title=Journal of Mathematical Economics;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Agreeing to disagree;,citation_author=Robert J. Aumann;,citation_publication_date=1976-11;,citation_cover_date=1976-11;,citation_year=1976;,citation_issue=6;,citation_doi=10.1214/aos/1176343654;,citation_volume=4;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Computing correlated equilibria in multi-player games;,citation_author=Christos H. Papadimitriou;,citation_author=Tim Roughgarden;,citation_publication_date=2008-07;,citation_cover_date=2008-07;,citation_year=2008;,citation_issue=3;,citation_doi=10.1145/1379759.1379762;,citation_volume=55;,citation_journal_title=Journal of the ACM;,citation_publisher=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players, iIII part i. The basic model;,citation_author=John C. Harsanyi;,citation_publication_date=1967-11;,citation_cover_date=1967-11;,citation_year=1967;,citation_issue=3;,citation_doi=10.1287/mnsc.14.3.159;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players part II. Bayesian equilibrium points;,citation_author=John C. Harsanyi;,citation_publication_date=1968-01;,citation_cover_date=1968-01;,citation_year=1968;,citation_issue=5;,citation_doi=10.1287/mnsc.14.5.320;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by “bayesian” players, part III. The basic probability distribution of the game;,citation_author=John C. Harsanyi;,citation_publication_date=1968-03;,citation_cover_date=1968-03;,citation_year=1968;,citation_issue=7;,citation_doi=10.1287/mnsc.14.7.486;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Game theory for applied economists;,citation_author=Robert Gibbons;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_isbn=0691043086;">
<meta name="citation_reference" content="citation_title=Computer science theory for the information age;,citation_author=John Hopcroft;,citation_author=Ravi Kannan;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_fulltext_html_url=https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/hopcroft-kannan-feb2012.pdf;">
<meta name="citation_reference" content="citation_title=Theory of self-adaptive control systems;,citation_author=H. Kwakernaak;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Information pattern for linear discrete-time models with stochastic coefficients;,citation_author=T. Bohlin;,citation_publication_date=1970-02;,citation_cover_date=1970-02;,citation_year=1970;,citation_issue=1;,citation_volume=15;,citation_journal_title=IEEE Transactions on Automatic Control (TAC);">
<meta name="citation_reference" content="citation_title=Information states for linear stochastic systems;,citation_author=M. H. A Davis;,citation_author=P. P Varaiya;,citation_publication_date=1972-02;,citation_cover_date=1972-02;,citation_year=1972;,citation_issue=2;,citation_volume=37;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Sufficient statistics in the optimal control of stochastic systems;,citation_author=Charlotte Striebel;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=12;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Some remarks on the concept of state;,citation_author=Hans S. Witsenhausen;,citation_editor=Y. C. Ho;,citation_editor=S. K. Mitter;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_inbook_title=Directions in large-scale systems;">
<meta name="citation_reference" content="citation_title=Linear automaton transformations;,citation_author=A. Nerode;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_volume=9;,citation_journal_title=Proceedings of American Mathematical Society;">
<meta name="citation_reference" content="citation_title=A convergence theorem for non-negative almost supermartingales and some applications;,citation_author=H. Robbins;,citation_author=D. Siegmund;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_doi=10.1016/b978-0-12-604550-5.50015-8;,citation_inbook_title=Optimizing methods in statistics;">
<meta name="citation_reference" content="citation_title=Discrete parameter martingales;,citation_author=J. Neveu;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;">
<meta name="citation_reference" content="citation_title=A user’s guide to measure theoretic probability;,citation_author=David Pollard;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Convergence of stochastic approximation via martingale and converse Lyapunov methods;,citation_author=M. Vidyasagar;,citation_publication_date=2023-01;,citation_cover_date=2023-01;,citation_year=2023;,citation_issue=2;,citation_doi=10.1007/s00498-023-00342-9;,citation_volume=35;,citation_journal_title=Mathematics of Control, Signals, and Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=On stochastic approximation;,citation_author=E. G. Gladyshev;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=2;,citation_doi=10.1137/1110031;,citation_volume=10;,citation_journal_title=Theory of Probability and Its Applications;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Gradient convergence in gradient methods with errors;,citation_author=Dimitri P. Bertsekas;,citation_author=John N. Tsitsiklis;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=3;,citation_doi=10.1137/s1052623497331063;,citation_volume=10;,citation_journal_title=SIAM Journal on Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Stochastic processes;,citation_author=Joseph T. Chang;,citation_publication_date=2007-02;,citation_cover_date=2007-02;,citation_year=2007;,citation_fulltext_html_url=http://www.stat.yale.edu/~pollard/Courses/251.spring2013/Handouts/Chang-notes.pdf;">
<meta name="citation_reference" content="citation_title=Lyapunov criterion for stochastic systems and its applications in distributed computation;,citation_author=Yuzhen Qin;,citation_author=Ming Cao;,citation_author=Brian D. O. Anderson;,citation_publication_date=2020-02;,citation_cover_date=2020-02;,citation_year=2020;,citation_issue=2;,citation_doi=10.1109/tac.2019.2910948;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=An upper bound on the loss from approximate optimal-value functions;,citation_author=Satinder P. Singh;,citation_author=Richard C. Yee;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993308;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Feature-based methods for large scale dynamic programming;,citation_author=John N. Tsitsiklis;,citation_author=Benjamin Roy;,citation_publication_date=1996-03;,citation_cover_date=1996-03;,citation_year=1996;,citation_issue=1-3;,citation_doi=10.1007/bf00114724;,citation_volume=22;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=A graphical derivation of the legendre transform;,citation_author=Sam Kennerly;,citation_publication_date=2011-04;,citation_cover_date=2011-04;,citation_year=2011;,citation_fulltext_html_url=http://einstein.drexel.edu/~skennerly/maths/Legendre.pdf;">
<meta name="citation_reference" content="citation_title=Variational analysis;,citation_author=R Tyrrell Rockafellar;,citation_author=Roger J-B Wets;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=317;">
<meta name="citation_reference" content="citation_title=Entropy, large deviations, and statistical mechanics;,citation_author=Richard S. Ellis;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_doi=10.1007/978-1-4613-8533-2;">
<meta name="citation_reference" content="citation_title=A theory of regularized Markov decision processes;,citation_abstract=Many recent successful (deep) reinforcement learning algorithms make use of regularization, generally based on entropy or Kullback-Leibler divergence. We propose a general theory of regularized Markov Decision Processes that generalizes these approaches in two directions: we consider a larger class of regularizers, and we consider the general modified policy iteration approach, encompassing both policy iteration and value iteration. The core building blocks of this theory are a notion of regularized Bellman operator and the Legendre-Fenchel transform, a classical tool of convex optimization. This approach allows for error propagation analyses of general algorithmic schemes of which (possibly variants of) classical algorithms such as Trust Region Policy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic Policy Programming are special cases. This also draws connections to proximal convex optimization, especially to Mirror Descent.;,citation_author=Matthieu Geist;,citation_author=Bruno Scherrer;,citation_author=Olivier Pietquin;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://proceedings.mlr.press/v97/geist19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../stochastic-control/index.html" rel="" target="">
 <span class="menu-text">Stochastic Control</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../multi-agent-systems/index.html" rel="" target="">
 <span class="menu-text">Multi-Agent Systems</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/adityam/stochastic-control" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../mdps/intro.html">MDPs</a></li><li class="breadcrumb-item"><a href="../mdps/reward-shaping.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reward Shaping</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the course</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Stochastic Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/newsvendor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The newsvendor problem</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/gambling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Optimal gambling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inventory Management</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/monotone-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/power-delay-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/reward-shaping.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reward Shaping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inf-horizon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mdp-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">MDP algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management-revisited.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Inventory management (revisted)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mobile-edge-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Service Migration in Mobile edge computing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/computational-complexity-vi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Computational complexity of value interation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/linear-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Linear programming formulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/lipschitz-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">POMDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/sequential-hypothesis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Approx DP</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/approx-DP.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Approximate dynamic programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/policy-loss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Upper bounds on policy loss</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/model-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Risk sensitive MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-utility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Risk Sensitive Utility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Risk Sensitive MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">LQ systems</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">RL</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rl/stochastic-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Stochastic approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Probability Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Convergence of random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/sub-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Sub-Gaussian random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/change-of-measure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Change of Measure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/martingales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Martingales</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/stochastic-stability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Stochastic stability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Linear Algebra Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/postive-definite-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Positive definite matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/svd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Singular value decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/rkhs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Reproducing Kernel Hilbert Space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Convexity Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/convexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Convex sets and convex functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/duality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Duality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 1</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#generalization-to-discounted-models" id="toc-generalization-to-discounted-models" class="nav-link active" data-scroll-target="#generalization-to-discounted-models"><span class="header-section-number">8.1</span> Generalization to discounted models</a></li>
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="header-section-number">8.2</span> Examples</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/adityam/stochastic-control/edit/quarto/mdps/reward-shaping.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reward Shaping</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="http://www.cim.mcgill.ca/~adityam">Aditya Mahajan</a> </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="http://www.mcgill.ca/ece">
            McGill University
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 3, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="bi bi-journal-text text-primary"></i> Summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>What are the conditions under which two MDPs which have the same dynamics but different cost functions have the same optimal policy? This is an important question in reinforcement learning (where one often <em>shapes</em> the reward function to speed up learning) and inverse reinforcement learning (where one learns the reward function from the behavior of an expert). The following result provides a complete answer to this question. These results are typically established for inifinte horizon models. However, in my opinion, it is conceptually simpler to start with the finite horizon model.</p>
</div>
</div>
<div class="page-columns page-full"><p>Let <span class="math inline">\(M^1\)</span> and <span class="math inline">\(M^2\)</span> denote two MDPs on the same state space <span class="math inline">\(\ALPHABET S\)</span> and action space <span class="math inline">\(\ALPHABET A\)</span>. Both MDPs have the same dynamics <span class="math inline">\(P = (P_1, \dots, P_T)\)</span>, but different cost functions <span class="math inline">\(c^1 = (c^1_1, \dots, c^1_T)\)</span> and <span class="math inline">\(c^2 = (c^2_1, \dots, c^2_T)\)</span>. We assume that for <span class="math inline">\(t \in \{1, \dots, T-1\}\)</span>, the per-step cost is a function of the current state, current action, and next state (see <a href="../mdp-functional#cost-depends-on-next-state">cost depending on next state</a>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and for <span class="math inline">\(t = T\)</span>, the per-step cost function is just a function of the current state.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;We choose the cost to depend on the next state only for convenience of analysis. The result of <a href="#thm-reward-shaping">Theorem&nbsp;<span>8.1</span></a> can be established for models where the cost depends only on the per-step cost by replacing property&nbsp;2 in <a href="#thm-reward-shaping">Theorem&nbsp;<span>8.1</span></a> by <span class="math display">\[ c^2_t(s,a) = c^1_t(s,a) + \sum_{s' \in \ALPHABET S} P_t(s'|s,a) Φ_{t+1}(s') -
Φ_t(s).\]</span></p></li></div></div>
<div id="thm-reward-shaping" class="theorem">
<p><span class="theorem-title"><strong>Theorem 8.1 </strong></span>Suppose the cost functions in MDPs <span class="math inline">\(M^1\)</span> and <span class="math inline">\(M^2\)</span> are related as follows:</p>
<ol type="1">
<li><p>For <span class="math inline">\(t = T\)</span>, <span class="math display">\[ c^2_T(s) = c^1_T(s) - Φ_T(s).  \]</span></p></li>
<li><p>For <span class="math inline">\(t \in \{1, \dots, T-1\}\)</span>, <span class="math display">\[ c^2_t(s,a,s_{+}) = c^1_t(s,a,s_{+}) +  Φ_{t+1}(s_{+}) - Φ_t(s). \]</span></p></li>
</ol>
<p>Then, for any policy <span class="math inline">\(π\)</span>, <span class="math display">\[\begin{equation}\label{eq:result}
    Q^{\pi,2}_t(s,a) = Q^{\pi,1}_t(s,a) - Φ_t(s)
    \quad\text{and}\quad
    V^{\pi,2}_t(s) = V^{\pi,1}_t(s) - Φ_t(s).
\end{equation}\]</span></p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sign of potential function
</div>
</div>
<div class="callout-body-container callout-body">
<p>The sign of the potential function is irrelevant. So, we could also have written <span class="math display">\[ c^2_t(s,a,s_{+}) = c^1_t(s,a,s_{+}) +  Φ_t(s) - Φ_{t+1}(s_{+}) \]</span> and argued that <span class="math display">\[  V^{\pi,2}_t(s) = V^{\pi,1}_t(s) + Φ_t(s).\]</span></p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We prove the result by backward induction. First note that <span class="math display">\[
  V^{\pi,2}_T(s) = c^2_T(s) = c^1_T(s) - Φ_T(s) = V^{\pi,1}_T(s) - Φ_T(s).
\]</span> This forms the basis of induction. Now suppose that \eqref{eq:result} holds for time <span class="math inline">\(t+1\)</span>. Now consider <span class="math display">\[\begin{align*}
Q^{\pi,2}_t(s,a) &amp;= \EXP[ c^2_t(s,a,S_{t+1}) + V^{\pi,2}_{t+1}(S_{t+1}) \mid S_t
= s, a ]
\\
&amp;\stackrel{(a)}= \EXP[ c^1_t(s,a,S_{t+1}) - Φ_t(s) + Φ_{t+1}(S_{t+1}) \\
&amp;\qquad + V^{\pi,1}_{t+1}(S_{t+1}) - Φ_{t+1}(S_{t+1}) \mid S_t = s, A_t = a ] \\
&amp;= \EXP[ c^1_t(s,a,S_{t+1}) - Φ_t(s) + V^1_{t+1}(S_{t+1}) \mid
S_t = s, A_t = a] \\
&amp;= Q^{\pi,1}_t(s,a) - Φ_t(s),
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from property 2 and the induction hypothesis.</p>
<p>Now, <span class="math display">\[ \begin{align*}
  V^{\pi,2}_t(s) &amp;= Q^{\pi,2}_t(s,\pi(s)) \\
  &amp;= Q^{\pi,1}_t(s,\pi(s) - Φ_t(s) \\
  &amp;= V^{\pi,1}_t(s) - Φ_t(s).
\end{align*}\]</span></p>
<p>This proves the induction step.</p>
</div>
</div>
</div>
<p>By almost an analogous argument, we can show that the optimal value functions also satisfy a similar relationship.</p>
<div id="cor-reward-shaping" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 8.1 </strong></span>Under conditions of <a href="#thm-reward-shaping">Theorem&nbsp;<span>8.1</span></a>, <span class="math display">\[\begin{equation}\label{eq:result-opt}
      Q^{2}_t(s,a) = Q^{1}_t(s,a) - Φ_t(s)
      \quad\text{and}\quad
      V^{2}_t(s) = V^{1}_t(s) - Φ_t(s).
  \end{equation}\]</span></p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advantage function
</div>
</div>
<div class="callout-body-container callout-body">
<p>The advantage (or benefit) function given by <span class="math display">\[ B_t(s,a) := Q_t(s,a) - V_t(s) \]</span> measures the relative cost of choosing action <span class="math inline">\(a\)</span> over the optimal action. An implication of \eqref{eq:result-opt} is that reward shaping does not change the advantage function!</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remark
</div>
</div>
<div class="callout-body-container callout-body">
<p>Another implication of <a href="#thm-reward-shaping">Theorem&nbsp;<span>8.1</span></a> and <a href="#cor-reward-shaping">Corollary&nbsp;<span>8.1</span></a> is that for any policy <span class="math inline">\(π\)</span>, <span class="math display">\[ V^{\pi,2}_t(s) - V^{2}_t(s) = V^{\pi,1}_t(s) - V^1_t(s). \]</span> Thus, reward shaping also preserves near-optimality; i.e., if a policy is approximately optimal in model <span class="math inline">\(M^1\)</span>, then it is approximately optimal in model <span class="math inline">\(M^2\)</span> as well.</p>
</div>
</div>
<section id="generalization-to-discounted-models" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="generalization-to-discounted-models"><span class="header-section-number">8.1</span> Generalization to discounted models</h2>
<p>Now consider a finite horizon discounted cost problem, where the performance of a policy <span class="math inline">\(π\)</span> is given by <span class="math display">\[
J(π) = \EXP\Bigl[ \sum_{t=1}^{T-1} γ^{t-1} c_t(S_t, A_t) + γ^T c_T(S_T)
       \Bigr].
\]</span> As argued in <a href="intro.html#discounted-cost">the introduction to discounted models</a>, the dynamic prgram for this case is given by</p>
<p><span class="math display">\[ V_{T}(s) = c_T(s) \]</span> and for <span class="math inline">\(t \in \{T-1, \dots, 1\}\)</span>: <span class="math display">\[ \begin{align*}
  Q_t(s,a) &amp;= c(s,a) + γ \EXP[ V_{t+1}(S_{t+1}) | S_t = s, A_t = a ], \\
  V_t(s) &amp;= \min_{a \in \ALPHABET A} Q_t(s,a).
\end{align*} \]</span></p>
<p>For such models, we have the following.</p>
<div id="cor-reward-shaping-discounted" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 8.2 </strong></span>For discounted cost models, the results of <a href="#thm-reward-shaping">Theorem&nbsp;<span>8.1</span></a> and <a href="#cor-reward-shaping">Corollary&nbsp;<span>8.1</span></a> continue to hold if condition 2 is replaced by</p>
<ol start="2" type="1">
<li><p>For <span class="math inline">\(t \in \{1, \dots, T-1\}\)</span>,</p>
<p><span class="math display">\[ c^2_t(s,a,s_{+}) = c^1_t(s,a,s_{+}) + γ Φ_{t+1}(s_{+}) - Φ_t(s). \]</span></p></li>
</ol>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Infinite horizon models
</div>
</div>
<div class="callout-body-container callout-body">
<p>If the cost function is time homogeneous, <a href="#cor-reward-shaping-discounted">Corollary&nbsp;<span>8.2</span></a> extends naturally to infinite horizon models with a time-homogeneous potential function. A remarkable feature is that if the potential function is chosen as the value function, i.e., <span class="math inline">\(Φ(s) = V(s)\)</span>, then the value function of the modified cost <span class="math inline">\(\tilde c(s,a,s_{+})\)</span> is zero!</p>
</div>
</div>
</section>
<section id="examples" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="examples"><span class="header-section-number">8.2</span> Examples</h2>
<p>As an example of reward shaping, see the notes on <a href="../../inf-mdp/inventory-management">inventory management</a>. Also see the notes on <a href="../../inf-mdp/martingale-approach">martingale approach to stochastic control</a> for an iteresting relationship between reward shaping and martingales.</p>
</section>
<section id="notes" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="notes">Notes</h2>
<p>The idea of <em>reward shaping</em> was proposed by <span class="citation" data-cites="Skinner1938">Skinner (<a href="../references.html#ref-Skinner1938" role="doc-biblioref">1938</a>)</span> to synthesize complex behavior by guiding animals to perform simple functions (see <a href="https://en.wikipedia.org/wiki/Operant_conditioning_chamber">:Skinner’s Box Experiment</a>). The formal description of reward shaping comes from <span class="citation" data-cites="Porteus1975">Porteus (<a href="../references.html#ref-Porteus1975" role="doc-biblioref">1975</a>)</span>, who established a result similar to <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span>, and called it the transformation method. <span class="citation" data-cites="Porteus1975">Porteus (<a href="../references.html#ref-Porteus1975" role="doc-biblioref">1975</a>)</span> also describes transformations of the dynamics which preserve the optimal policy.</p>
<p><a href="#cor-reward-shaping-discounted">Corollary&nbsp;<span>8.2</span></a> was also re-established by <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span>, who aslo provided a partial converse. The results of <span class="citation" data-cites="Porteus1975">Porteus (<a href="../references.html#ref-Porteus1975" role="doc-biblioref">1975</a>)</span> and <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span> were restricted to time-homogeneous potential functions. The generalization to time-varying potential functions was presented in <span class="citation" data-cites="Devlin2012">Devlin and Kudenko (<a href="../references.html#ref-Devlin2012" role="doc-biblioref">2012</a>)</span>.</p>
<p>The partial converse of <a href="#cor-reward-shaping">Corollary&nbsp;<span>8.1</span></a> established by <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span> states that the shaping presented in <a href="#thm-reward-shaping">Theorem&nbsp;<span>8.1</span></a> is the <em>only</em> additive cost transformation that that preserves the set of optimal policy. However, this converse was derived under the assumption that the transition dynamics are <em>complete</em> (see <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span>). A similar converse under a weaker set of assumptions on the transition dynamics is established in <span class="citation" data-cites="Jenner2022">Jenner et al. (<a href="../references.html#ref-Jenner2022" role="doc-biblioref">2022</a>)</span>.</p>
<p>For a discussion on practical considerations in using reward shaping in reinforcement learning, see <span class="citation" data-cites="Grzes2009">Grzes and Kudenko (<a href="../references.html#ref-Grzes2009" role="doc-biblioref">2009</a>)</span> and <span class="citation" data-cites="Devlin2014">Devlin (<a href="../references.html#ref-Devlin2014" role="doc-biblioref">2014</a>)</span>. As a counter-point, <span class="citation" data-cites="Wiewiora2003">Wiewiora (<a href="../references.html#ref-Wiewiora2003" role="doc-biblioref">2003</a>)</span> shows that the advantages of reward shaping can also be achieved by simply adding the potential function to the <span class="math inline">\(Q\)</span>-function initialization.</p>
<hr>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Devlin2014" class="csl-entry" role="listitem">
<span class="smallcaps">Devlin, S.</span> 2014. Potential based reward shaping tutorial. Available at: <a href="http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf">http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf</a>.
</div>
<div id="ref-Devlin2012" class="csl-entry" role="listitem">
<span class="smallcaps">Devlin, S. and Kudenko, D.</span> 2012. Dynamic potential-based reward shaping. <em>Proceedings of the 11th international conference on autonomous agents and multiagent systems</em>, International Foundation for Autonomous Agents; Multiagent Systems, 433–440.
</div>
<div id="ref-Grzes2009" class="csl-entry" role="listitem">
<span class="smallcaps">Grzes, M. and Kudenko, D.</span> 2009. Theoretical and empirical analysis of reward shaping in reinforcement learning. <em>International conference on machine learning and applications</em>, 337–344. DOI: <a href="https://doi.org/10.1109/ICMLA.2009.33">10.1109/ICMLA.2009.33</a>.
</div>
<div id="ref-Jenner2022" class="csl-entry" role="listitem">
<span class="smallcaps">Jenner, E., Hoof, H. van, and Gleave, A.</span> 2022. Calculus on MDPs: Potential shaping as a gradient. Available at: <a href="https://arxiv.org/abs/2208.09570v1">https://arxiv.org/abs/2208.09570v1</a>.
</div>
<div id="ref-Ng1999" class="csl-entry" role="listitem">
<span class="smallcaps">Ng, A.Y., Harada, D., and Russell, S.</span> 1999. Policy invariance under reward transformations: Theory and application to reward shaping. <em>ICML</em>, 278–287. Available at: <a href="http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf">http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf</a>.
</div>
<div id="ref-Porteus1975" class="csl-entry" role="listitem">
<span class="smallcaps">Porteus, E.L.</span> 1975. Bounds and transformations for discounted finite markov decision chains. <em>Operations Research</em> <em>23</em>, 4, 761–784. DOI: <a href="https://doi.org/10.1287/opre.23.4.761">10.1287/opre.23.4.761</a>.
</div>
<div id="ref-Skinner1938" class="csl-entry" role="listitem">
<span class="smallcaps">Skinner, B.F.</span> 1938. <em>Behavior of organisms</em>. Appleton-Century.
</div>
<div id="ref-Wiewiora2003" class="csl-entry" role="listitem">
<span class="smallcaps">Wiewiora, E.</span> 2003. Potential-based shaping and q-value initialization are equivalent. <em>Journal of Artificial Intelligence Research</em> <em>19</em>, 1, 205–208.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../mdps/power-delay-tradeoff.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../mdps/inf-horizon.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>