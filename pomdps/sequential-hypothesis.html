<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aditya Mahajan">
<meta name="dcterms.date" content="2023-06-07">
<meta name="description" content="ECES 506 (Stochastic Control and Decision Theory)">

<title>Course Notes - 17&nbsp; Sequential hypothesis testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../approx-mdps/approx-DP.html" rel="next">
<link href="../pomdps/intro.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      IND: "\\mathbb{I}",
      ONES: "\\mathbb{1}",
      reals: "\\mathbb{R}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      BELLMAN: "\\mathcal{B}",
      MISMATCH: "\\mathcal{D}",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      NORM: ["\\left\\lVert #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert #1 \\right\\rvert", 1],
      GRAD: "\\nabla"
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>
<script type="text/javascript" src="https://www.geogebra.org/apps/deployggb.js">
</script>


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="citation_title" content="[17]{.chapter-number}&nbsp; [Sequential hypothesis testing]{.chapter-title}">
<meta name="citation_author" content="Aditya Mahajan">
<meta name="citation_publication_date" content="2023-06-07">
<meta name="citation_cover_date" content="2023-06-07">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-06-07">
<meta name="citation_fulltext_html_url" content="https://adityam.github.io/stochastic-control//pomdps/sequential-hypothesis.html">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Course notes for ECSE 506 (Stochastic Control and Decision Theorey)">
<meta name="citation_reference" content="citation_title=A new interpretation of information rate;,citation_author=John L. Kelly;,citation_publication_date=1956-07;,citation_cover_date=1956-07;,citation_year=1956;,citation_issue=4;,citation_doi=10.1002/j.1538-7305.1956.tb03809.x;,citation_volume=35;,citation_journal_title=Bell System Technical Journal;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic programming and gambling models;,citation_author=Sheldon M. Ross;,citation_publication_date=1974-09;,citation_cover_date=1974-09;,citation_year=1974;,citation_issue=3;,citation_doi=10.2307/1426236;,citation_volume=6;,citation_journal_title=Advances in Applied Probability;,citation_publisher=Applied Probability Trust;">
<meta name="citation_reference" content="citation_title=Optimal inventory policy;,citation_author=Kenneth J Arrow;,citation_author=Theodore Harris;,citation_author=Jacob Marschak;,citation_publication_date=1952-01;,citation_cover_date=1952-01;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/1907830;,citation_volume=20;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=On the optimal inventory equation;,citation_author=Richard Bellman;,citation_author=Irving Glicksberg;,citation_author=Oliver Gross;,citation_publication_date=1955-10;,citation_cover_date=1955-10;,citation_year=1955;,citation_issue=1;,citation_doi=10.1287/mnsc.2.1.83;,citation_volume=2;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Memoryless strategies in finite-stage dynamic programming;,citation_author=David Blackwell;,citation_publication_date=1964-06;,citation_cover_date=1964-06;,citation_year=1964;,citation_issue=2;,citation_doi=10.1214/aoms/1177703586;,citation_volume=35;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=On the structure of real-time source coders;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=6;,citation_volume=58;,citation_journal_title=Bell System Technical Journal;">
<meta name="citation_reference" content="citation_title=Contributions to the theory of optimal control;,citation_author=Rudolf Emil Kalman;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_volume=5;,citation_journal_title=Boletin de la Sociedad Matematica Mexicana;">
<meta name="citation_reference" content="citation_title=Dynamic programming under uncertainty with a quadratic criterion function;,citation_author=Herbert A Simon;,citation_publication_date=1956-01;,citation_cover_date=1956-01;,citation_year=1956;,citation_issue=1;,citation_doi=10.2307/1905261;,citation_volume=24;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Econometric models and welfare maximization;,citation_author=Henri Theil;,citation_publication_date=1954;,citation_cover_date=1954;,citation_year=1954;,citation_doi=10.1007/978-94-011-2410-2_1;,citation_volume=72;,citation_journal_title=Wirtschaftliches Archiv;">
<meta name="citation_reference" content="citation_title=A note on certainty equivalence in dynamic planning;,citation_author=Henri Theil;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_doi=10.1007/978-94-011-2410-2_3;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Power and delay trade-offs in fading channels;,citation_author=Randall Alexander Berry;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_fulltext_html_url=https://dspace.mit.edu/handle/1721.1/9290;,citation_dissertation_institution=Massachusetts Institute of Technology;">
<meta name="citation_reference" content="citation_title=Communication over fading channels with delay constraints;,citation_author=Randall A Berry;,citation_author=Robert G Gallager;,citation_publication_date=2002-05;,citation_cover_date=2002-05;,citation_year=2002;,citation_issue=5;,citation_doi=10.1109/18.995554;,citation_volume=48;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal power-delay tradeoffs in fading channels—small-delay asymptotics;,citation_author=Randall A Berry;,citation_publication_date=2013-06;,citation_cover_date=2013-06;,citation_year=2013;,citation_issue=6;,citation_doi=10.1109/TIT.2013.2253194;,citation_volume=59;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Evaluating a call option and optimal timing strategy in the stock market;,citation_author=Howard M. Taylor;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_fulltext_html_url=http://www.jstor.org/stable/2628546;,citation_issue=1;,citation_issn=00251909, 15265501;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Optimal stopping and applications;,citation_author=Thomas S. Ferguson;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_fulltext_html_url=http://www.math.ucla.edu/~tom/Stopping/Contents.html;">
<meta name="citation_reference" content="citation_title=Who solved the secretary problem?;,citation_author=Thomas S Ferguson;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_journal_title=Statistical science;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Characterizing the structure of optimal stopping policies;,citation_author=Sechan Oh;,citation_author=Özalp Özer;,citation_publication_date=2016-07;,citation_cover_date=2016-07;,citation_year=2016;,citation_issue=11;,citation_doi=10.1111/poms.12579;,citation_volume=25;,citation_journal_title=Production and Operations Management;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Markov decision processes: Discrete stochastic dynamic programming;,citation_author=Martin L Puterman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_doi=10.1002/9780470316887;">
<meta name="citation_reference" content="citation_title=Optimization over time: Dynamic programming and stochastic control. Vol. 1 and 2;,citation_author=Peter Whittle;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;">
<meta name="citation_reference" content="citation_title=Optimal control: Basics and beyond;,citation_author=Peter Whittle;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Dynamic programming and optimal control;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.athenasc.com/dpbook.html;,citation_volume=I and II;">
<meta name="citation_reference" content="citation_title=Abstract dynamic programming;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://web.mit.edu/dimitrib/www/abstractdp_MIT.html;">
<meta name="citation_reference" content="citation_title=Introduction to stochastic control theory;,citation_author=Karl J. Aström;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;">
<meta name="citation_reference" content="citation_title=Policy invariance under reward transformations: Theory and application to reward shaping;,citation_author=Andrew Y Ng;,citation_author=Daishi Harada;,citation_author=Stuart Russell;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf;,citation_volume=99;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Theoretical and empirical analysis of reward shaping in reinforcement learning;,citation_author=M. Grzes;,citation_author=D. Kudenko;,citation_publication_date=2009-12;,citation_cover_date=2009-12;,citation_year=2009;,citation_doi=10.1109/ICMLA.2009.33;,citation_conference_title=International conference on machine learning and applications;">
<meta name="citation_reference" content="citation_title=Potential based reward shaping tutorial;,citation_author=Sam Devlin;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf;">
<meta name="citation_reference" content="citation_title=How many parts to make at once;,citation_author=Ford W Harris;,citation_publication_date=1913-02;,citation_cover_date=1913-02;,citation_year=1913;,citation_issue=2;,citation_doi=10.1287/opre.38.6.947;,citation_volume=10;,citation_journal_title=The magazine of management;">
<meta name="citation_reference" content="citation_title=The mathematical theory of banking;,citation_author=Francis Y Edgeworth;,citation_publication_date=1888;,citation_cover_date=1888;,citation_year=1888;,citation_fulltext_html_url=https://www.jstor.org/stable/2979084;,citation_issue=1;,citation_volume=51;,citation_journal_title=Journal of the Royal Statistical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Methods of operations research;,citation_author=P. Morse;,citation_author=G. Kimball;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;">
<meta name="citation_reference" content="citation_title=The theory of inventory management;,citation_author=S. Whitin;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;">
<meta name="citation_reference" content="citation_title=Building intuition: Insights from basic operations management models and principles;,citation_author=Evan L. Porteus;,citation_editor=D. Chhajed;,citation_editor=T. J. Lowe;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=10.1007/978-0-387-73699-0;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Selling random wind;,citation_author=Eilyan Bitar;,citation_author=Kameshwar Poolla;,citation_author=Pramod Khargonekar;,citation_author=Ram Rajagopal;,citation_author=Pravin Varaiya;,citation_author=Felix Wu;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 45th hawaii international conference on system sciences;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Fundamental performance limits in cross-layer wireless optimization: Throughput, delay, and energy;,citation_author=Edmund M. Yeh;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_doi=10.1561/0100000014;,citation_issn=1567-2190;,citation_volume=9;,citation_journal_title=Foundations and Trends in Communications and Information Theory;">
<meta name="citation_reference" content="citation_title=Energy-efficient scheduling under delay constraints for wireless networks;,citation_author=Randall Berry;,citation_author=Eytan Modiano;,citation_author=Murtaza Zafer;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_doi=10.2200/S00443ED1V01Y201208CNT011;,citation_volume=5;,citation_journal_title=Synthesis Lectures on Communication Networks;">
<meta name="citation_reference" content="citation_title=Stochastic dominance: Investment decision making under uncertainty;,citation_author=Haim Levy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_doi=10.1007/978-3-319-21708-6;">
<meta name="citation_reference" content="citation_title=Stochastic dominance and expected utility: Survey and analysis;,citation_author=Haim Levy;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_doi=10.1287/mnsc.38.4.555;,citation_volume=38;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Stochastically monotone markov chains;,citation_author=D J Daley;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=4;,citation_doi=10.1007/BF00531852;,citation_volume=10;,citation_journal_title=Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Monotone matrices and monotone markov processes;,citation_author=Julian Keilson;,citation_author=Adri Kester;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=3;,citation_volume=5;,citation_journal_title=Stochastic Processes and their Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=On monotonicity of the optimal transmission policy in cross-layer adaptive m -QAM modulation;,citation_author=N. Ding;,citation_author=P. Sadeghi;,citation_author=R. A. Kennedy;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=9;,citation_doi=10.1109/TCOMM.2016.2590427;,citation_issn=1558-0857;,citation_volume=64;,citation_journal_title=IEEE Transactions on Communications;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity in economics: An elementary survey;,citation_author=Rabah Amir;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=3;,citation_doi=10.2307/20062066;,citation_issn=00384038;,citation_volume=71;,citation_journal_title=Southern Economic Journal;,citation_publisher=Southern Economic Association;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity;,citation_author=Donald M. Topkis;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_isbn=9780691032443;">
<meta name="citation_reference" content="citation_title=Sufficient conditions for the value function and optimal strategy to be even and quasi-convex;,citation_author=J. Chakravorty;,citation_author=A. Mahajan;,citation_publication_date=2018-11;,citation_cover_date=2018-11;,citation_year=2018;,citation_issue=11;,citation_doi=10.1109/TAC.2018.2800796;,citation_issn=2334-3303;,citation_volume=63;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=On the locality of action domination in sequential decision making;,citation_author=Emmanuel Rachelson;,citation_author=Michail G Lagoudakis;,citation_publication_date=2010-01;,citation_cover_date=2010-01;,citation_year=2010;,citation_fulltext_html_url=https://oatao.univ-toulouse.fr/17977/;,citation_conference_title=Proceedings of 11th international symposium on artificial intelligence and mathematics;">
<meta name="citation_reference" content="citation_title=Lipschitz continuity of value functions in Markovian decision processes;,citation_author=Karl Hinderer;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_doi=10.1007/s00186-005-0438-1;,citation_volume=62;,citation_journal_title=Mathematical Methods of Operations Research;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=DeepMDP: Learning continuous latent space models for representation learning;,citation_author=Carles Gelada;,citation_author=Saurabh Kumar;,citation_author=Jacob Buckman;,citation_author=Ofir Nachum;,citation_author=Marc G. Bellemare;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=http://proceedings.mlr.press/v97/gelada19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Convergence of discretization procedures in dynamic programming;,citation_author=Demitri Bertsekas;,citation_publication_date=1975-06;,citation_cover_date=1975-06;,citation_year=1975;,citation_issue=3;,citation_doi=10.1109/TAC.1975.1100984;,citation_issn=2334-3303;,citation_volume=20;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=Towards a unified theory of state abstraction for MDPs;,citation_author=Lihong Li;,citation_author=Thomas J Walsh;,citation_author=Michael L Littman;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://anytime.cs.umass.edu/aimath06/proceedings/P21.pdf;,citation_conference_title=ISAIM;">
<meta name="citation_reference" content="citation_title=Death and discounting;,citation_author=A. Shwartz;,citation_publication_date=2001-04;,citation_cover_date=2001-04;,citation_year=2001;,citation_fulltext_html_url=https://doi.org/10.1109/9.917668;,citation_issue=4;,citation_doi=10.1109/9.917668;,citation_volume=46;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Constrained markov decision processes;,citation_author=Eitan. Altman;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://www-sop.inria.fr/members/Eitan.Altman/TEMP/h.pdf;">
<meta name="citation_reference" content="citation_title=Optimal investment policies for the horse race model&amp;amp;amp;quot;;,citation_author=Thomas S. Ferguson;,citation_author=C. Zachary Gilstein;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=https://www.math.ucla.edu/~tom/papers/unpublished/Zach2.pdf;">
<meta name="citation_reference" content="citation_title=Discovery of the kalman filter as a practical tool for aerospace and;,citation_author=Stanley F. Mcgee;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_fulltext_html_url=https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19860003843.pdf;,citation_technical_report_institution=National Aeronautics; Space Administration;">
<meta name="citation_reference" content="citation_title=Stochastic systems: Estimation identification and adaptive control;,citation_author=P. R. Kumar;,citation_author=Pravin Varaiya;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;">
<meta name="citation_reference" content="citation_title=Stochastic dynamic programming and the control of queueing systems;,citation_author=Linn I. Sennott;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_isbn=0-471-16120-9;">
<meta name="citation_reference" content="citation_title=Discrete-time controlled Markov processes with average cost criterion - a survey;,citation_author=Aristotle Arapostathis;,citation_author=Vivek S. Borkar;,citation_author=Emmaneul Fernandez-Gaucherand;,citation_author=Mrinak K. Ghosh;,citation_author=Steven I. Marcus;,citation_publication_date=1993-03;,citation_cover_date=1993-03;,citation_year=1993;,citation_issue=2;,citation_volume=31;,citation_journal_title=SIAM Journal of Control and Optimization;">
<meta name="citation_reference" content="citation_title=The optimal control of partially observable markov processes over a finite horizon;,citation_author=Richard D. Smallwood;,citation_author=Edward J. Sondik;,citation_publication_date=1973-10;,citation_cover_date=1973-10;,citation_year=1973;,citation_issue=5;,citation_doi=10.1287/opre.21.5.1071;,citation_volume=21;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Convex analytic methods in markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_11;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=A convex analytic approach to markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=1988-08;,citation_cover_date=1988-08;,citation_year=1988;,citation_issue=4;,citation_doi=10.1007/bf00353877;,citation_volume=78;,citation_journal_title=Probability Theory and Related Fields;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Applications of markov decision processes in communication networks;,citation_author=Eitan Altman;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_16;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Water reservoir applications of markov decision processes;,citation_author=Bernard F. Lamond;,citation_author=Abdeslem Boukhtouta;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_17;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Asymptotically efficient adaptive allocation rules;,citation_author=T. L Lai;,citation_author=Herbert Robbins;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_issue=1;,citation_doi=http://dx.doi.org/10.1016/0196-8858(85)90002-8;,citation_issn=0196-8858;,citation_volume=6;,citation_journal_title=Advances in Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Dynamic programming;,citation_author=Richard Bellman;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;">
<meta name="citation_reference" content="citation_title=A dynamic allocation index for the discounted multiarmed bandit problem;,citation_author=J. C. Gittins;,citation_author=D. M. Jones;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_volume=9;,citation_inbook_title=Progress in statistics;">
<meta name="citation_reference" content="citation_title=Bandit processes and dynamic allocation indices;,citation_author=John C Gittins;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=2;,citation_volume=41;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits and the Gittins index;,citation_abstract=A plausible conjecture (C) has the implication that a relationship (12) holds between the maximal expected rewards for a multi-project process and for a one-project process (F and Ï&amp;amp;amp;lt;sub&amp;gt;i&amp;lt;/sub&amp;gt; respectively), if the option of retirement with reward M is available. The validity of this relation and optimality of Gittins’ index rule are verified simultaneously by dynamic programming methods. These results are partially extended to the case of so-called &amp;quot;bandit superprocesses&amp;quot;.;,citation_author=P. Whittle;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=2;,citation_issn=00359246;,citation_volume=42;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=[Royal Statistical Society, Wiley];">
<meta name="citation_reference" content="citation_title=Four proofs of Gittins’ multiarmed bandit theorem;,citation_abstract=We study four proofs that the Gittins index priority rule is optimal for alternative bandit processes. These include Gittins’ original exchange argument, Weber’s prevailing charge argument, Whittle’s Lagrangian dual approach, and Bertsimas and Niño-Mora’s proof based on the achievable region approach and generalized conservation laws. We extend the achievable region proof to infinite countable state spaces, by using infinite dimensional linear programming theory.;,citation_author=Esther Frostig;,citation_author=Gideon Weiss;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=http://dx.doi.org/10.1007/s10479-013-1523-0;,citation_issue=1;,citation_doi=10.1007/s10479-013-1523-0;,citation_issn=1572-9338;,citation_volume=241;,citation_journal_title=Annals of Operations Research;">
<meta name="citation_reference" content="citation_title=The multi-armed bandit problem: Decomposition and computation;,citation_author=Michael N Katehakis;,citation_author=Arthur F Veinott;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=2;,citation_volume=12;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits under general deprecation and commitment;,citation_author=Wesley Cowan;,citation_author=Michael N. Katehakis;,citation_publication_date=2015-10;,citation_cover_date=2015-10;,citation_year=2015;,citation_issue=1;,citation_doi=10.1017/s0269964814000217;,citation_volume=29;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Restless bandits: Activity allocation in a changing world;,citation_author=Peter Whittle;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=A;,citation_volume=25;,citation_journal_title=Journal of applied probability;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=Foundations and applications of sensor management;,citation_author=A. Mahajan;,citation_author=D. Teneketzis;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Two characterizations of optimality in dynamic programming;,citation_author=Ioannis Karatzas;,citation_author=William D. Sudderth;,citation_publication_date=2010-11;,citation_cover_date=2010-11;,citation_year=2010;,citation_issue=3;,citation_doi=10.1007/s00245-009-9093-x;,citation_volume=61;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Structural properties of stochastic dynamic programs;,citation_author=James E. Smith;,citation_author=Kevin F. McCardle;,citation_publication_date=2002-10;,citation_cover_date=2002-10;,citation_year=2002;,citation_issue=5;,citation_doi=10.1287/opre.50.5.796.365;,citation_volume=50;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Monotonicity in multidimensional markov decision processes for the batch dispatch problem;,citation_author=Katerina Papadaki;,citation_author=Warren B. Powell;,citation_publication_date=2007-03;,citation_cover_date=2007-03;,citation_year=2007;,citation_issue=2;,citation_doi=10.1016/j.orl.2006.03.013;,citation_volume=35;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Basic ideas for event-based optimization of markov systems;,citation_author=Xi-Ren Cao;,citation_publication_date=2005-06;,citation_cover_date=2005-06;,citation_year=2005;,citation_issue=2;,citation_doi=10.1007/s10626-004-6211-4;,citation_volume=15;,citation_journal_title=Discrete Event Dynamic Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Monotonicity in markov reward and decision chains: Theory and applications;,citation_author=Ger Koole;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_doi=10.1561/0900000002;,citation_volume=1;,citation_journal_title=Foundations and Trends in Stochastic Systems;,citation_publisher=Now Publishers;">
<meta name="citation_reference" content="citation_title=Stochastic learning and optimization;,citation_author=Xi-Ren Cao;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-0-387-69082-7;">
<meta name="citation_reference" content="citation_title=Optimality and approximation with policy gradient methods in markov decision processes;,citation_abstract=Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution (say with a sufficiently rich policy class); how they cope with approximation error due to using a restricted class of parametric policies; or their finite sample behavior. Such characterizations are important not only to compare these methods to their approximate value function counterparts (where such issues are relatively well understood, at least in the worst case), but also to help with more principled approaches to algorithm design. This work provides provable characterizations of computational, approximation, and sample size issues with regards to policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: 1) &amp;amp;amp;quot;tabular&amp;quot; policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy, and 2) restricted policy classes, which may not contain the optimal policy and where we provide agnostic learning results. One insight of this work is in formalizing the importance how a favorable initial state distribution provides a means to circumvent worst-case exploration issues. Overall, these results place policy gradient methods under a solid theoretical footing, analogous to the global convergence guarantees of iterative value function based algorithms.;,citation_author=Alekh Agarwal;,citation_author=Sham M. Kakade;,citation_author=Jason D. Lee;,citation_author=Gaurav Mahajan;,citation_publication_date=2019-08-01;,citation_cover_date=2019-08-01;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1908.00261v2;">
<meta name="citation_reference" content="citation_title=Analysis of stochastic dual dynamic programming method;,citation_author=Alexander Shapiro;,citation_publication_date=2011-02;,citation_cover_date=2011-02;,citation_year=2011;,citation_issue=1;,citation_doi=10.1016/j.ejor.2010.08.007;,citation_volume=209;,citation_journal_title=European Journal of Operational Research;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Multi-stage stochastic optimization applied to energy planning;,citation_author=M. V. F. Pereira;,citation_author=L. M. V. G. Pinto;,citation_publication_date=1991-05;,citation_cover_date=1991-05;,citation_year=1991;,citation_issue=1-3;,citation_doi=10.1007/bf01582895;,citation_volume=52;,citation_journal_title=Mathematical Programming;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Approximate information state for partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Aditya Mahajan;,citation_publication_date=2019-12;,citation_cover_date=2019-12;,citation_year=2019;,citation_doi=10.1109/cdc40024.2019.9029898;,citation_conference_title=2019 IEEE 58th conference on decision and control (CDC);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Approximate information state for approximate planning and reinforcement learning in partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Amit Sinha;,citation_author=Raihan Seraj;,citation_author=Aditya Mahajan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=http://jmlr.org/papers/v23/20-1165.html;,citation_issue=12;,citation_volume=23;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=On policy independence of conditional expectation;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_volume=28;,citation_journal_title=Information and Control;">
<meta name="citation_reference" content="citation_title=Incremental pruning: A simple, fast, exact method for partially observable Markov decision processes;,citation_author=Anthony Cassandra;,citation_author=Michael L. Littman;,citation_author=Nevin L. Zhang;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_conference_title=Proceedings of the thirteenth conference on uncertainty in artificial intelligence;">
<meta name="citation_reference" content="citation_title=Partially observable Markov decision processes: A geometric technique and analysis;,citation_author=H. Zhang;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Operations Research;">
<meta name="citation_reference" content="citation_title=Algorithms for partially observable markov decision processes;,citation_author=Hsien-Te Cheng;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_dissertation_institution=University of British Columbia;">
<meta name="citation_reference" content="citation_title=Acting optimally in partially observable stochastic domains;,citation_author=Anthony R Cassandra;,citation_author=Leslie Pack Kaelbling;,citation_author=Michael L Littman;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_volume=94;,citation_conference_title=AAAI;">
<meta name="citation_reference" content="citation_title=Planning in stochastic domains: Problem characteristics and approximation;,citation_author=N Zhang;,citation_author=W Liu;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_technical_report_institution=Hong Kong Univeristy of Science; Technology;,citation_technical_report_number=HKUST-CS96-31;">
<meta name="citation_reference" content="citation_title=Sequential tests of statistical hypotheses;,citation_author=A. Wald;,citation_publication_date=1945-06;,citation_cover_date=1945-06;,citation_year=1945;,citation_issue=2;,citation_doi=10.1214/aoms/1177731118;,citation_volume=16;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bayes and minimax solutions of sequential decision problems;,citation_author=K. J. Arrow;,citation_author=D. Blackwell;,citation_author=M. A. Girshick;,citation_publication_date=1949-07;,citation_cover_date=1949-07;,citation_year=1949;,citation_issue=3/4;,citation_doi=10.2307/1905525;,citation_volume=17;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Optimal statistical decisions;,citation_author=Morris DeGroot;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_isbn=047168029X;">
<meta name="citation_reference" content="citation_title=On a test whether two samples are from the same population;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1940-06;,citation_cover_date=1940-06;,citation_year=1940;,citation_issue=2;,citation_doi=10.1214/aoms/1177731909;,citation_volume=11;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Optimum character of the sequential probability ratio test;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1948-09;,citation_cover_date=1948-09;,citation_year=1948;,citation_issue=3;,citation_doi=10.1214/aoms/1177730197;,citation_volume=19;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=A stochastic sensor selection scheme for sequential hypothesis testing with multiple sensors;,citation_author=Cheng-Zong Bai;,citation_author=Vaibhav Katewa;,citation_author=Vijay Gupta;,citation_author=Yih-Fang Huang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=14;,citation_volume=63;,citation_journal_title=IEEE transactions on signal processing;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=A discrete markov chain representation of the sequential probability ratio test;,citation_author=Willam H. Woodall;,citation_author=Marion R. Reynolds;,citation_publication_date=1983-01;,citation_cover_date=1983-01;,citation_year=1983;,citation_issue=1;,citation_doi=10.1080/07474948308836025;,citation_volume=2;,citation_journal_title=Communications in Statistics. Part C: Sequential Analysis;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Mean-field games with a major player;,citation_author=Jean-Michel Lasry;,citation_author=Pierre-Louis Lions;,citation_publication_date=2018-08;,citation_cover_date=2018-08;,citation_year=2018;,citation_issue=8;,citation_doi=10.1016/j.crma.2018.06.001;,citation_volume=356;,citation_journal_title=Comptes Rendus Mathematique;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Remote estimation over a packet-drop channel with markovian state;,citation_author=Jhelum Chakravorty;,citation_author=Aditya Mahajan;,citation_publication_date=2020-05;,citation_cover_date=2020-05;,citation_year=2020;,citation_issue=5;,citation_doi=10.1109/tac.2019.2926160;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal state estimation in the presence of communication costs and packet drops;,citation_author=Gabriel M. Lipsa;,citation_author=Nuno C. Martins;,citation_publication_date=2009-09;,citation_cover_date=2009-09;,citation_year=2009;,citation_doi=10.1109/allerton.2009.5394899;,citation_conference_title=Annual allerton conference on communication, control, and computing (allerton);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Remote state estimation with communication costs for first-order LTI systems;,citation_author=G. M. Lipsa;,citation_author=N. C. Martins;,citation_publication_date=2011-09;,citation_cover_date=2011-09;,citation_year=2011;,citation_issue=9;,citation_doi=10.1109/tac.2011.2139370;,citation_volume=56;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Policy improvement and the newton-raphson algorithm;,citation_author=P. Whittle;,citation_author=N. Komarova;,citation_publication_date=1988-04;,citation_cover_date=1988-04;,citation_year=1988;,citation_issue=2;,citation_doi=10.1017/s0269964800000760;,citation_volume=2;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Optimal adaptive control of linear-quadratic-gaussian systems;,citation_author=P. R. Kumar;,citation_publication_date=1983-03;,citation_cover_date=1983-03;,citation_year=1983;,citation_issue=2;,citation_doi=10.1137/0321009;,citation_volume=21;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=The optimal inventory policy for batch ordering;,citation_author=Arthur F. Veinott;,citation_publication_date=1965-06;,citation_cover_date=1965-06;,citation_year=1965;,citation_issue=3;,citation_doi=10.1287/opre.13.3.424;,citation_volume=13;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Elements of game theory;,citation_author=Ye S. Venttsel;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_fulltext_html_url=https://archive.org/details/ElementsOfGameTheorylittleMathematicsLibrary/;">
<meta name="citation_reference" content="citation_title=Periodic review inventory systems with continuous demand and discrete order sizes;,citation_author=John N. Tsitsiklis;,citation_publication_date=1984-10;,citation_cover_date=1984-10;,citation_year=1984;,citation_issue=10;,citation_doi=10.1287/mnsc.30.10.1250;,citation_volume=30;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Risk sensitivity, A strangely pervasive concept;,citation_author=Peter Whittle;,citation_publication_date=2002-02;,citation_cover_date=2002-02;,citation_year=2002;,citation_issue=1;,citation_doi=10.1017/s1365100502027025;,citation_volume=6;,citation_journal_title=Macroeconomic Dynamics;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Risk-sensitive markov decision processes;,citation_author=Ronald A. Howard;,citation_author=James E. Matheson;,citation_publication_date=1972-03;,citation_cover_date=1972-03;,citation_year=1972;,citation_issue=7;,citation_doi=10.1287/mnsc.18.7.356;,citation_volume=18;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Inequalities: Theory of majorization and its applications;,citation_author=Albert W. Marshall;,citation_author=Ingram Olkin;,citation_author=Barry C. Arnold;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_doi=10.1007/978-0-387-68276-1;">
<meta name="citation_reference" content="citation_title=Risk sensitive control of markov processes in countable state space;,citation_author=Daniel Hernandez-Hernández;,citation_author=Steven I. Marcus;,citation_publication_date=1996-11;,citation_cover_date=1996-11;,citation_year=1996;,citation_issue=3;,citation_doi=10.1016/s0167-6911(96)00051-5;,citation_volume=29;,citation_journal_title=Systems &amp;amp;amp; Control Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Existence of risk-sensitive optimal stationary policies for controlled markov processes;,citation_author=D. Hernández-Hernández;,citation_publication_date=1999-11;,citation_cover_date=1999-11;,citation_year=1999;,citation_issue=3;,citation_doi=10.1007/s002459900126;,citation_volume=40;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Convex risk measures;,citation_author=Hans Föllmer;,citation_author=Alexander Schied;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470061602.eqf15003;,citation_doi=10.1002/9780470061602.eqf15003;,citation_isbn=9780470061602;,citation_inbook_title=Encyclopedia of quantitative finance;">
<meta name="citation_reference" content="citation_title=Updating the inverse of a matrix;,citation_author=William W. Hager;,citation_publication_date=1989-06;,citation_cover_date=1989-06;,citation_year=1989;,citation_issue=2;,citation_doi=10.1137/1031049;,citation_volume=31;,citation_journal_title=SIAM Review;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=A stochastic approximation method;,citation_author=Herbert Robbins;,citation_author=Sutton Monro;,citation_publication_date=1951-09;,citation_cover_date=1951-09;,citation_year=1951;,citation_issue=3;,citation_doi=10.1214/aoms/1177729586;,citation_volume=22;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=The o.d.e. Method for convergence of stochastic approximation and reinforcement learning;,citation_author=V. S. Borkar;,citation_author=S. P. Meyn;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=2;,citation_doi=10.1137/s0363012997331639;,citation_volume=38;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Q-learning;,citation_author=Christopher J. C. H. Watkins;,citation_author=Peter Dayan;,citation_publication_date=1992-05;,citation_cover_date=1992-05;,citation_year=1992;,citation_issue=3-4;,citation_doi=10.1007/bf00992698;,citation_volume=8;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Asynchronous stochastic approximation and q-learning;,citation_author=John N. Tsitsiklis;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993306;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=An analog scheme for fixed point computation. I. theory;,citation_author=V. S. Borkar;,citation_author=K. Soumyanatha;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=4;,citation_doi=10.1109/81.563625;,citation_volume=44;,citation_journal_title=IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the convergence of stochastic iterative dynamic programming algorithms;,citation_author=Tommi Jaakkola;,citation_author=Michael I. Jordan;,citation_author=Satinder P. Singh;,citation_publication_date=1994-11;,citation_cover_date=1994-11;,citation_year=1994;,citation_issue=6;,citation_doi=10.1162/neco.1994.6.6.1185;,citation_volume=6;,citation_journal_title=Neural Computation;,citation_publisher=MIT Press - Journals;">
<meta name="citation_reference" content="citation_title=Dynamic programming and markov processes;,citation_author=Ronald A. Howard;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and martingale inequalities: A survey;,citation_author=Fan Chung;,citation_author=Linyuan Lu;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=https://projecteuclid.org:443/euclid.im/1175266369;,citation_issue=1;,citation_volume=3;,citation_journal_title=Internet Math.;,citation_publisher=A K Peters, Ltd.;">
<meta name="citation_reference" content="citation_title=On the fenchel duality between strong convexity and lipschitz continuous gradient;,citation_abstract=We provide a simple proof for the Fenchel duality between strong convexity and Lipschitz continuous gradient. To this end, we first establish equivalent conditions of convexity for a general function that may not be differentiable. By utilizing these equivalent conditions, we can directly obtain equivalent conditions for strong convexity and Lipschitz continuous gradient. Based on these results, we can easily prove Fenchel duality. Beside this main result, we also identify several conditions that are implied by strong convexity or Lipschitz continuous gradient, but are not necessarily equivalent to them. This means that these conditions are more general than strong convexity or Lipschitz continuous gradient themselves.;,citation_author=Xingyu Zhou;,citation_publication_date=2018-03-17;,citation_cover_date=2018-03-17;,citation_year=2018;,citation_fulltext_html_url=https://arxiv.org/abs/1803.06573v1;">
<meta name="citation_reference" content="citation_title=Optimal control of markov processes with incomplete state information;,citation_author=K. J Åström;,citation_publication_date=1965-02;,citation_cover_date=1965-02;,citation_year=1965;,citation_issue=1;,citation_doi=10.1016/0022-247x(65)90154-x;,citation_volume=10;,citation_journal_title=Journal of Mathematical Analysis and Applications;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Dynamic service migration in mobile edge computing based on Markov decision process;,citation_author=Shiqiang Wang;,citation_author=Rahul Urgaonkar;,citation_author=Murtaza Zafer;,citation_author=Ting He;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_issue=3;,citation_doi=10.1109/tnet.2019.2916577;,citation_volume=27;,citation_journal_title=IEEE/ACM Transactions on Networking;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic service migration and workload scheduling in edge-clouds;,citation_author=Rahul Urgaonkar;,citation_author=Shiqiang Wang;,citation_author=Ting He;,citation_author=Murtaza Zafer;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_doi=10.1016/j.peva.2015.06.013;,citation_volume=91;,citation_journal_title=Performance Evaluation;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=The role and use of the stochastic linear-quadratic-gaussian problem in control system design;,citation_author=M. Athans;,citation_publication_date=1971-12;,citation_cover_date=1971-12;,citation_year=1971;,citation_issue=6;,citation_doi=10.1109/tac.1971.1099818;,citation_volume=16;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Complexity bounds for approximately solving discounted MDPs by value iterations;,citation_author=Eugene A. Feinberg;,citation_author=Gaojin He;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_doi=10.1016/j.orl.2020.07.001;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=How does the value function of a markov decision process depend on the transition probabilities?;,citation_author=Alfred Müller;,citation_publication_date=1997-11;,citation_cover_date=1997-11;,citation_year=1997;,citation_issue=4;,citation_doi=10.1287/moor.22.4.872;,citation_volume=22;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=What is RKHS?;,citation_author=Dino Sejdinovic;,citation_author=Arthur Gretton;,citation_fulltext_html_url=http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf;">
<meta name="citation_reference" content="citation_title=Martingale methods in stochastic control;,citation_author=M. H. A. Davis;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_doi=10.1007/bfb0009377;,citation_inbook_title=Stochastic control theory and stochastic differential systems;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and model selection;,citation_author=Jean Picard;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-3-540-48503-2;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Phillippe Rigollet;,citation_publication_date=2015-07;,citation_cover_date=2015-07;,citation_year=2015;,citation_fulltext_html_url=https://ocw.mit.edu/courses/mathematics/18-s997-high-dimensional-statistics-spring-2015/lecture-notes/;">
<meta name="citation_reference" content="citation_title=Subgaussian random variables: An expository note;,citation_author=Omar Rivasplata;,citation_publication_date=2012-11;,citation_cover_date=2012-11;,citation_year=2012;,citation_fulltext_html_url=http://stat.cmu.edu/~arinaldo/36788/subgaussians.pdf;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Martin J. Wainwright;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_doi=10.1017/9781108627771;">
<meta name="citation_reference" content="citation_title=Selecting computations: Theory and applications;,citation_author=Nicholas Hay;,citation_author=S. Russell;,citation_author=David Tolpin;,citation_author=S. E. Shimony;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=http://www.auai.org/uai2012/papers/123.pdf;,citation_conference_title=UAI;">
<meta name="citation_reference" content="citation_title=On linear control theory;,citation_author=D. Peter Joseph;,citation_author=T. Julius Tou;,citation_publication_date=1961;,citation_cover_date=1961;,citation_year=1961;,citation_issue=4;,citation_doi=10.1109/tai.1961.6371743;,citation_volume=80;,citation_journal_title=Transactions of the American Institute of Electrical Engineers, Part II: Applications and Industry;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the separation theorem of stochastic control;,citation_author=W. M. Wonham;,citation_publication_date=1968-05;,citation_cover_date=1968-05;,citation_year=1968;,citation_issue=2;,citation_doi=10.1137/0306023;,citation_volume=6;,citation_journal_title=SIAM Journal on Control;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Some comments on a theorem of Hardy and Littlewood;,citation_author=R. Sznajder;,citation_author=J. A. Filar;,citation_publication_date=1992-10;,citation_cover_date=1992-10;,citation_year=1992;,citation_issue=1;,citation_doi=10.1007/bf00939913;,citation_volume=75;,citation_journal_title=Journal of Optimization Theory and Applications;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Notes on the theory of series (XVI): Two Tauberian theorems;,citation_author=G. H. Hardy;,citation_author=J. E. Littlewood;,citation_publication_date=1931-10;,citation_cover_date=1931-10;,citation_year=1931;,citation_issue=4;,citation_doi=10.1112/jlms/s1-6.4.281;,citation_volume=s1-6;,citation_journal_title=Journal of the London Mathematical Society;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=The Hardy-Littlewood theorems;,citation_author=Jacob Korevaar;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_doi=10.1007/978-3-662-10225-1_1;,citation_inbook_title=Tauberian theory: A century of developments;">
<meta name="citation_reference" content="citation_title=Monotone optimal policies for markov decision processes;,citation_author=Richard F. Serfozo;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_doi=10.1007/bfb0120752;,citation_inbook_title=Mathematical programming studies;">
<meta name="citation_reference" content="citation_title=Cross-layer communication over fading channels with adaptive decision feedback;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_author=Edmund Yeh;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=International symposium on modeling and optimization in mobile, ad hoc, and wireless networks (WiOPT);">
<meta name="citation_reference" content="citation_title=Counterexamples on the monotonicity of delay optimal strategies for energy harvesting transmitters;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.1109/lwc.2020.2981066;,citation_journal_title=IEEE Wireless Communications Letters;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Q-learning for MDPs with general spaces: Convergence and near optimality via quantization under weak continuity;,citation_abstract=Reinforcement learning algorithms often require finiteness of state and action spaces in Markov decision processes (MDPs) and various efforts have been made in the literature towards the applicability of such algorithms for continuous state and action spaces. In this paper, we show that under very mild regularity conditions (in particular, involving only weak continuity of the transition kernel of an MDP), Q-learning for standard Borel MDPs via quantization of states and actions converge to a limit, and furthermore this limit satisfies an optimality equation which leads to near optimality with either explicit performance bounds or which are guaranteed to be asymptotically optimal. Our approach builds on (i) viewing quantization as a measurement kernel and thus a quantized MDP as a POMDP, (ii) utilizing near optimality and convergence results of Q-learning for POMDPs, and (iii) finally, near-optimality of finite state model approximations for MDPs with weakly continuous kernels which we show to correspond to the fixed point of the constructed POMDP. Thus, our paper presents a very general convergence and approximation result for the applicability of Q-learning for continuous MDPs.;,citation_author=Ali Devran Kara;,citation_author=Naci Saldi;,citation_author=Serdar Yüksel;,citation_publication_date=2021-11-12;,citation_cover_date=2021-11-12;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2111.06781v1;">
<meta name="citation_reference" content="citation_title=Bounds and transformations for discounted finite markov decision chains;,citation_author=Evan L. Porteus;,citation_publication_date=1975-08;,citation_cover_date=1975-08;,citation_year=1975;,citation_issue=4;,citation_doi=10.1287/opre.23.4.761;,citation_volume=23;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Calculus on MDPs: Potential shaping as a gradient;,citation_abstract=In reinforcement learning, different reward functions can be equivalent in terms of the optimal policies they induce. A particularly well-known and important example is potential shaping, a class of functions that can be added to any reward function without changing the optimal policy set under arbitrary transition dynamics. Potential shaping is conceptually similar to potentials, conservative vector fields and gauge transformations in math and physics, but this connection has not previously been formally explored. We develop a formalism for discrete calculus on graphs that abstract a Markov Decision Process, and show how potential shaping can be formally interpreted as a gradient within this framework. This allows us to strengthen results from Ng et al. (1999) describing conditions under which potential shaping is the only additive reward transformation to always preserve optimal policies. As an additional application of our formalism, we define a rule for picking a single unique reward function from each potential shaping equivalence class.;,citation_author=Erik Jenner;,citation_author=Herke Hoof;,citation_author=Adam Gleave;,citation_publication_date=2022-08-20;,citation_cover_date=2022-08-20;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2208.09570v1;">
<meta name="citation_reference" content="citation_title=Dynamic potential-based reward shaping;,citation_abstract=Potential-based reward shaping can significantly improve the time needed to learn an optimal policy and, in multi-agent systems, the performance of the final joint-policy. It has been proven to not alter the optimal policy of an agent learning alone or the Nash equilibria of multiple agents learning together.However, a limitation of existing proofs is the assumption that the potential of a state does not change dynamically during the learning. This assumption often is broken, especially if the reward-shaping function is generated automatically.In this paper we prove and demonstrate a method of extending potential-based reward shaping to allow dynamic shaping and maintain the guarantees of policy invariance in the single-agent case and consistent Nash equilibria in the multi-agent case.;,citation_author=Sam Devlin;,citation_author=Daniel Kudenko;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_isbn=0981738117;,citation_conference_title=Proceedings of the 11th international conference on autonomous agents and multiagent systems;,citation_conference=International Foundation for Autonomous Agents; Multiagent Systems;,citation_series_title=AAMAS ’12;">
<meta name="citation_reference" content="citation_title=Potential-based shaping and q-value initialization are equivalent;,citation_abstract=Shaping has proven to be a powerful but precarious means of improving reinforcement learning performance. Ng, Harada, and Russell (1999) proposed the potential-based shaping algorithm for adding shaping rewards in a way that guarantees the learner will learn optimal behavior.In this note, we prove certain similarities between this shaping algorithm and the initialization step required for several reinforcement learning algorithms. More specifically, we prove that a reinforcement learner with initial Q-values based on the shaping algorithm’s potential function make the same updates throughout learning as a learner receiving potential-based shaping rewards. We further prove that under a broad category of policies, the behavior of these two learners are indistinguishable. The comparison provides intuition on the theoretical properties of the shaping algorithm as well as a suggestion for a simpler method for capturing the algorithm’s benefit. In addition, the equivalence raises previously unaddressed issues concerning the efficiency of learning with potential-based shaping.;,citation_author=Eric Wiewiora;,citation_publication_date=2003-09;,citation_cover_date=2003-09;,citation_year=2003;,citation_issue=1;,citation_issn=1076-9757;,citation_volume=19;,citation_journal_title=Journal of Artificial Intelligence Research;,citation_publisher=AI Access Foundation;">
<meta name="citation_reference" content="citation_title=Behavior of organisms;,citation_author=B. F. Skinner;,citation_publication_date=1938;,citation_cover_date=1938;,citation_year=1938;,citation_isbn=9781583900079;">
<meta name="citation_reference" content="citation_title=John von Neumann’s conception of the minimax theorem: A journey through different mathematical contexts;,citation_author=Tinne Hoff Kjeldsen;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_fulltext_html_url=http://www.jstor.org/stable/41134130;,citation_issue=1;,citation_issn=00039519, 14320657;,citation_volume=56;,citation_journal_title=Archive for History of Exact Sciences;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in multiple independent Gaussian channels as a game;,citation_author=Michail Fasoulakis;,citation_author=Apostolos Traganitis;,citation_author=Anthony Ephremides;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1007/978-3-030-16989-3_1;,citation_inbook_title=Lecture notes of the institute for computer sciences, social informatics and telecommunications engineering;">
<meta name="citation_reference" content="citation_title=A jamming game in wireless networks with transmission cost;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2007-06;,citation_cover_date=2007-06;,citation_year=2007;,citation_fulltext_html_url=https://www-sop.inria.fr/members/Eitan.Altman/PAPERS/andrey-lncs.pdf;,citation_conference_title=EuroFGI international conference on network control and optimization (NET-COOP);,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Closed form solutions for symmetric water filling games;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=https://doi.org/10.1109/INFOCOM.2008.117;,citation_conference_title=IEEE INFOCOM conference on computer communications;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Closed form solutions for water-filling problems in optimization and game frameworks;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=47;,citation_journal_title=Telecommunication Systems;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in wireless networks: The case of several jammers;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=2009 international conference on game theory for networks;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Jamming game with incomplete information about the jammer;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the fourth international ICST conference on performance evaluation methodologies and tools;">
<meta name="citation_reference" content="citation_title=Equilibrium points in n -person games;,citation_author=John F. Nash;,citation_publication_date=1950-01;,citation_cover_date=1950-01;,citation_year=1950;,citation_issue=1;,citation_doi=10.1073/pnas.36.1.48;,citation_volume=36;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=Proceedings of the National Academy of Sciences;">
<meta name="citation_reference" content="citation_title=A further generalization of the Kakutani fixed point theorem, with application to nash equilibrium points;,citation_author=I. L. Glicksberg;,citation_publication_date=1952-02;,citation_cover_date=1952-02;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/2032478;,citation_volume=3;,citation_journal_title=Proceedings of the American Mathematical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=The logic of animal conflict;,citation_author=J Maynard Smith;,citation_author=G. R. Price;,citation_publication_date=1973-11;,citation_cover_date=1973-11;,citation_year=1973;,citation_issue=5427;,citation_doi=10.1038/246015a0;,citation_volume=246;,citation_journal_title=Nature;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Evolution and the theory of games;,citation_author=John Maynard Smith;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_isbn=0521246733;">
<meta name="citation_reference" content="citation_title=The selfish gene;,citation_author=Richard Dawkins;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_isbn=019857519X;">
<meta name="citation_reference" content="citation_title=Population games and evolutionary dynamics;,citation_author=William H. Sandholm;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_isbn=9780262195874;">
<meta name="citation_reference" content="citation_title=A note on evolutionary stable strategies and game dynamics;,citation_author=Josef Hofbauer;,citation_author=Peter Schuster;,citation_author=Karl Sigmund;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=3;,citation_volume=81;,citation_journal_title=Journal of Theoretical Biology;">
<meta name="citation_reference" content="citation_title=Evolutionary stable strategies and game dynamics;,citation_author=Peter D. Taylor;,citation_author=Leo B. Jonker;,citation_publication_date=1978-07;,citation_cover_date=1978-07;,citation_year=1978;,citation_issue=1-2;,citation_doi=10.1016/0025-5564(78)90077-9;,citation_volume=40;,citation_journal_title=Mathematical Biosciences;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium in a nutshell;,citation_author=Rabah Amir;,citation_author=Sergei Belkov;,citation_author=Igor V. Evstigneev;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_issue=4;,citation_doi=10.1007/s11238-017-9609-9;,citation_volume=83;,citation_journal_title=Theory and Decision;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium as an expression of bayesian rationality;,citation_author=Robert J. Aumann;,citation_publication_date=1987-01;,citation_cover_date=1987-01;,citation_year=1987;,citation_issue=1;,citation_doi=10.2307/1911154;,citation_volume=55;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Subjectivity and correlation in randomized strategies;,citation_author=Robert J. Aumann;,citation_publication_date=1974-03;,citation_cover_date=1974-03;,citation_year=1974;,citation_issue=1;,citation_doi=10.1016/0304-4068(74)90037-8;,citation_volume=1;,citation_journal_title=Journal of Mathematical Economics;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Agreeing to disagree;,citation_author=Robert J. Aumann;,citation_publication_date=1976-11;,citation_cover_date=1976-11;,citation_year=1976;,citation_issue=6;,citation_doi=10.1214/aos/1176343654;,citation_volume=4;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Computing correlated equilibria in multi-player games;,citation_author=Christos H. Papadimitriou;,citation_author=Tim Roughgarden;,citation_publication_date=2008-07;,citation_cover_date=2008-07;,citation_year=2008;,citation_issue=3;,citation_doi=10.1145/1379759.1379762;,citation_volume=55;,citation_journal_title=Journal of the ACM;,citation_publisher=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players, iIII part i. The basic model;,citation_author=John C. Harsanyi;,citation_publication_date=1967-11;,citation_cover_date=1967-11;,citation_year=1967;,citation_issue=3;,citation_doi=10.1287/mnsc.14.3.159;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players part II. Bayesian equilibrium points;,citation_author=John C. Harsanyi;,citation_publication_date=1968-01;,citation_cover_date=1968-01;,citation_year=1968;,citation_issue=5;,citation_doi=10.1287/mnsc.14.5.320;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by “bayesian” players, part III. The basic probability distribution of the game;,citation_author=John C. Harsanyi;,citation_publication_date=1968-03;,citation_cover_date=1968-03;,citation_year=1968;,citation_issue=7;,citation_doi=10.1287/mnsc.14.7.486;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Game theory for applied economists;,citation_author=Robert Gibbons;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_isbn=0691043086;">
<meta name="citation_reference" content="citation_title=Computer science theory for the information age;,citation_author=John Hopcroft;,citation_author=Ravi Kannan;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_fulltext_html_url=https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/hopcroft-kannan-feb2012.pdf;">
<meta name="citation_reference" content="citation_title=Theory of self-adaptive control systems;,citation_author=H. Kwakernaak;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Information pattern for linear discrete-time models with stochastic coefficients;,citation_author=T. Bohlin;,citation_publication_date=1970-02;,citation_cover_date=1970-02;,citation_year=1970;,citation_issue=1;,citation_volume=15;,citation_journal_title=IEEE Transactions on Automatic Control (TAC);">
<meta name="citation_reference" content="citation_title=Information states for linear stochastic systems;,citation_author=M. H. A Davis;,citation_author=P. P Varaiya;,citation_publication_date=1972-02;,citation_cover_date=1972-02;,citation_year=1972;,citation_issue=2;,citation_volume=37;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Sufficient statistics in the optimal control of stochastic systems;,citation_author=Charlotte Striebel;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=12;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Some remarks on the concept of state;,citation_author=Hans S. Witsenhausen;,citation_editor=Y. C. Ho;,citation_editor=S. K. Mitter;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_inbook_title=Directions in large-scale systems;">
<meta name="citation_reference" content="citation_title=Linear automaton transformations;,citation_author=A. Nerode;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_volume=9;,citation_journal_title=Proceedings of American Mathematical Society;">
<meta name="citation_reference" content="citation_title=A convergence theorem for non-negative almost supermartingales and some applications;,citation_author=H. Robbins;,citation_author=D. Siegmund;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_doi=10.1016/b978-0-12-604550-5.50015-8;,citation_inbook_title=Optimizing methods in statistics;">
<meta name="citation_reference" content="citation_title=Discrete parameter martingales;,citation_author=J. Neveu;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;">
<meta name="citation_reference" content="citation_title=A user’s guide to measure theoretic probability;,citation_author=David Pollard;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Convergence of stochastic approximation via martingale and converse Lyapunov methods;,citation_author=M. Vidyasagar;,citation_publication_date=2023-01;,citation_cover_date=2023-01;,citation_year=2023;,citation_issue=2;,citation_doi=10.1007/s00498-023-00342-9;,citation_volume=35;,citation_journal_title=Mathematics of Control, Signals, and Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=On stochastic approximation;,citation_author=E. G. Gladyshev;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=2;,citation_doi=10.1137/1110031;,citation_volume=10;,citation_journal_title=Theory of Probability and Its Applications;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Gradient convergence in gradient methods with errors;,citation_author=Dimitri P. Bertsekas;,citation_author=John N. Tsitsiklis;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=3;,citation_doi=10.1137/s1052623497331063;,citation_volume=10;,citation_journal_title=SIAM Journal on Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Stochastic processes;,citation_author=Joseph T. Chang;,citation_publication_date=2007-02;,citation_cover_date=2007-02;,citation_year=2007;,citation_fulltext_html_url=http://www.stat.yale.edu/~pollard/Courses/251.spring2013/Handouts/Chang-notes.pdf;">
<meta name="citation_reference" content="citation_title=Lyapunov criterion for stochastic systems and its applications in distributed computation;,citation_author=Yuzhen Qin;,citation_author=Ming Cao;,citation_author=Brian D. O. Anderson;,citation_publication_date=2020-02;,citation_cover_date=2020-02;,citation_year=2020;,citation_issue=2;,citation_doi=10.1109/tac.2019.2910948;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=An upper bound on the loss from approximate optimal-value functions;,citation_author=Satinder P. Singh;,citation_author=Richard C. Yee;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993308;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Feature-based methods for large scale dynamic programming;,citation_author=John N. Tsitsiklis;,citation_author=Benjamin Roy;,citation_publication_date=1996-03;,citation_cover_date=1996-03;,citation_year=1996;,citation_issue=1-3;,citation_doi=10.1007/bf00114724;,citation_volume=22;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=A graphical derivation of the legendre transform;,citation_author=Sam Kennerly;,citation_publication_date=2011-04;,citation_cover_date=2011-04;,citation_year=2011;,citation_fulltext_html_url=http://einstein.drexel.edu/~skennerly/maths/Legendre.pdf;">
<meta name="citation_reference" content="citation_title=Variational analysis;,citation_author=R Tyrrell Rockafellar;,citation_author=Roger J-B Wets;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=317;">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../stochastic-control/index.html" rel="" target="">
 <span class="menu-text">Stochastic Control</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../multi-agent-systems/index.html" rel="" target="">
 <span class="menu-text">Multi-Agent Systems</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/adityam/stochastic-control" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../pomdps/intro.html">POMDPs</a></li><li class="breadcrumb-item"><a href="../pomdps/sequential-hypothesis.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the course</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Stochastic Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/newsvendor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The newsvendor problem</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/gambling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Optimal gambling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inventory Management</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/monotone-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/power-delay-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/reward-shaping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reward Shaping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inf-horizon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mdp-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">MDP algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management-revisited.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Inventory management (revisted)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mobile-edge-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Service Migration in Mobile edge computing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/computational-complexity-vi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Computational complexity of value interation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/linear-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Linear programming formulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/lipschitz-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">POMDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/sequential-hypothesis.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Approx DP</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/approx-DP.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Approximate dynamic programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/policy-loss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Upper bounds on policy loss</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/model-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Risk sensitive MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-utility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Risk Sensitive Utility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Risk Sensitive MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">LQ systems</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">RL</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rl/stochastic-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Stochastic approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Probability Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Convergence of random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/sub-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Sub-Gaussian random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/change-of-measure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Change of Measure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/martingales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Martingales</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/stochastic-stability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Stochastic stability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Linear Algebra Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/postive-definite-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Positive definite matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/svd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Singular value decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/rkhs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Reproducing Kernel Hilbert Space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Convexity Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/convexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Convex sets and convex functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/duality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Duality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 1</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#dynamic-programming-decomposition" id="toc-dynamic-programming-decomposition" class="nav-link active" data-scroll-target="#dynamic-programming-decomposition"><span class="header-section-number">17.1</span> Dynamic programming decomposition</a></li>
  <li><a href="#structure-of-the-optimal-policy" id="toc-structure-of-the-optimal-policy" class="nav-link" data-scroll-target="#structure-of-the-optimal-policy"><span class="header-section-number">17.2</span> Structure of the optimal policy</a></li>
  <li><a href="#infinite-horizon-setup" id="toc-infinite-horizon-setup" class="nav-link" data-scroll-target="#infinite-horizon-setup"><span class="header-section-number">17.3</span> Infinite horizon setup</a></li>
  <li><a href="#upper-bound-on-the-expected-number-of-measurements" id="toc-upper-bound-on-the-expected-number-of-measurements" class="nav-link" data-scroll-target="#upper-bound-on-the-expected-number-of-measurements"><span class="header-section-number">17.4</span> Upper bound on the expected number of measurements</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/adityam/stochastic-control/edit/quarto/pomdps/sequential-hypothesis.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="http://www.cim.mcgill.ca/~adityam">Aditya Mahajan</a> </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="http://www.mcgill.ca/ece">
            McGill University
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 7, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Consider a decision maker (DM) that makes a series of i.i.d. observations which may be distributed according to PDF <span class="math inline">\(f_0\)</span> or <span class="math inline">\(f_1\)</span>. Let <span class="math inline">\(Y_t\)</span> denote the observaion at time <span class="math inline">\(t\)</span>. The DM wants to differentiate between two hypothesis: <span class="math display">\[\begin{gather*}
  h_0 : Y_t \sim f_0 \\
  h_1 : Y_t \sim f_1
\end{gather*}\]</span> Typically, we think of <span class="math inline">\(h_0\)</span> as the normal situation (or the null hypothesis) and <span class="math inline">\(h_1\)</span> as an anomaly. For example, the hypothesis may be <span class="math display">\[ h_0: Y_t \sim {\cal N}(0, σ^2) \quad h_1: Y_t \sim {\cal N}(μ, σ^2) \]</span> or <span class="math display">\[ h_0: Y_t \sim \text{Ber}(p) \quad h_1: Y_t \sim \text{Ber}(q). \]</span></p>
<p>Let the random variable <span class="math inline">\(H\)</span> denote the value of the hypothesis. The a priori probability <span class="math inline">\(\PR(H = h_0) = p\)</span>.</p>
<p>The system continues for a finite time <span class="math inline">\(T\)</span>. At each <span class="math inline">\(t &lt; T\)</span>, the DM has three options:</p>
<ul>
<li>stop and declare <span class="math inline">\(h_0\)</span></li>
<li>stop and declare <span class="math inline">\(h_1\)</span></li>
<li>continue and take another measurement</li>
</ul>
<p>At the terminal time step <span class="math inline">\(T\)</span>, the continuation option is not available. Each measurement has a cost <span class="math inline">\(c\)</span>. When the DM takes a stopping action <span class="math inline">\(ν\)</span>, it incurs a stopping cost <span class="math inline">\(\ell(ν, H)\)</span>.</p>
<p>We typically assume <span class="math inline">\(\ell(h_0, h_0) = \ell(h_1, h_1) = 0\)</span>. The term <span class="math inline">\(\ell(h_1, h_0)\)</span> indicates that the DM declares an anomaly when everything is okay. This is called <em>false alarm penalty</em>. The term <span class="math inline">\(\ell(h_0, h_1)\)</span> indicates that DM declares everything is okay when there is an anomaly. This is called the <em>missed detection penalty</em>.</p>
<p>Let <span class="math inline">\(τ\)</span> denote the time when the DM stops. Then the total cost of running the system is <span class="math inline">\(cτ + \ell(ν, H)\)</span>. The objective is to find the optimal stopping strategy that minimize the expected total cost.</p>
<section id="dynamic-programming-decomposition" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="dynamic-programming-decomposition"><span class="header-section-number">17.1</span> Dynamic programming decomposition</h2>
<p>We use the belief-state as an information state to obtain a dynamic programming decomposition. Recall that the beief state is two-dimensional pdf where <span class="math display">\[ b_t(h) = \PR(H = h | Y_{1:t}), \quad h \in \{h_0, h_1\}. \]</span></p>
<dl>
<dt>Remarks</dt>
<dd>
<ul>
<li><p>We are only conditioning on <span class="math inline">\(Y_{1:t}\)</span> and not adding <span class="math inline">\(A_{1:t-1}\)</span> in the conditioning. This is because we are taking the standard approach used in optimal stopping problems where we are only defining the state for case when the stopping decision hasn’t been taken so far and all previous actions are continue. Taking a continue action does not effect the observations. For this reason, we do not condition on <span class="math inline">\(A_{1:t-1}\)</span>.</p></li>
<li><p>It is possible to exploit the fact that <span class="math inline">\(b_t = [p_t, 1 - p_t]^T\)</span> and write a simplified DP in terms of <span class="math inline">\(p_t\)</span>. In these notes, I don’t make this simplification so that we can see how these results will extend to the case of non-binary hypothesis.</p></li>
</ul>
</dd>
</dl>
<p>The dynamic program for the above model is then given by <span class="math display">\[
  V_T(b_T) = \min\{ \EXP[ \ell(h_0, H) | B_T = b_T],
                    \EXP[ \ell(h_1, H) | B_T = b_T] \}
\]</span> and for <span class="math inline">\(t \in \{T-1, \dots, 1\}\)</span>, <span class="math display">\[ V_t(b_t) = \min \{ \EXP[ \ell(h_0, H) | B_t = b_t],
                      \EXP[ \ell(h_1, H) | B_t = b_t],
                     c + \EXP[V_{t+1}(ψ(b_t, Y_{t+1})) | B_t = b_t] \},
\]</span> where <span class="math inline">\(ψ(b, y)\)</span> denotes the standard non-linear filtering update (there is no dependence on <span class="math inline">\(a\)</span> here because there are no state dynamics in this model).</p>
<p>We introduce some notation to simplify the discussion. Define</p>
<ul>
<li><span class="math inline">\(L_i(b) = \EXP[ \ell(h_i, H) | B = b] = \sum_{h \in \{h_0, h_1\}} \ell(h_i, h) b(h)\)</span>.</li>
<li><span class="math inline">\(W_t(b_t) = c + \EXP[V_{t+1}(ψ(b_t, Y_{t+1})) | B_t = b_t]\)</span>.</li>
</ul>
<p>Then, the above DP can be written as <span class="math display">\[
  V_T(b_T) = \min\{ L_0(b_T), L_1(b_T) \}
\]</span> and for <span class="math inline">\(t \in \{T-1, \dots, 1\}\)</span>, <span class="math display">\[ V_t(b_t) = \min \{ L_0(b_t), L_1(b_t), W_t(b_t) \}. \]</span></p>
</section>
<section id="structure-of-the-optimal-policy" class="level2 page-columns page-full" data-number="17.2">
<h2 data-number="17.2" class="anchored" data-anchor-id="structure-of-the-optimal-policy"><span class="header-section-number">17.2</span> Structure of the optimal policy</h2>
<p>We start by establishing simple properties of the different functions defined above.</p>
<div id="lem-hypothesis-concavity" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 17.1 </strong></span>The above functions statisfy the following properties:</p>
<ul>
<li><span class="math inline">\(L_i(b)\)</span> is linear in <span class="math inline">\(b\)</span>.</li>
<li><span class="math inline">\(V_t(b)\)</span> and <span class="math inline">\(W_t(b)\)</span> is concave in <span class="math inline">\(b\)</span>.</li>
<li><span class="math inline">\(V_t(b)\)</span> and <span class="math inline">\(W_t(b)\)</span> are increasing in <span class="math inline">\(t\)</span>.</li>
</ul>
</div>
<figure class="figure">
<div id="applet_container" style="width:800px;height:800px;display:block">

</div>
<figcaption class="figure-caption">
An illustration of the minimum of two straight lines and a concave function. Move the points around to see how the shape of the function changes.
</figcaption>
</figure>
<script type="text/javascript">
      var params1 = {
        filename: "../www/geogebra/pomdp-hypothesis-testing1.ggb",
        enableShiftDragZoom: false,
        width: 800,
        height: 700,
      }

      var params2 = {
        filename: "../www/geogebra/pomdp-hypothesis-testing2.ggb",
        enableShiftDragZoom: false,
        width: 800,
        height: 700,
      }

      var applet1 = new GGBApplet(params1, true);
      var applet2 = new GGBApplet(params2, true);

      window.onload = function() {
          applet1.inject('applet_container');
          applet2.inject('applet_container2');
      }
  </script>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The linearity of <span class="math inline">\(L_i(b)\)</span> follows from definition. From the discussion on <a href="intro.html#thm-belief-PWLC">POMDPs</a>, we know that <span class="math inline">\(V_{t+1}(b)\)</span> is concave in <span class="math inline">\(b\)</span> and so is <span class="math inline">\(\EXP[V_{t+1}(ψ(b, Y_{t+1})) | B_t = b]\)</span>. Therefore <span class="math inline">\(W_t(b)\)</span> is concave in <span class="math inline">\(b\)</span>.</p>
<p>Finally, by construction, we have that <span class="math inline">\(V_{T-1}(b) \le V_T(b)\)</span>. The monotonicity in time then follows from Q2 of <a href="../assignments/02.html">Assignment 2</a>. Sincen <span class="math inline">\(V_t\)</span> is monotone in time, it implies that <span class="math inline">\(W_t\)</span> is also monotone.</p>
</div>
</div>
</div>
<p>Now define stopping sets <span class="math inline">\(D_t(h) = \{ b \in Δ^2 : π_t(b) = h \}\)</span> for <span class="math inline">\(h \in \{h_0, h_1\}\)</span>. The key result is the following.</p>
<div id="thm-hypothesis-convex" class="theorem">
<p><span class="theorem-title"><strong>Theorem 17.1 </strong></span>For all <span class="math inline">\(t\)</span> and <span class="math inline">\(h \in \{h_0, h_1\}\)</span>, the set <span class="math inline">\(D_t(h)\)</span> is convex. Moreover, <span class="math inline">\(D_t(h_i) \subseteq D_{t+1}(h_i)\)</span>.</p>
</div>
<figure class="figure">
<div id="applet_container2" style="width:800px;height:800px;display:block">

</div>
<figcaption class="figure-caption">
An illustration of the stopping sets. Move the points around to see how the shape of the stopping set changes.
</figcaption>
</figure>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Note that we can write <span class="math inline">\(D_t(h) = A_t(h) \cap B_t(h)\)</span>, where <span class="math display">\[ A_t(h_i) = \{ b \in Δ^2 : L_i(b)  \le L_j(b) \}
   \quad\text{and}\quad
   B_t(h_i) = \{ b \in Δ^2 : L_i(b) \le W_t(b)  \}. \]</span></p>
<p><span class="math inline">\(A_t(h_i)\)</span> is a the set of <span class="math inline">\(b\)</span> where one linear function of <span class="math inline">\(b\)</span> is less than or equal to another linear function of <span class="math inline">\(b\)</span>. Therefore, <span class="math inline">\(A_t(h_i)\)</span> is a convex set.</p>
<p>Similarly, <span class="math inline">\(B_t(h_i)\)</span> is the set of <span class="math inline">\(b\)</span> where a linear function of <span class="math inline">\(b\)</span> is less than or equal to a concave function of <span class="math inline">\(b\)</span>. Therefore <span class="math inline">\(B_t(h_i)\)</span> is also a convex set.</p>
<p><span class="math inline">\(D_t(h_i)\)</span> is the intersection of two convex sets, and hence convex.</p>
<p>The monotonicty of <span class="math inline">\(D_t(h_i)\)</span> in time follows from the monotonicity of <span class="math inline">\(W_t\)</span> in time.</p>
</div>
</div>
</div>
<div id="thm-hypothesis-corner" class="theorem">
<p><span class="theorem-title"><strong>Theorem 17.2 </strong></span>Suppose the stopping cost satisfy the following: <span class="math display">\[\begin{equation} \label{eq:cost-ass}
\ell(h_0, h_0) \le c \le \ell(h_0, h_1)
  \quad\text{and}\quad
  \ell(h_1, h_1) \le c \le \ell(h_1, h_0).
\end{equation}\]</span> Then, <span class="math inline">\(e_i \in D_t(h_i)\)</span>, where <span class="math inline">\(e_i\)</span> denotes the standard unit vector (i.e., <span class="math inline">\(e_0 = [1, 0]^T\)</span> and <span class="math inline">\(e_1 = [0, 1]^T\)</span>).</p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remark
</div>
</div>
<div class="callout-body-container callout-body">
<p>The assumption on observation cost states that: (i) the cost of observation is greater than the cost incurred when the DM chooses the right hypothesis, and (ii) the cost of observation is less than the cost incurred when the DM chooses the wrong hypothesis. Both these assumptions are fairly natural.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Note that <span class="math inline">\(L_i(e_0) = \ell(h_i, h_0)\)</span> and <span class="math inline">\(L_i(e_1) = \ell(h_1, h_1)\)</span>. Moreover, by construction, <span class="math inline">\(W_t(b) \ge c\)</span>. Thus, under the above assumption on the cost, <span class="math display">\[ L_0(e_0) = \ell(h_0, h_0) \le c \le W_t(e_0) \]</span> and <span class="math display">\[ L_0(e_0) = \ell(h_0, h_0) \le \ell(h_1, h_0) = L_1(e_0). \]</span> Thus, <span class="math inline">\(e_0 \in D_t(h_0)\)</span>.</p>
<p>By a symmetric argument, we can show that <span class="math inline">\(e_1 \in D_t(h_1)\)</span>.</p>
</div>
</div>
</div>
<p><a href="#thm-hypothesis-convex">Theorem&nbsp;<span>17.1</span></a> and <a href="#thm-hypothesis-corner">Theorem&nbsp;<span>17.2</span></a> imply that the optimal stopping regions are convex and include the “corner points” of the simplex. Note that although we formulated the problem for binary hypothesis, all the steps of the proof hold in general as well.</p>

<div class="no-row-height column-margin column-container"><div class="">
<figure class="figure">
<img src="images/general-stopping.png" title="Stopping regions" alt="Stopping regions" width="300" class="figure-img">
<figcaption class="figure-caption">
Stopping regions for multiple hypothesis
</figcaption>
</figure>
</div></div><p>For binary hypothesis, we can present a more concerete characterizatin of the optimal policy. Note that the two-dimensional simplex is equivalent to the interval <span class="math inline">\([0,1]\)</span>. In particular, any <span class="math inline">\(b = Δ^2\)</span> is equal to <span class="math inline">\([p, 1-p]\)</span>, where <span class="math inline">\(p \in [0,1]\)</span>. Now define:</p>
<ul>
<li><span class="math inline">\(\displaystyle b_t = \min\left\{ p \in [0, 1] :  π_t\left(\begin{bmatrix} p \\ 1-p \end{bmatrix}\right) = h_0 \right\}.\)</span></li>
<li><span class="math inline">\(\displaystyle a_t = \max\left\{ p \in [0, 1] :  π_t\left(\begin{bmatrix} p \\ 1-p \end{bmatrix}\right) = h_1 \right\}.\)</span></li>
</ul>
<p>Then, by definition, the optimal policy has the following threshold property:</p>
<div id="prp-hypothesis-threshold" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 17.1 </strong></span>Let <span class="math inline">\(\bar π_t(p) = π_t([p, 1-p]^T)\)</span>. Then, under \eqref{eq:cost-ass}, <span class="math display">\[ \bar π_t(p) = \begin{cases}
   h_1, &amp; \text{if } p \le a_t \\
   \mathsf{C}, &amp; \text{if } a_t &lt; p &lt; b_t \\
   h_0, &amp; \text{if } b_t \le p.
  \end{cases} \]</span></p>
<p>Furthermore, the decision thresholds are monotone in time. In particular, for all <span class="math inline">\(t\)</span>, <span class="math display">\[ a_t \le a_{t+1} \le b_{t+1} \le b_t. \]</span></p>
</div>
<p>The above property is simplies stated slighted in terms of the likelihood ratio. In particular, define <span class="math inline">\(λ_t = b_t(0)/b_t(1) = p_t/(1 - p_t)\)</span>. Then, we have the following:</p>
<div id="prp-hypothesis-likelihood" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 17.2 </strong></span>Let <span class="math inline">\(\hat π_t(λ) = π_t([λ/(1+λ), 1/(1+λ)]^T)\)</span>. Then, under \eqref{eq:cost-ass}, <span class="math display">\[ \hat π_t(λ) = \begin{cases}
   h_1, &amp; \text{if } λ \le a_t/(1 - a_t) \\
   \mathsf{C}, &amp; \text{if } a_t/(1 - a_t) &lt; λ &lt; b_t/(1 - b_t)_t \\
   h_0, &amp; \text{if } b_t/(1 - b_t)_t \le λ.
  \end{cases} \]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For any <span class="math inline">\(a, b \in [0, 1]\)</span>, <span class="math display">\[ a \le b \iff \frac{a}{1-a} \le \frac{b}{1-b}.\]</span></p>
</div>
</div>
</div>
<p>The result of <a href="#prp-hypothesis-likelihood">Proposition&nbsp;<span>17.2</span></a> is called the <em>sequential</em> likelihood ratio test (SLRT) or <em>sequential</em> probability ratio test (SPRT) to contrast it with the standard <a href="https://en.wikipedia.org/wiki/Likelihood-ratio_test">:likelihood ratio test</a> in hypotehsis testing.</p>
</section>
<section id="infinite-horizon-setup" class="level2" data-number="17.3">
<h2 data-number="17.3" class="anchored" data-anchor-id="infinite-horizon-setup"><span class="header-section-number">17.3</span> Infinite horizon setup</h2>
<p>Assume that <span class="math inline">\(T = ∞\)</span> so that the continuation alternative is always available. Then, we have the following.</p>
<div id="thm-hypothesis-inf" class="theorem">
<p><span class="theorem-title"><strong>Theorem 17.3 </strong></span>Under \eqref{eq:cost-ass}, an optimal decision rule always exists, is time-homogeneous, and is given by the solution of the following DP: <span class="math display">\[ V(b) = \min\{ L_0(b) , L_1(b) , W(b) \} \]</span> where <span class="math display">\[ W(b) = c + \int_{y} [ pf_0(y) + (1-p)f_1(y)] V(ψ(b,y)) dy. \]</span></p>
<p>Therefore, the optimal thresholds <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are time-homogeneous.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The result follows from standard results on non-negative dynamic programming. We did not cover non-negative DP. Essentially it determines conditions under which undiscounted infinite horizon problems have a solution when the per-step cost is non-negative.</p>
</div>
</div>
</div>
</section>
<section id="upper-bound-on-the-expected-number-of-measurements" class="level2" data-number="17.4">
<h2 data-number="17.4" class="anchored" data-anchor-id="upper-bound-on-the-expected-number-of-measurements"><span class="header-section-number">17.4</span> Upper bound on the expected number of measurements</h2>
<p>For simplicity, we assume that <span class="math inline">\(\ell(h_0, h_0) = \ell(h_1, h_1) = 0\)</span>. For the infinite horizon model, we can get upper bound on the expected number of measurements that an optimal policy will take. Let <span class="math inline">\(τ\)</span> denote the number of measurements taken under policy <span class="math inline">\(π\)</span> and <span class="math inline">\(A_τ\)</span> denote the terminal action after stopping. Then, the performance of policy <span class="math inline">\(π\)</span> is given by <span class="math display">\[
  J(π) = \EXP[ c τ + \ell(H, A_\tau) \mid \Pi = b ].
\]</span> Note that <span class="math inline">\(\ell(H, A_\tau) \ge 0\)</span>. Therefore, the performance of the optimal policy is lower bounded by <span class="math display">\[
  J^* \ge c\, \EXP^{π^*}[  τ \mid \Pi = b] .
\]</span> Now, consider a policy <span class="math inline">\(\tilde π\)</span> which does not consider continuation action and takes the best stopping decision. The performance of <span class="math inline">\(\tilde π\)</span> is given by <span class="math display">\[ J(\tilde π) = \min \{ \ell(h_1, h_0) b_1, \ell(h_0, h_1) b_0 \}. \]</span> Since <span class="math inline">\(J(\tilde π) \ge J^*\)</span>, we get <span class="math display">\[
  \EXP^{π^*}[ τ  \mid \Pi = b ] \le \frac 1c
  \min \{ \ell(h_1, h_0) b_1, \ell(h_0, h_1) b_0 \}. \]</span></p>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div id="exr-multi-hypothesis" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 17.1 </strong></span>Consider the following modification of the sequential hypothesis testing. As in the model discussed above, there are two hypothesis <span class="math inline">\(h_0\)</span> and <span class="math inline">\(h_1\)</span>. The a priori probability that the hypothesis is <span class="math inline">\(h_0\)</span> is <span class="math inline">\(p\)</span>.</p>
<p>In contrast to the model discussed above, there are <span class="math inline">\(N\)</span> sensors. If the underlying hypothesis is <span class="math inline">\(h_i\)</span> and sensor <span class="math inline">\(m\)</span> is used at time <span class="math inline">\(t\)</span>, then the observation <span class="math inline">\(Y_t\)</span> is distrubted according to pdf (or pmf) <span class="math inline">\(f^m_i(y)\)</span>. The cost of using sensor <span class="math inline">\(m\)</span> is <span class="math inline">\(c_m\)</span>.</p>
<p>Whenever the decision maker takes a measurement, he picks a sensor <span class="math inline">\(m\)</span> uniformly at random from <span class="math inline">\(\{1, \dots, N\}\)</span> and observes <span class="math inline">\(Y_t\)</span> according to the distribution <span class="math inline">\(f^m_i(\cdot)\)</span> and incurs a cost <span class="math inline">\(c_m\)</span>.</p>
<p>The system continues for a finite time <span class="math inline">\(T\)</span>. At each time <span class="math inline">\(t &lt; T\)</span>, the decision maker has three options: stop and declare <span class="math inline">\(h_0\)</span>, stop and declare <span class="math inline">\(h_1\)</span>, or continue to take another measurement. At time <span class="math inline">\(T\)</span>, the continue alternative is unavailable.</p>
<ol type="a">
<li><p>Formulate the above problem as a POMDP. Identify an information state and write the dynamic programming decomposition for the problem.</p></li>
<li><p>Show that the optimal control law has a threshold property, similar to the threshold propertly for the model described above.</p></li>
</ol>
</div>
<div id="exr-approx-hypothesis" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 17.2 </strong></span>In this exercise, we will derive an approximate method to compute the performance of a given threshold based policy for infinite horizon sequential hypothesis testing problem. Let <span class="math display">\[ θ_i(π,p) = \EXP^{π}[ τ | H = h_i] \]</span> denote the expected number of samples when using stopping rule <span class="math inline">\(π\)</span> assuming that the true hypothesis is <span class="math inline">\(h_i\)</span>. Note that for any belief state based stopping rule, <span class="math inline">\(θ_i\)</span> depends on the initial belief <span class="math inline">\([p, 1-p]\)</span>. Furthermore, let <span class="math display">\[ ξ_i(h_k ;π, p) = \PR^π(A_τ = h_k | H = h_i) \]</span> denote the probability that the stopping action is <span class="math inline">\(h_k\)</span> when using stopping rule <span class="math inline">\(π\)</span> assuming that the true hypothesis is <span class="math inline">\(h_i\)</span>.</p>
<ol type="a">
<li><p>Argue that the performance of any policy <span class="math inline">\(π\)</span> can be written as <span class="math display">\[\begin{align*}
  V_π(p) &amp;= c [ p θ_0(π, p) + (1-p) θ_1(π,p) ] \\
  &amp; \quad + p \sum_{a \in \{h_0, h_1\}} \ell(a, h_0) ξ_0(a; π, p) \\
  &amp; \quad + (1-p) \sum_{a \in \{h_0, h_1\}} \ell(a, h_1) ξ_1(a; π, p).
  \end{align*}\]</span> Thus, approximately computing <span class="math inline">\(θ_i\)</span> and <span class="math inline">\(ξ_i\)</span> gives an approximate value of <span class="math inline">\(V_π(p)\)</span>.</p></li>
<li><p>Now assume that the policy <span class="math inline">\(π\)</span> is of a threshold form with thresholds <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. To avoid trivial cases, we assume that <span class="math inline">\(p \in (a,b)\)</span>. The key idea to compute <span class="math inline">\(θ_i\)</span> and <span class="math inline">\(ξ_i\)</span> is that the evolution of <span class="math inline">\(p_t =  \PR(H = h_t | Y_{1:t})\)</span> is a Markov chain which starts at a state <span class="math inline">\(p  \in (a,b)\)</span> and stops the first time <span class="math inline">\(p_t\)</span> goes below <span class="math inline">\(a\)</span> or above <span class="math inline">\(b\)</span>.</p>
<figure class="figure">
<p><img src="images/discretization.png" title="Discretization of the state space" alt="Discretization of the state space" width="300" class="figure-img"></p>
<figcaption class="figure-caption">
<p>Discretization of the state space</p>
</figcaption>
</figure>
<p>Suppose we discretize the state space space <span class="math inline">\([0, 1]\)</span> into <span class="math inline">\(n+1\)</span> grid points <span class="math inline">\(\ALPHABET D_n = \{0, \frac1n, \dots, 1\}\)</span>. Assume that <span class="math inline">\(p\)</span>, <span class="math inline">\(a\)</span>, and <span class="math inline">\(b\)</span> lie on this discrete grid. Discreteize <span class="math inline">\(p_t\)</span> to the closest grid point and let <span class="math inline">\(P_i\)</span> denote the transition matrix of the discretized <span class="math inline">\(p_t\)</span> when the true hypothesis is <span class="math inline">\(h_i\)</span>. Partition the <span class="math inline">\(P_i\)</span> as <span class="math display">\[ \left[\begin{array}{c|c|c}
     A_i &amp; B_i &amp; C_i \\
     \hline
     D_i &amp; E_i &amp; F_i \\
     \hline
     G_i &amp; H_i &amp; J_i
    \end{array}\right] \]</span> where the lines correspond to the index for <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. The transition matrix of the absorbing Markov chain is given by <span class="math display">\[ \hat P_i = \left[\begin{array}{c|c|c}
       I &amp; 0 &amp; I \\
       \hline
       D_i &amp; E_i &amp; F_i \\
       \hline
       I &amp; 0 &amp; I
      \end{array}\right] \]</span> Now suppose <span class="math inline">\(j\)</span> is the index of <span class="math inline">\(p\)</span> in <span class="math inline">\(\ALPHABET D_n\)</span>. Using properties of absorbing Markov chains, show that</p>
<ul>
<li><span class="math inline">\(ξ_i(h_0; \langle a, b \rangle, p) \approx  [ (I - E_i)^{-1} F_i \mathbf{1} ]_j\)</span></li>
<li><span class="math inline">\(ξ_i(h_1; \langle a, b \rangle, p) \approx  [ (I - E_i)^{-1} D_i \mathbf{1} ]_j\)</span></li>
<li><span class="math inline">\(θ_i(\langle a, b \rangle, p) \approx  [ (I - E_i)^{-1} \mathbf{1} ]_j\)</span></li>
</ul></li>
</ol>
</div>
</section>
<section id="notes" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="notes">Notes</h2>
<p>For more details on sequential hypothesis testing, incuding an approximate method to determine the thresholds, see <span class="citation" data-cites="Wald1945">Wald (<a href="../references.html#ref-Wald1945" role="doc-biblioref">1945</a>)</span>. The optimal of sequential likelihood ratio test was proved in <span class="citation" data-cites="Wald1948">Wald and Wolfowitz (<a href="../references.html#ref-Wald1948" role="doc-biblioref">1948</a>)</span>. The model described above was first considered by <span class="citation" data-cites="Arrow1949">Arrow et al. (<a href="../references.html#ref-Arrow1949" role="doc-biblioref">1949</a>)</span>. See <span class="citation" data-cites="DeGroot1970">DeGroot (<a href="../references.html#ref-DeGroot1970" role="doc-biblioref">1970</a>)</span>.</p>
<p>The upper bound on expected number of measurements is adapted from an argument presented in <span class="citation" data-cites="Hay2012">Hay et al. (<a href="../references.html#ref-Hay2012" role="doc-biblioref">2012</a>)</span>.</p>
<p><a href="#exr-multi-hypothesis">Exercise&nbsp;<span>17.1</span></a> is from <span class="citation" data-cites="Bai2015">Bai et al. (<a href="../references.html#ref-Bai2015" role="doc-biblioref">2015</a>)</span>. <a href="#exr-approx-hypothesis">Exercise&nbsp;<span>17.2</span></a> is from <span class="citation" data-cites="Woodall1983">Woodall and Reynolds (<a href="../references.html#ref-Woodall1983" role="doc-biblioref">1983</a>)</span>.</p>
<hr>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Arrow1949" class="csl-entry" role="listitem">
<span class="smallcaps">Arrow, K.J., Blackwell, D., and Girshick, M.A.</span> 1949. Bayes and minimax solutions of sequential decision problems. <em>Econometrica</em> <em>17</em>, 3/4, 213. DOI: <a href="https://doi.org/10.2307/1905525">10.2307/1905525</a>.
</div>
<div id="ref-Bai2015" class="csl-entry" role="listitem">
<span class="smallcaps">Bai, C.-Z., Katewa, V., Gupta, V., and Huang, Y.-F.</span> 2015. A stochastic sensor selection scheme for sequential hypothesis testing with multiple sensors. <em>IEEE transactions on signal processing</em> <em>63</em>, 14, 3687–3699.
</div>
<div id="ref-DeGroot1970" class="csl-entry" role="listitem">
<span class="smallcaps">DeGroot, M.</span> 1970. <em>Optimal statistical decisions</em>. Wiley-Interscience, Hoboken, N.J.
</div>
<div id="ref-Hay2012" class="csl-entry" role="listitem">
<span class="smallcaps">Hay, N., Russell, S., Tolpin, D., and Shimony, S.E.</span> 2012. Selecting computations: Theory and applications. <em>UAI</em>. Available at: <a href="http://www.auai.org/uai2012/papers/123.pdf">http://www.auai.org/uai2012/papers/123.pdf</a>.
</div>
<div id="ref-Wald1945" class="csl-entry" role="listitem">
<span class="smallcaps">Wald, A.</span> 1945. Sequential tests of statistical hypotheses. <em>The Annals of Mathematical Statistics</em> <em>16</em>, 2, 117–186. DOI: <a href="https://doi.org/10.1214/aoms/1177731118">10.1214/aoms/1177731118</a>.
</div>
<div id="ref-Wald1948" class="csl-entry" role="listitem">
<span class="smallcaps">Wald, A. and Wolfowitz, J.</span> 1948. Optimum character of the sequential probability ratio test. <em>The Annals of Mathematical Statistics</em> <em>19</em>, 3, 326–339. DOI: <a href="https://doi.org/10.1214/aoms/1177730197">10.1214/aoms/1177730197</a>.
</div>
<div id="ref-Woodall1983" class="csl-entry" role="listitem">
<span class="smallcaps">Woodall, W.H. and Reynolds, M.R.</span> 1983. A discrete markov chain representation of the sequential probability ratio test. <em>Communications in Statistics. Part C: Sequential Analysis</em> <em>2</em>, 1, 27–44. DOI: <a href="https://doi.org/10.1080/07474948308836025">10.1080/07474948308836025</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../pomdps/intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../approx-mdps/approx-DP.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Approximate dynamic programming</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>