<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aditya Mahajan">
<meta name="dcterms.date" content="2023-06-07">
<meta name="keywords" content="POMDPs, Dynamic programming, Information state">
<meta name="description" content="ECES 506 (Stochastic Control and Decision Theory)">

<title>Course Notes - 16&nbsp; Introduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../pomdps/sequential-hypothesis.html" rel="next">
<link href="../mdps/lipschitz-mdps.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      IND: "\\mathbb{I}",
      ONES: "\\mathbb{1}",
      reals: "\\mathbb{R}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      BELLMAN: "\\mathcal{B}",
      MISMATCH: "\\mathcal{D}",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      NORM: ["\\left\\lVert #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert #1 \\right\\rvert", 1],
      GRAD: "\\nabla"
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>
<script type="text/javascript" src="https://www.geogebra.org/apps/deployggb.js">
</script>


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="citation_title" content="[16]{.chapter-number}&nbsp; [Introduction]{.chapter-title}">
<meta name="citation_keywords" content="POMDPs,Dynamic programming,Information state">
<meta name="citation_author" content="Aditya Mahajan">
<meta name="citation_publication_date" content="2023-06-07">
<meta name="citation_cover_date" content="2023-06-07">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-06-07">
<meta name="citation_fulltext_html_url" content="https://adityam.github.io/stochastic-control//pomdps/intro.html">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Course notes for ECSE 506 (Stochastic Control and Decision Theorey)">
<meta name="citation_reference" content="citation_title=A new interpretation of information rate;,citation_author=John L. Kelly;,citation_publication_date=1956-07;,citation_cover_date=1956-07;,citation_year=1956;,citation_issue=4;,citation_doi=10.1002/j.1538-7305.1956.tb03809.x;,citation_volume=35;,citation_journal_title=Bell System Technical Journal;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic programming and gambling models;,citation_author=Sheldon M. Ross;,citation_publication_date=1974-09;,citation_cover_date=1974-09;,citation_year=1974;,citation_issue=3;,citation_doi=10.2307/1426236;,citation_volume=6;,citation_journal_title=Advances in Applied Probability;,citation_publisher=Applied Probability Trust;">
<meta name="citation_reference" content="citation_title=Optimal inventory policy;,citation_author=Kenneth J Arrow;,citation_author=Theodore Harris;,citation_author=Jacob Marschak;,citation_publication_date=1952-01;,citation_cover_date=1952-01;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/1907830;,citation_volume=20;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=On the optimal inventory equation;,citation_author=Richard Bellman;,citation_author=Irving Glicksberg;,citation_author=Oliver Gross;,citation_publication_date=1955-10;,citation_cover_date=1955-10;,citation_year=1955;,citation_issue=1;,citation_doi=10.1287/mnsc.2.1.83;,citation_volume=2;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Memoryless strategies in finite-stage dynamic programming;,citation_author=David Blackwell;,citation_publication_date=1964-06;,citation_cover_date=1964-06;,citation_year=1964;,citation_issue=2;,citation_doi=10.1214/aoms/1177703586;,citation_volume=35;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=On the structure of real-time source coders;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=6;,citation_volume=58;,citation_journal_title=Bell System Technical Journal;">
<meta name="citation_reference" content="citation_title=Contributions to the theory of optimal control;,citation_author=Rudolf Emil Kalman;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_volume=5;,citation_journal_title=Boletin de la Sociedad Matematica Mexicana;">
<meta name="citation_reference" content="citation_title=Dynamic programming under uncertainty with a quadratic criterion function;,citation_author=Herbert A Simon;,citation_publication_date=1956-01;,citation_cover_date=1956-01;,citation_year=1956;,citation_issue=1;,citation_doi=10.2307/1905261;,citation_volume=24;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Econometric models and welfare maximization;,citation_author=Henri Theil;,citation_publication_date=1954;,citation_cover_date=1954;,citation_year=1954;,citation_doi=10.1007/978-94-011-2410-2_1;,citation_volume=72;,citation_journal_title=Wirtschaftliches Archiv;">
<meta name="citation_reference" content="citation_title=A note on certainty equivalence in dynamic planning;,citation_author=Henri Theil;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_doi=10.1007/978-94-011-2410-2_3;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Power and delay trade-offs in fading channels;,citation_author=Randall Alexander Berry;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_fulltext_html_url=https://dspace.mit.edu/handle/1721.1/9290;,citation_dissertation_institution=Massachusetts Institute of Technology;">
<meta name="citation_reference" content="citation_title=Communication over fading channels with delay constraints;,citation_author=Randall A Berry;,citation_author=Robert G Gallager;,citation_publication_date=2002-05;,citation_cover_date=2002-05;,citation_year=2002;,citation_issue=5;,citation_doi=10.1109/18.995554;,citation_volume=48;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal power-delay tradeoffs in fading channels—small-delay asymptotics;,citation_author=Randall A Berry;,citation_publication_date=2013-06;,citation_cover_date=2013-06;,citation_year=2013;,citation_issue=6;,citation_doi=10.1109/TIT.2013.2253194;,citation_volume=59;,citation_journal_title=IEEE Transactions on Information Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Evaluating a call option and optimal timing strategy in the stock market;,citation_author=Howard M. Taylor;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_fulltext_html_url=http://www.jstor.org/stable/2628546;,citation_issue=1;,citation_issn=00251909, 15265501;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Optimal stopping and applications;,citation_author=Thomas S. Ferguson;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_fulltext_html_url=http://www.math.ucla.edu/~tom/Stopping/Contents.html;">
<meta name="citation_reference" content="citation_title=Who solved the secretary problem?;,citation_author=Thomas S Ferguson;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_journal_title=Statistical science;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Characterizing the structure of optimal stopping policies;,citation_author=Sechan Oh;,citation_author=Özalp Özer;,citation_publication_date=2016-07;,citation_cover_date=2016-07;,citation_year=2016;,citation_issue=11;,citation_doi=10.1111/poms.12579;,citation_volume=25;,citation_journal_title=Production and Operations Management;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Markov decision processes: Discrete stochastic dynamic programming;,citation_author=Martin L Puterman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_doi=10.1002/9780470316887;">
<meta name="citation_reference" content="citation_title=Optimization over time: Dynamic programming and stochastic control. Vol. 1 and 2;,citation_author=Peter Whittle;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;">
<meta name="citation_reference" content="citation_title=Optimal control: Basics and beyond;,citation_author=Peter Whittle;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Dynamic programming and optimal control;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.athenasc.com/dpbook.html;,citation_volume=I and II;">
<meta name="citation_reference" content="citation_title=Abstract dynamic programming;,citation_author=Dimitri P Bertsekas;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://web.mit.edu/dimitrib/www/abstractdp_MIT.html;">
<meta name="citation_reference" content="citation_title=Introduction to stochastic control theory;,citation_author=Karl J. Aström;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;">
<meta name="citation_reference" content="citation_title=Policy invariance under reward transformations: Theory and application to reward shaping;,citation_author=Andrew Y Ng;,citation_author=Daishi Harada;,citation_author=Stuart Russell;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf;,citation_volume=99;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Theoretical and empirical analysis of reward shaping in reinforcement learning;,citation_author=M. Grzes;,citation_author=D. Kudenko;,citation_publication_date=2009-12;,citation_cover_date=2009-12;,citation_year=2009;,citation_doi=10.1109/ICMLA.2009.33;,citation_conference_title=International conference on machine learning and applications;">
<meta name="citation_reference" content="citation_title=Potential based reward shaping tutorial;,citation_author=Sam Devlin;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf;">
<meta name="citation_reference" content="citation_title=How many parts to make at once;,citation_author=Ford W Harris;,citation_publication_date=1913-02;,citation_cover_date=1913-02;,citation_year=1913;,citation_issue=2;,citation_doi=10.1287/opre.38.6.947;,citation_volume=10;,citation_journal_title=The magazine of management;">
<meta name="citation_reference" content="citation_title=The mathematical theory of banking;,citation_author=Francis Y Edgeworth;,citation_publication_date=1888;,citation_cover_date=1888;,citation_year=1888;,citation_fulltext_html_url=https://www.jstor.org/stable/2979084;,citation_issue=1;,citation_volume=51;,citation_journal_title=Journal of the Royal Statistical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Methods of operations research;,citation_author=P. Morse;,citation_author=G. Kimball;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;">
<meta name="citation_reference" content="citation_title=The theory of inventory management;,citation_author=S. Whitin;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;">
<meta name="citation_reference" content="citation_title=Building intuition: Insights from basic operations management models and principles;,citation_author=Evan L. Porteus;,citation_editor=D. Chhajed;,citation_editor=T. J. Lowe;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=10.1007/978-0-387-73699-0;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Selling random wind;,citation_author=Eilyan Bitar;,citation_author=Kameshwar Poolla;,citation_author=Pramod Khargonekar;,citation_author=Ram Rajagopal;,citation_author=Pravin Varaiya;,citation_author=Felix Wu;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 45th hawaii international conference on system sciences;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Fundamental performance limits in cross-layer wireless optimization: Throughput, delay, and energy;,citation_author=Edmund M. Yeh;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_doi=10.1561/0100000014;,citation_issn=1567-2190;,citation_volume=9;,citation_journal_title=Foundations and Trends in Communications and Information Theory;">
<meta name="citation_reference" content="citation_title=Energy-efficient scheduling under delay constraints for wireless networks;,citation_author=Randall Berry;,citation_author=Eytan Modiano;,citation_author=Murtaza Zafer;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_doi=10.2200/S00443ED1V01Y201208CNT011;,citation_volume=5;,citation_journal_title=Synthesis Lectures on Communication Networks;">
<meta name="citation_reference" content="citation_title=Stochastic dominance: Investment decision making under uncertainty;,citation_author=Haim Levy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_doi=10.1007/978-3-319-21708-6;">
<meta name="citation_reference" content="citation_title=Stochastic dominance and expected utility: Survey and analysis;,citation_author=Haim Levy;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_doi=10.1287/mnsc.38.4.555;,citation_volume=38;,citation_journal_title=Management Science;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Stochastically monotone markov chains;,citation_author=D J Daley;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=4;,citation_doi=10.1007/BF00531852;,citation_volume=10;,citation_journal_title=Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Monotone matrices and monotone markov processes;,citation_author=Julian Keilson;,citation_author=Adri Kester;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=3;,citation_volume=5;,citation_journal_title=Stochastic Processes and their Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=On monotonicity of the optimal transmission policy in cross-layer adaptive m -QAM modulation;,citation_author=N. Ding;,citation_author=P. Sadeghi;,citation_author=R. A. Kennedy;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=9;,citation_doi=10.1109/TCOMM.2016.2590427;,citation_issn=1558-0857;,citation_volume=64;,citation_journal_title=IEEE Transactions on Communications;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity in economics: An elementary survey;,citation_author=Rabah Amir;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=3;,citation_doi=10.2307/20062066;,citation_issn=00384038;,citation_volume=71;,citation_journal_title=Southern Economic Journal;,citation_publisher=Southern Economic Association;">
<meta name="citation_reference" content="citation_title=Supermodularity and complementarity;,citation_author=Donald M. Topkis;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_isbn=9780691032443;">
<meta name="citation_reference" content="citation_title=Sufficient conditions for the value function and optimal strategy to be even and quasi-convex;,citation_author=J. Chakravorty;,citation_author=A. Mahajan;,citation_publication_date=2018-11;,citation_cover_date=2018-11;,citation_year=2018;,citation_issue=11;,citation_doi=10.1109/TAC.2018.2800796;,citation_issn=2334-3303;,citation_volume=63;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=On the locality of action domination in sequential decision making;,citation_author=Emmanuel Rachelson;,citation_author=Michail G Lagoudakis;,citation_publication_date=2010-01;,citation_cover_date=2010-01;,citation_year=2010;,citation_fulltext_html_url=https://oatao.univ-toulouse.fr/17977/;,citation_conference_title=Proceedings of 11th international symposium on artificial intelligence and mathematics;">
<meta name="citation_reference" content="citation_title=Lipschitz continuity of value functions in Markovian decision processes;,citation_author=Karl Hinderer;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_doi=10.1007/s00186-005-0438-1;,citation_volume=62;,citation_journal_title=Mathematical Methods of Operations Research;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=DeepMDP: Learning continuous latent space models for representation learning;,citation_author=Carles Gelada;,citation_author=Saurabh Kumar;,citation_author=Jacob Buckman;,citation_author=Ofir Nachum;,citation_author=Marc G. Bellemare;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=http://proceedings.mlr.press/v97/gelada19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Convergence of discretization procedures in dynamic programming;,citation_author=Demitri Bertsekas;,citation_publication_date=1975-06;,citation_cover_date=1975-06;,citation_year=1975;,citation_issue=3;,citation_doi=10.1109/TAC.1975.1100984;,citation_issn=2334-3303;,citation_volume=20;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=Towards a unified theory of state abstraction for MDPs;,citation_author=Lihong Li;,citation_author=Thomas J Walsh;,citation_author=Michael L Littman;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://anytime.cs.umass.edu/aimath06/proceedings/P21.pdf;,citation_conference_title=ISAIM;">
<meta name="citation_reference" content="citation_title=Death and discounting;,citation_author=A. Shwartz;,citation_publication_date=2001-04;,citation_cover_date=2001-04;,citation_year=2001;,citation_fulltext_html_url=https://doi.org/10.1109/9.917668;,citation_issue=4;,citation_doi=10.1109/9.917668;,citation_volume=46;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Constrained markov decision processes;,citation_author=Eitan. Altman;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://www-sop.inria.fr/members/Eitan.Altman/TEMP/h.pdf;">
<meta name="citation_reference" content="citation_title=Optimal investment policies for the horse race model&amp;amp;amp;quot;;,citation_author=Thomas S. Ferguson;,citation_author=C. Zachary Gilstein;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=https://www.math.ucla.edu/~tom/papers/unpublished/Zach2.pdf;">
<meta name="citation_reference" content="citation_title=Discovery of the kalman filter as a practical tool for aerospace and;,citation_author=Stanley F. Mcgee;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_fulltext_html_url=https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19860003843.pdf;,citation_technical_report_institution=National Aeronautics; Space Administration;">
<meta name="citation_reference" content="citation_title=Stochastic systems: Estimation identification and adaptive control;,citation_author=P. R. Kumar;,citation_author=Pravin Varaiya;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;">
<meta name="citation_reference" content="citation_title=Stochastic dynamic programming and the control of queueing systems;,citation_author=Linn I. Sennott;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_isbn=0-471-16120-9;">
<meta name="citation_reference" content="citation_title=Discrete-time controlled Markov processes with average cost criterion - a survey;,citation_author=Aristotle Arapostathis;,citation_author=Vivek S. Borkar;,citation_author=Emmaneul Fernandez-Gaucherand;,citation_author=Mrinak K. Ghosh;,citation_author=Steven I. Marcus;,citation_publication_date=1993-03;,citation_cover_date=1993-03;,citation_year=1993;,citation_issue=2;,citation_volume=31;,citation_journal_title=SIAM Journal of Control and Optimization;">
<meta name="citation_reference" content="citation_title=The optimal control of partially observable markov processes over a finite horizon;,citation_author=Richard D. Smallwood;,citation_author=Edward J. Sondik;,citation_publication_date=1973-10;,citation_cover_date=1973-10;,citation_year=1973;,citation_issue=5;,citation_doi=10.1287/opre.21.5.1071;,citation_volume=21;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Convex analytic methods in markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_11;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=A convex analytic approach to markov decision processes;,citation_author=Vivek S. Borkar;,citation_publication_date=1988-08;,citation_cover_date=1988-08;,citation_year=1988;,citation_issue=4;,citation_doi=10.1007/bf00353877;,citation_volume=78;,citation_journal_title=Probability Theory and Related Fields;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Applications of markov decision processes in communication networks;,citation_author=Eitan Altman;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_16;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Water reservoir applications of markov decision processes;,citation_author=Bernard F. Lamond;,citation_author=Abdeslem Boukhtouta;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_doi=10.1007/978-1-4615-0805-2_17;,citation_inbook_title=International series in operations research &amp;amp;amp; management science;">
<meta name="citation_reference" content="citation_title=Asymptotically efficient adaptive allocation rules;,citation_author=T. L Lai;,citation_author=Herbert Robbins;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_issue=1;,citation_doi=http://dx.doi.org/10.1016/0196-8858(85)90002-8;,citation_issn=0196-8858;,citation_volume=6;,citation_journal_title=Advances in Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Dynamic programming;,citation_author=Richard Bellman;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;">
<meta name="citation_reference" content="citation_title=A dynamic allocation index for the discounted multiarmed bandit problem;,citation_author=J. C. Gittins;,citation_author=D. M. Jones;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_volume=9;,citation_inbook_title=Progress in statistics;">
<meta name="citation_reference" content="citation_title=Bandit processes and dynamic allocation indices;,citation_author=John C Gittins;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=2;,citation_volume=41;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits and the Gittins index;,citation_abstract=A plausible conjecture (C) has the implication that a relationship (12) holds between the maximal expected rewards for a multi-project process and for a one-project process (F and Ï&amp;amp;amp;lt;sub&amp;gt;i&amp;lt;/sub&amp;gt; respectively), if the option of retirement with reward M is available. The validity of this relation and optimality of Gittins’ index rule are verified simultaneously by dynamic programming methods. These results are partially extended to the case of so-called &amp;quot;bandit superprocesses&amp;quot;.;,citation_author=P. Whittle;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=2;,citation_issn=00359246;,citation_volume=42;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);,citation_publisher=[Royal Statistical Society, Wiley];">
<meta name="citation_reference" content="citation_title=Four proofs of Gittins’ multiarmed bandit theorem;,citation_abstract=We study four proofs that the Gittins index priority rule is optimal for alternative bandit processes. These include Gittins’ original exchange argument, Weber’s prevailing charge argument, Whittle’s Lagrangian dual approach, and Bertsimas and Niño-Mora’s proof based on the achievable region approach and generalized conservation laws. We extend the achievable region proof to infinite countable state spaces, by using infinite dimensional linear programming theory.;,citation_author=Esther Frostig;,citation_author=Gideon Weiss;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=http://dx.doi.org/10.1007/s10479-013-1523-0;,citation_issue=1;,citation_doi=10.1007/s10479-013-1523-0;,citation_issn=1572-9338;,citation_volume=241;,citation_journal_title=Annals of Operations Research;">
<meta name="citation_reference" content="citation_title=The multi-armed bandit problem: Decomposition and computation;,citation_author=Michael N Katehakis;,citation_author=Arthur F Veinott;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=2;,citation_volume=12;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=INFORMS;">
<meta name="citation_reference" content="citation_title=Multi-armed bandits under general deprecation and commitment;,citation_author=Wesley Cowan;,citation_author=Michael N. Katehakis;,citation_publication_date=2015-10;,citation_cover_date=2015-10;,citation_year=2015;,citation_issue=1;,citation_doi=10.1017/s0269964814000217;,citation_volume=29;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Restless bandits: Activity allocation in a changing world;,citation_author=Peter Whittle;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=A;,citation_volume=25;,citation_journal_title=Journal of applied probability;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=Foundations and applications of sensor management;,citation_author=A. Mahajan;,citation_author=D. Teneketzis;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Two characterizations of optimality in dynamic programming;,citation_author=Ioannis Karatzas;,citation_author=William D. Sudderth;,citation_publication_date=2010-11;,citation_cover_date=2010-11;,citation_year=2010;,citation_issue=3;,citation_doi=10.1007/s00245-009-9093-x;,citation_volume=61;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Structural properties of stochastic dynamic programs;,citation_author=James E. Smith;,citation_author=Kevin F. McCardle;,citation_publication_date=2002-10;,citation_cover_date=2002-10;,citation_year=2002;,citation_issue=5;,citation_doi=10.1287/opre.50.5.796.365;,citation_volume=50;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Monotonicity in multidimensional markov decision processes for the batch dispatch problem;,citation_author=Katerina Papadaki;,citation_author=Warren B. Powell;,citation_publication_date=2007-03;,citation_cover_date=2007-03;,citation_year=2007;,citation_issue=2;,citation_doi=10.1016/j.orl.2006.03.013;,citation_volume=35;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Basic ideas for event-based optimization of markov systems;,citation_author=Xi-Ren Cao;,citation_publication_date=2005-06;,citation_cover_date=2005-06;,citation_year=2005;,citation_issue=2;,citation_doi=10.1007/s10626-004-6211-4;,citation_volume=15;,citation_journal_title=Discrete Event Dynamic Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Monotonicity in markov reward and decision chains: Theory and applications;,citation_author=Ger Koole;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_doi=10.1561/0900000002;,citation_volume=1;,citation_journal_title=Foundations and Trends in Stochastic Systems;,citation_publisher=Now Publishers;">
<meta name="citation_reference" content="citation_title=Stochastic learning and optimization;,citation_author=Xi-Ren Cao;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-0-387-69082-7;">
<meta name="citation_reference" content="citation_title=Optimality and approximation with policy gradient methods in markov decision processes;,citation_abstract=Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution (say with a sufficiently rich policy class); how they cope with approximation error due to using a restricted class of parametric policies; or their finite sample behavior. Such characterizations are important not only to compare these methods to their approximate value function counterparts (where such issues are relatively well understood, at least in the worst case), but also to help with more principled approaches to algorithm design. This work provides provable characterizations of computational, approximation, and sample size issues with regards to policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: 1) &amp;amp;amp;quot;tabular&amp;quot; policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy, and 2) restricted policy classes, which may not contain the optimal policy and where we provide agnostic learning results. One insight of this work is in formalizing the importance how a favorable initial state distribution provides a means to circumvent worst-case exploration issues. Overall, these results place policy gradient methods under a solid theoretical footing, analogous to the global convergence guarantees of iterative value function based algorithms.;,citation_author=Alekh Agarwal;,citation_author=Sham M. Kakade;,citation_author=Jason D. Lee;,citation_author=Gaurav Mahajan;,citation_publication_date=2019-08-01;,citation_cover_date=2019-08-01;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1908.00261v2;">
<meta name="citation_reference" content="citation_title=Analysis of stochastic dual dynamic programming method;,citation_author=Alexander Shapiro;,citation_publication_date=2011-02;,citation_cover_date=2011-02;,citation_year=2011;,citation_issue=1;,citation_doi=10.1016/j.ejor.2010.08.007;,citation_volume=209;,citation_journal_title=European Journal of Operational Research;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Multi-stage stochastic optimization applied to energy planning;,citation_author=M. V. F. Pereira;,citation_author=L. M. V. G. Pinto;,citation_publication_date=1991-05;,citation_cover_date=1991-05;,citation_year=1991;,citation_issue=1-3;,citation_doi=10.1007/bf01582895;,citation_volume=52;,citation_journal_title=Mathematical Programming;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Approximate information state for partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Aditya Mahajan;,citation_publication_date=2019-12;,citation_cover_date=2019-12;,citation_year=2019;,citation_doi=10.1109/cdc40024.2019.9029898;,citation_conference_title=2019 IEEE 58th conference on decision and control (CDC);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Approximate information state for approximate planning and reinforcement learning in partially observed systems;,citation_author=Jayakumar Subramanian;,citation_author=Amit Sinha;,citation_author=Raihan Seraj;,citation_author=Aditya Mahajan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=http://jmlr.org/papers/v23/20-1165.html;,citation_issue=12;,citation_volume=23;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=On policy independence of conditional expectation;,citation_author=Hans S. Witsenhausen;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_volume=28;,citation_journal_title=Information and Control;">
<meta name="citation_reference" content="citation_title=Incremental pruning: A simple, fast, exact method for partially observable Markov decision processes;,citation_author=Anthony Cassandra;,citation_author=Michael L. Littman;,citation_author=Nevin L. Zhang;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_conference_title=Proceedings of the thirteenth conference on uncertainty in artificial intelligence;">
<meta name="citation_reference" content="citation_title=Partially observable Markov decision processes: A geometric technique and analysis;,citation_author=H. Zhang;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Operations Research;">
<meta name="citation_reference" content="citation_title=Algorithms for partially observable markov decision processes;,citation_author=Hsien-Te Cheng;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_dissertation_institution=University of British Columbia;">
<meta name="citation_reference" content="citation_title=Acting optimally in partially observable stochastic domains;,citation_author=Anthony R Cassandra;,citation_author=Leslie Pack Kaelbling;,citation_author=Michael L Littman;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_volume=94;,citation_conference_title=AAAI;">
<meta name="citation_reference" content="citation_title=Planning in stochastic domains: Problem characteristics and approximation;,citation_author=N Zhang;,citation_author=W Liu;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_technical_report_institution=Hong Kong Univeristy of Science; Technology;,citation_technical_report_number=HKUST-CS96-31;">
<meta name="citation_reference" content="citation_title=Sequential tests of statistical hypotheses;,citation_author=A. Wald;,citation_publication_date=1945-06;,citation_cover_date=1945-06;,citation_year=1945;,citation_issue=2;,citation_doi=10.1214/aoms/1177731118;,citation_volume=16;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bayes and minimax solutions of sequential decision problems;,citation_author=K. J. Arrow;,citation_author=D. Blackwell;,citation_author=M. A. Girshick;,citation_publication_date=1949-07;,citation_cover_date=1949-07;,citation_year=1949;,citation_issue=3/4;,citation_doi=10.2307/1905525;,citation_volume=17;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Optimal statistical decisions;,citation_author=Morris DeGroot;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_isbn=047168029X;">
<meta name="citation_reference" content="citation_title=On a test whether two samples are from the same population;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1940-06;,citation_cover_date=1940-06;,citation_year=1940;,citation_issue=2;,citation_doi=10.1214/aoms/1177731909;,citation_volume=11;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Optimum character of the sequential probability ratio test;,citation_author=A. Wald;,citation_author=J. Wolfowitz;,citation_publication_date=1948-09;,citation_cover_date=1948-09;,citation_year=1948;,citation_issue=3;,citation_doi=10.1214/aoms/1177730197;,citation_volume=19;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=A stochastic sensor selection scheme for sequential hypothesis testing with multiple sensors;,citation_author=Cheng-Zong Bai;,citation_author=Vaibhav Katewa;,citation_author=Vijay Gupta;,citation_author=Yih-Fang Huang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=14;,citation_volume=63;,citation_journal_title=IEEE transactions on signal processing;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=A discrete markov chain representation of the sequential probability ratio test;,citation_author=Willam H. Woodall;,citation_author=Marion R. Reynolds;,citation_publication_date=1983-01;,citation_cover_date=1983-01;,citation_year=1983;,citation_issue=1;,citation_doi=10.1080/07474948308836025;,citation_volume=2;,citation_journal_title=Communications in Statistics. Part C: Sequential Analysis;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Mean-field games with a major player;,citation_author=Jean-Michel Lasry;,citation_author=Pierre-Louis Lions;,citation_publication_date=2018-08;,citation_cover_date=2018-08;,citation_year=2018;,citation_issue=8;,citation_doi=10.1016/j.crma.2018.06.001;,citation_volume=356;,citation_journal_title=Comptes Rendus Mathematique;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Remote estimation over a packet-drop channel with markovian state;,citation_author=Jhelum Chakravorty;,citation_author=Aditya Mahajan;,citation_publication_date=2020-05;,citation_cover_date=2020-05;,citation_year=2020;,citation_issue=5;,citation_doi=10.1109/tac.2019.2926160;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Optimal state estimation in the presence of communication costs and packet drops;,citation_author=Gabriel M. Lipsa;,citation_author=Nuno C. Martins;,citation_publication_date=2009-09;,citation_cover_date=2009-09;,citation_year=2009;,citation_doi=10.1109/allerton.2009.5394899;,citation_conference_title=Annual allerton conference on communication, control, and computing (allerton);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Remote state estimation with communication costs for first-order LTI systems;,citation_author=G. M. Lipsa;,citation_author=N. C. Martins;,citation_publication_date=2011-09;,citation_cover_date=2011-09;,citation_year=2011;,citation_issue=9;,citation_doi=10.1109/tac.2011.2139370;,citation_volume=56;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Policy improvement and the newton-raphson algorithm;,citation_author=P. Whittle;,citation_author=N. Komarova;,citation_publication_date=1988-04;,citation_cover_date=1988-04;,citation_year=1988;,citation_issue=2;,citation_doi=10.1017/s0269964800000760;,citation_volume=2;,citation_journal_title=Probability in the Engineering and Informational Sciences;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Optimal adaptive control of linear-quadratic-gaussian systems;,citation_author=P. R. Kumar;,citation_publication_date=1983-03;,citation_cover_date=1983-03;,citation_year=1983;,citation_issue=2;,citation_doi=10.1137/0321009;,citation_volume=21;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=The optimal inventory policy for batch ordering;,citation_author=Arthur F. Veinott;,citation_publication_date=1965-06;,citation_cover_date=1965-06;,citation_year=1965;,citation_issue=3;,citation_doi=10.1287/opre.13.3.424;,citation_volume=13;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Elements of game theory;,citation_author=Ye S. Venttsel;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_fulltext_html_url=https://archive.org/details/ElementsOfGameTheorylittleMathematicsLibrary/;">
<meta name="citation_reference" content="citation_title=Periodic review inventory systems with continuous demand and discrete order sizes;,citation_author=John N. Tsitsiklis;,citation_publication_date=1984-10;,citation_cover_date=1984-10;,citation_year=1984;,citation_issue=10;,citation_doi=10.1287/mnsc.30.10.1250;,citation_volume=30;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Risk sensitivity, A strangely pervasive concept;,citation_author=Peter Whittle;,citation_publication_date=2002-02;,citation_cover_date=2002-02;,citation_year=2002;,citation_issue=1;,citation_doi=10.1017/s1365100502027025;,citation_volume=6;,citation_journal_title=Macroeconomic Dynamics;,citation_publisher=Cambridge University Press (CUP);">
<meta name="citation_reference" content="citation_title=Risk-sensitive markov decision processes;,citation_author=Ronald A. Howard;,citation_author=James E. Matheson;,citation_publication_date=1972-03;,citation_cover_date=1972-03;,citation_year=1972;,citation_issue=7;,citation_doi=10.1287/mnsc.18.7.356;,citation_volume=18;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Inequalities: Theory of majorization and its applications;,citation_author=Albert W. Marshall;,citation_author=Ingram Olkin;,citation_author=Barry C. Arnold;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_doi=10.1007/978-0-387-68276-1;">
<meta name="citation_reference" content="citation_title=Risk sensitive control of markov processes in countable state space;,citation_author=Daniel Hernandez-Hernández;,citation_author=Steven I. Marcus;,citation_publication_date=1996-11;,citation_cover_date=1996-11;,citation_year=1996;,citation_issue=3;,citation_doi=10.1016/s0167-6911(96)00051-5;,citation_volume=29;,citation_journal_title=Systems &amp;amp;amp; Control Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Existence of risk-sensitive optimal stationary policies for controlled markov processes;,citation_author=D. Hernández-Hernández;,citation_publication_date=1999-11;,citation_cover_date=1999-11;,citation_year=1999;,citation_issue=3;,citation_doi=10.1007/s002459900126;,citation_volume=40;,citation_journal_title=Applied Mathematics and Optimization;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Convex risk measures;,citation_author=Hans Föllmer;,citation_author=Alexander Schied;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470061602.eqf15003;,citation_doi=10.1002/9780470061602.eqf15003;,citation_isbn=9780470061602;,citation_inbook_title=Encyclopedia of quantitative finance;">
<meta name="citation_reference" content="citation_title=Updating the inverse of a matrix;,citation_author=William W. Hager;,citation_publication_date=1989-06;,citation_cover_date=1989-06;,citation_year=1989;,citation_issue=2;,citation_doi=10.1137/1031049;,citation_volume=31;,citation_journal_title=SIAM Review;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=A stochastic approximation method;,citation_author=Herbert Robbins;,citation_author=Sutton Monro;,citation_publication_date=1951-09;,citation_cover_date=1951-09;,citation_year=1951;,citation_issue=3;,citation_doi=10.1214/aoms/1177729586;,citation_volume=22;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=The o.d.e. Method for convergence of stochastic approximation and reinforcement learning;,citation_author=V. S. Borkar;,citation_author=S. P. Meyn;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=2;,citation_doi=10.1137/s0363012997331639;,citation_volume=38;,citation_journal_title=SIAM Journal on Control and Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Q-learning;,citation_author=Christopher J. C. H. Watkins;,citation_author=Peter Dayan;,citation_publication_date=1992-05;,citation_cover_date=1992-05;,citation_year=1992;,citation_issue=3-4;,citation_doi=10.1007/bf00992698;,citation_volume=8;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Asynchronous stochastic approximation and q-learning;,citation_author=John N. Tsitsiklis;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993306;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=An analog scheme for fixed point computation. I. theory;,citation_author=V. S. Borkar;,citation_author=K. Soumyanatha;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=4;,citation_doi=10.1109/81.563625;,citation_volume=44;,citation_journal_title=IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the convergence of stochastic iterative dynamic programming algorithms;,citation_author=Tommi Jaakkola;,citation_author=Michael I. Jordan;,citation_author=Satinder P. Singh;,citation_publication_date=1994-11;,citation_cover_date=1994-11;,citation_year=1994;,citation_issue=6;,citation_doi=10.1162/neco.1994.6.6.1185;,citation_volume=6;,citation_journal_title=Neural Computation;,citation_publisher=MIT Press - Journals;">
<meta name="citation_reference" content="citation_title=Dynamic programming and markov processes;,citation_author=Ronald A. Howard;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and martingale inequalities: A survey;,citation_author=Fan Chung;,citation_author=Linyuan Lu;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=https://projecteuclid.org:443/euclid.im/1175266369;,citation_issue=1;,citation_volume=3;,citation_journal_title=Internet Math.;,citation_publisher=A K Peters, Ltd.;">
<meta name="citation_reference" content="citation_title=On the fenchel duality between strong convexity and lipschitz continuous gradient;,citation_abstract=We provide a simple proof for the Fenchel duality between strong convexity and Lipschitz continuous gradient. To this end, we first establish equivalent conditions of convexity for a general function that may not be differentiable. By utilizing these equivalent conditions, we can directly obtain equivalent conditions for strong convexity and Lipschitz continuous gradient. Based on these results, we can easily prove Fenchel duality. Beside this main result, we also identify several conditions that are implied by strong convexity or Lipschitz continuous gradient, but are not necessarily equivalent to them. This means that these conditions are more general than strong convexity or Lipschitz continuous gradient themselves.;,citation_author=Xingyu Zhou;,citation_publication_date=2018-03-17;,citation_cover_date=2018-03-17;,citation_year=2018;,citation_fulltext_html_url=https://arxiv.org/abs/1803.06573v1;">
<meta name="citation_reference" content="citation_title=Optimal control of markov processes with incomplete state information;,citation_author=K. J Åström;,citation_publication_date=1965-02;,citation_cover_date=1965-02;,citation_year=1965;,citation_issue=1;,citation_doi=10.1016/0022-247x(65)90154-x;,citation_volume=10;,citation_journal_title=Journal of Mathematical Analysis and Applications;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Dynamic service migration in mobile edge computing based on Markov decision process;,citation_author=Shiqiang Wang;,citation_author=Rahul Urgaonkar;,citation_author=Murtaza Zafer;,citation_author=Ting He;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_issue=3;,citation_doi=10.1109/tnet.2019.2916577;,citation_volume=27;,citation_journal_title=IEEE/ACM Transactions on Networking;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Dynamic service migration and workload scheduling in edge-clouds;,citation_author=Rahul Urgaonkar;,citation_author=Shiqiang Wang;,citation_author=Ting He;,citation_author=Murtaza Zafer;,citation_author=Kevin Chan;,citation_author=Kin K. Leung;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_doi=10.1016/j.peva.2015.06.013;,citation_volume=91;,citation_journal_title=Performance Evaluation;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=The role and use of the stochastic linear-quadratic-gaussian problem in control system design;,citation_author=M. Athans;,citation_publication_date=1971-12;,citation_cover_date=1971-12;,citation_year=1971;,citation_issue=6;,citation_doi=10.1109/tac.1971.1099818;,citation_volume=16;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Complexity bounds for approximately solving discounted MDPs by value iterations;,citation_author=Eugene A. Feinberg;,citation_author=Gaojin He;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_doi=10.1016/j.orl.2020.07.001;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=How does the value function of a markov decision process depend on the transition probabilities?;,citation_author=Alfred Müller;,citation_publication_date=1997-11;,citation_cover_date=1997-11;,citation_year=1997;,citation_issue=4;,citation_doi=10.1287/moor.22.4.872;,citation_volume=22;,citation_journal_title=Mathematics of Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=What is RKHS?;,citation_author=Dino Sejdinovic;,citation_author=Arthur Gretton;,citation_fulltext_html_url=http://www.stats.ox.ac.uk/~sejdinov/teaching/atml14/Theory_2014.pdf;">
<meta name="citation_reference" content="citation_title=Martingale methods in stochastic control;,citation_author=M. H. A. Davis;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_doi=10.1007/bfb0009377;,citation_inbook_title=Stochastic control theory and stochastic differential systems;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and model selection;,citation_author=Jean Picard;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_doi=10.1007/978-3-540-48503-2;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Phillippe Rigollet;,citation_publication_date=2015-07;,citation_cover_date=2015-07;,citation_year=2015;,citation_fulltext_html_url=https://ocw.mit.edu/courses/mathematics/18-s997-high-dimensional-statistics-spring-2015/lecture-notes/;">
<meta name="citation_reference" content="citation_title=Subgaussian random variables: An expository note;,citation_author=Omar Rivasplata;,citation_publication_date=2012-11;,citation_cover_date=2012-11;,citation_year=2012;,citation_fulltext_html_url=http://stat.cmu.edu/~arinaldo/36788/subgaussians.pdf;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics;,citation_author=Martin J. Wainwright;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_doi=10.1017/9781108627771;">
<meta name="citation_reference" content="citation_title=Selecting computations: Theory and applications;,citation_author=Nicholas Hay;,citation_author=S. Russell;,citation_author=David Tolpin;,citation_author=S. E. Shimony;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=http://www.auai.org/uai2012/papers/123.pdf;,citation_conference_title=UAI;">
<meta name="citation_reference" content="citation_title=On linear control theory;,citation_author=D. Peter Joseph;,citation_author=T. Julius Tou;,citation_publication_date=1961;,citation_cover_date=1961;,citation_year=1961;,citation_issue=4;,citation_doi=10.1109/tai.1961.6371743;,citation_volume=80;,citation_journal_title=Transactions of the American Institute of Electrical Engineers, Part II: Applications and Industry;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=On the separation theorem of stochastic control;,citation_author=W. M. Wonham;,citation_publication_date=1968-05;,citation_cover_date=1968-05;,citation_year=1968;,citation_issue=2;,citation_doi=10.1137/0306023;,citation_volume=6;,citation_journal_title=SIAM Journal on Control;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Some comments on a theorem of Hardy and Littlewood;,citation_author=R. Sznajder;,citation_author=J. A. Filar;,citation_publication_date=1992-10;,citation_cover_date=1992-10;,citation_year=1992;,citation_issue=1;,citation_doi=10.1007/bf00939913;,citation_volume=75;,citation_journal_title=Journal of Optimization Theory and Applications;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Notes on the theory of series (XVI): Two Tauberian theorems;,citation_author=G. H. Hardy;,citation_author=J. E. Littlewood;,citation_publication_date=1931-10;,citation_cover_date=1931-10;,citation_year=1931;,citation_issue=4;,citation_doi=10.1112/jlms/s1-6.4.281;,citation_volume=s1-6;,citation_journal_title=Journal of the London Mathematical Society;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=The Hardy-Littlewood theorems;,citation_author=Jacob Korevaar;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_doi=10.1007/978-3-662-10225-1_1;,citation_inbook_title=Tauberian theory: A century of developments;">
<meta name="citation_reference" content="citation_title=Monotone optimal policies for markov decision processes;,citation_author=Richard F. Serfozo;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_doi=10.1007/bfb0120752;,citation_inbook_title=Mathematical programming studies;">
<meta name="citation_reference" content="citation_title=Cross-layer communication over fading channels with adaptive decision feedback;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_author=Edmund Yeh;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=International symposium on modeling and optimization in mobile, ad hoc, and wireless networks (WiOPT);">
<meta name="citation_reference" content="citation_title=Counterexamples on the monotonicity of delay optimal strategies for energy harvesting transmitters;,citation_author=Borna Sayedana;,citation_author=Aditya Mahajan;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_doi=10.1109/lwc.2020.2981066;,citation_journal_title=IEEE Wireless Communications Letters;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=Q-learning for MDPs with general spaces: Convergence and near optimality via quantization under weak continuity;,citation_abstract=Reinforcement learning algorithms often require finiteness of state and action spaces in Markov decision processes (MDPs) and various efforts have been made in the literature towards the applicability of such algorithms for continuous state and action spaces. In this paper, we show that under very mild regularity conditions (in particular, involving only weak continuity of the transition kernel of an MDP), Q-learning for standard Borel MDPs via quantization of states and actions converge to a limit, and furthermore this limit satisfies an optimality equation which leads to near optimality with either explicit performance bounds or which are guaranteed to be asymptotically optimal. Our approach builds on (i) viewing quantization as a measurement kernel and thus a quantized MDP as a POMDP, (ii) utilizing near optimality and convergence results of Q-learning for POMDPs, and (iii) finally, near-optimality of finite state model approximations for MDPs with weakly continuous kernels which we show to correspond to the fixed point of the constructed POMDP. Thus, our paper presents a very general convergence and approximation result for the applicability of Q-learning for continuous MDPs.;,citation_author=Ali Devran Kara;,citation_author=Naci Saldi;,citation_author=Serdar Yüksel;,citation_publication_date=2021-11-12;,citation_cover_date=2021-11-12;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2111.06781v1;">
<meta name="citation_reference" content="citation_title=Bounds and transformations for discounted finite markov decision chains;,citation_author=Evan L. Porteus;,citation_publication_date=1975-08;,citation_cover_date=1975-08;,citation_year=1975;,citation_issue=4;,citation_doi=10.1287/opre.23.4.761;,citation_volume=23;,citation_journal_title=Operations Research;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Calculus on MDPs: Potential shaping as a gradient;,citation_abstract=In reinforcement learning, different reward functions can be equivalent in terms of the optimal policies they induce. A particularly well-known and important example is potential shaping, a class of functions that can be added to any reward function without changing the optimal policy set under arbitrary transition dynamics. Potential shaping is conceptually similar to potentials, conservative vector fields and gauge transformations in math and physics, but this connection has not previously been formally explored. We develop a formalism for discrete calculus on graphs that abstract a Markov Decision Process, and show how potential shaping can be formally interpreted as a gradient within this framework. This allows us to strengthen results from Ng et al. (1999) describing conditions under which potential shaping is the only additive reward transformation to always preserve optimal policies. As an additional application of our formalism, we define a rule for picking a single unique reward function from each potential shaping equivalence class.;,citation_author=Erik Jenner;,citation_author=Herke Hoof;,citation_author=Adam Gleave;,citation_publication_date=2022-08-20;,citation_cover_date=2022-08-20;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2208.09570v1;">
<meta name="citation_reference" content="citation_title=Dynamic potential-based reward shaping;,citation_abstract=Potential-based reward shaping can significantly improve the time needed to learn an optimal policy and, in multi-agent systems, the performance of the final joint-policy. It has been proven to not alter the optimal policy of an agent learning alone or the Nash equilibria of multiple agents learning together.However, a limitation of existing proofs is the assumption that the potential of a state does not change dynamically during the learning. This assumption often is broken, especially if the reward-shaping function is generated automatically.In this paper we prove and demonstrate a method of extending potential-based reward shaping to allow dynamic shaping and maintain the guarantees of policy invariance in the single-agent case and consistent Nash equilibria in the multi-agent case.;,citation_author=Sam Devlin;,citation_author=Daniel Kudenko;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_isbn=0981738117;,citation_conference_title=Proceedings of the 11th international conference on autonomous agents and multiagent systems;,citation_conference=International Foundation for Autonomous Agents; Multiagent Systems;,citation_series_title=AAMAS ’12;">
<meta name="citation_reference" content="citation_title=Potential-based shaping and q-value initialization are equivalent;,citation_abstract=Shaping has proven to be a powerful but precarious means of improving reinforcement learning performance. Ng, Harada, and Russell (1999) proposed the potential-based shaping algorithm for adding shaping rewards in a way that guarantees the learner will learn optimal behavior.In this note, we prove certain similarities between this shaping algorithm and the initialization step required for several reinforcement learning algorithms. More specifically, we prove that a reinforcement learner with initial Q-values based on the shaping algorithm’s potential function make the same updates throughout learning as a learner receiving potential-based shaping rewards. We further prove that under a broad category of policies, the behavior of these two learners are indistinguishable. The comparison provides intuition on the theoretical properties of the shaping algorithm as well as a suggestion for a simpler method for capturing the algorithm’s benefit. In addition, the equivalence raises previously unaddressed issues concerning the efficiency of learning with potential-based shaping.;,citation_author=Eric Wiewiora;,citation_publication_date=2003-09;,citation_cover_date=2003-09;,citation_year=2003;,citation_issue=1;,citation_issn=1076-9757;,citation_volume=19;,citation_journal_title=Journal of Artificial Intelligence Research;,citation_publisher=AI Access Foundation;">
<meta name="citation_reference" content="citation_title=Behavior of organisms;,citation_author=B. F. Skinner;,citation_publication_date=1938;,citation_cover_date=1938;,citation_year=1938;,citation_isbn=9781583900079;">
<meta name="citation_reference" content="citation_title=John von Neumann’s conception of the minimax theorem: A journey through different mathematical contexts;,citation_author=Tinne Hoff Kjeldsen;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_fulltext_html_url=http://www.jstor.org/stable/41134130;,citation_issue=1;,citation_issn=00039519, 14320657;,citation_volume=56;,citation_journal_title=Archive for History of Exact Sciences;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in multiple independent Gaussian channels as a game;,citation_author=Michail Fasoulakis;,citation_author=Apostolos Traganitis;,citation_author=Anthony Ephremides;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1007/978-3-030-16989-3_1;,citation_inbook_title=Lecture notes of the institute for computer sciences, social informatics and telecommunications engineering;">
<meta name="citation_reference" content="citation_title=A jamming game in wireless networks with transmission cost;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2007-06;,citation_cover_date=2007-06;,citation_year=2007;,citation_fulltext_html_url=https://www-sop.inria.fr/members/Eitan.Altman/PAPERS/andrey-lncs.pdf;,citation_conference_title=EuroFGI international conference on network control and optimization (NET-COOP);,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Closed form solutions for symmetric water filling games;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_doi=https://doi.org/10.1109/INFOCOM.2008.117;,citation_conference_title=IEEE INFOCOM conference on computer communications;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Closed form solutions for water-filling problems in optimization and game frameworks;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=47;,citation_journal_title=Telecommunication Systems;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Jamming in wireless networks: The case of several jammers;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=2009 international conference on game theory for networks;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Jamming game with incomplete information about the jammer;,citation_author=Eitan Altman;,citation_author=Konstantin Avrachenkov;,citation_author=Andrey Garnaev;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the fourth international ICST conference on performance evaluation methodologies and tools;">
<meta name="citation_reference" content="citation_title=Equilibrium points in n -person games;,citation_author=John F. Nash;,citation_publication_date=1950-01;,citation_cover_date=1950-01;,citation_year=1950;,citation_issue=1;,citation_doi=10.1073/pnas.36.1.48;,citation_volume=36;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=Proceedings of the National Academy of Sciences;">
<meta name="citation_reference" content="citation_title=A further generalization of the Kakutani fixed point theorem, with application to nash equilibrium points;,citation_author=I. L. Glicksberg;,citation_publication_date=1952-02;,citation_cover_date=1952-02;,citation_year=1952;,citation_issue=1;,citation_doi=10.2307/2032478;,citation_volume=3;,citation_journal_title=Proceedings of the American Mathematical Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=The logic of animal conflict;,citation_author=J Maynard Smith;,citation_author=G. R. Price;,citation_publication_date=1973-11;,citation_cover_date=1973-11;,citation_year=1973;,citation_issue=5427;,citation_doi=10.1038/246015a0;,citation_volume=246;,citation_journal_title=Nature;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Evolution and the theory of games;,citation_author=John Maynard Smith;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_isbn=0521246733;">
<meta name="citation_reference" content="citation_title=The selfish gene;,citation_author=Richard Dawkins;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_isbn=019857519X;">
<meta name="citation_reference" content="citation_title=Population games and evolutionary dynamics;,citation_author=William H. Sandholm;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_isbn=9780262195874;">
<meta name="citation_reference" content="citation_title=A note on evolutionary stable strategies and game dynamics;,citation_author=Josef Hofbauer;,citation_author=Peter Schuster;,citation_author=Karl Sigmund;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=3;,citation_volume=81;,citation_journal_title=Journal of Theoretical Biology;">
<meta name="citation_reference" content="citation_title=Evolutionary stable strategies and game dynamics;,citation_author=Peter D. Taylor;,citation_author=Leo B. Jonker;,citation_publication_date=1978-07;,citation_cover_date=1978-07;,citation_year=1978;,citation_issue=1-2;,citation_doi=10.1016/0025-5564(78)90077-9;,citation_volume=40;,citation_journal_title=Mathematical Biosciences;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium in a nutshell;,citation_author=Rabah Amir;,citation_author=Sergei Belkov;,citation_author=Igor V. Evstigneev;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_issue=4;,citation_doi=10.1007/s11238-017-9609-9;,citation_volume=83;,citation_journal_title=Theory and Decision;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Correlated equilibrium as an expression of bayesian rationality;,citation_author=Robert J. Aumann;,citation_publication_date=1987-01;,citation_cover_date=1987-01;,citation_year=1987;,citation_issue=1;,citation_doi=10.2307/1911154;,citation_volume=55;,citation_journal_title=Econometrica;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Subjectivity and correlation in randomized strategies;,citation_author=Robert J. Aumann;,citation_publication_date=1974-03;,citation_cover_date=1974-03;,citation_year=1974;,citation_issue=1;,citation_doi=10.1016/0304-4068(74)90037-8;,citation_volume=1;,citation_journal_title=Journal of Mathematical Economics;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Agreeing to disagree;,citation_author=Robert J. Aumann;,citation_publication_date=1976-11;,citation_cover_date=1976-11;,citation_year=1976;,citation_issue=6;,citation_doi=10.1214/aos/1176343654;,citation_volume=4;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Computing correlated equilibria in multi-player games;,citation_author=Christos H. Papadimitriou;,citation_author=Tim Roughgarden;,citation_publication_date=2008-07;,citation_cover_date=2008-07;,citation_year=2008;,citation_issue=3;,citation_doi=10.1145/1379759.1379762;,citation_volume=55;,citation_journal_title=Journal of the ACM;,citation_publisher=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players, iIII part i. The basic model;,citation_author=John C. Harsanyi;,citation_publication_date=1967-11;,citation_cover_date=1967-11;,citation_year=1967;,citation_issue=3;,citation_doi=10.1287/mnsc.14.3.159;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by &amp;amp;amp;quot;bayesian&amp;quot; players part II. Bayesian equilibrium points;,citation_author=John C. Harsanyi;,citation_publication_date=1968-01;,citation_cover_date=1968-01;,citation_year=1968;,citation_issue=5;,citation_doi=10.1287/mnsc.14.5.320;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Games with incomplete information played by “bayesian” players, part III. The basic probability distribution of the game;,citation_author=John C. Harsanyi;,citation_publication_date=1968-03;,citation_cover_date=1968-03;,citation_year=1968;,citation_issue=7;,citation_doi=10.1287/mnsc.14.7.486;,citation_volume=14;,citation_journal_title=Management Science;,citation_publisher=Institute for Operations Research; the Management Sciences (INFORMS);">
<meta name="citation_reference" content="citation_title=Game theory for applied economists;,citation_author=Robert Gibbons;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_isbn=0691043086;">
<meta name="citation_reference" content="citation_title=Computer science theory for the information age;,citation_author=John Hopcroft;,citation_author=Ravi Kannan;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_fulltext_html_url=https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/hopcroft-kannan-feb2012.pdf;">
<meta name="citation_reference" content="citation_title=Theory of self-adaptive control systems;,citation_author=H. Kwakernaak;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Information pattern for linear discrete-time models with stochastic coefficients;,citation_author=T. Bohlin;,citation_publication_date=1970-02;,citation_cover_date=1970-02;,citation_year=1970;,citation_issue=1;,citation_volume=15;,citation_journal_title=IEEE Transactions on Automatic Control (TAC);">
<meta name="citation_reference" content="citation_title=Information states for linear stochastic systems;,citation_author=M. H. A Davis;,citation_author=P. P Varaiya;,citation_publication_date=1972-02;,citation_cover_date=1972-02;,citation_year=1972;,citation_issue=2;,citation_volume=37;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Sufficient statistics in the optimal control of stochastic systems;,citation_author=Charlotte Striebel;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=12;,citation_journal_title=Journal of Mathematical Analysis and Applications;">
<meta name="citation_reference" content="citation_title=Some remarks on the concept of state;,citation_author=Hans S. Witsenhausen;,citation_editor=Y. C. Ho;,citation_editor=S. K. Mitter;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_inbook_title=Directions in large-scale systems;">
<meta name="citation_reference" content="citation_title=Linear automaton transformations;,citation_author=A. Nerode;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_volume=9;,citation_journal_title=Proceedings of American Mathematical Society;">
<meta name="citation_reference" content="citation_title=A convergence theorem for non-negative almost supermartingales and some applications;,citation_author=H. Robbins;,citation_author=D. Siegmund;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_doi=10.1016/b978-0-12-604550-5.50015-8;,citation_inbook_title=Optimizing methods in statistics;">
<meta name="citation_reference" content="citation_title=Discrete parameter martingales;,citation_author=J. Neveu;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;">
<meta name="citation_reference" content="citation_title=A user’s guide to measure theoretic probability;,citation_author=David Pollard;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Convergence of stochastic approximation via martingale and converse Lyapunov methods;,citation_author=M. Vidyasagar;,citation_publication_date=2023-01;,citation_cover_date=2023-01;,citation_year=2023;,citation_issue=2;,citation_doi=10.1007/s00498-023-00342-9;,citation_volume=35;,citation_journal_title=Mathematics of Control, Signals, and Systems;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=On stochastic approximation;,citation_author=E. G. Gladyshev;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=2;,citation_doi=10.1137/1110031;,citation_volume=10;,citation_journal_title=Theory of Probability and Its Applications;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Gradient convergence in gradient methods with errors;,citation_author=Dimitri P. Bertsekas;,citation_author=John N. Tsitsiklis;,citation_publication_date=2000-01;,citation_cover_date=2000-01;,citation_year=2000;,citation_issue=3;,citation_doi=10.1137/s1052623497331063;,citation_volume=10;,citation_journal_title=SIAM Journal on Optimization;,citation_publisher=Society for Industrial &amp;amp;amp; Applied Mathematics (SIAM);">
<meta name="citation_reference" content="citation_title=Stochastic processes;,citation_author=Joseph T. Chang;,citation_publication_date=2007-02;,citation_cover_date=2007-02;,citation_year=2007;,citation_fulltext_html_url=http://www.stat.yale.edu/~pollard/Courses/251.spring2013/Handouts/Chang-notes.pdf;">
<meta name="citation_reference" content="citation_title=Lyapunov criterion for stochastic systems and its applications in distributed computation;,citation_author=Yuzhen Qin;,citation_author=Ming Cao;,citation_author=Brian D. O. Anderson;,citation_publication_date=2020-02;,citation_cover_date=2020-02;,citation_year=2020;,citation_issue=2;,citation_doi=10.1109/tac.2019.2910948;,citation_volume=65;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=Institute of Electrical; Electronics Engineers (IEEE);">
<meta name="citation_reference" content="citation_title=An upper bound on the loss from approximate optimal-value functions;,citation_author=Satinder P. Singh;,citation_author=Richard C. Yee;,citation_publication_date=1994-09;,citation_cover_date=1994-09;,citation_year=1994;,citation_issue=3;,citation_doi=10.1007/bf00993308;,citation_volume=16;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Feature-based methods for large scale dynamic programming;,citation_author=John N. Tsitsiklis;,citation_author=Benjamin Roy;,citation_publication_date=1996-03;,citation_cover_date=1996-03;,citation_year=1996;,citation_issue=1-3;,citation_doi=10.1007/bf00114724;,citation_volume=22;,citation_journal_title=Machine Learning;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=A graphical derivation of the legendre transform;,citation_author=Sam Kennerly;,citation_publication_date=2011-04;,citation_cover_date=2011-04;,citation_year=2011;,citation_fulltext_html_url=http://einstein.drexel.edu/~skennerly/maths/Legendre.pdf;">
<meta name="citation_reference" content="citation_title=Variational analysis;,citation_author=R Tyrrell Rockafellar;,citation_author=Roger J-B Wets;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=317;">
<meta name="citation_reference" content="citation_title=Entropy, large deviations, and statistical mechanics;,citation_author=Richard S. Ellis;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_doi=10.1007/978-1-4613-8533-2;">
<meta name="citation_reference" content="citation_title=A theory of regularized Markov decision processes;,citation_abstract=Many recent successful (deep) reinforcement learning algorithms make use of regularization, generally based on entropy or Kullback-Leibler divergence. We propose a general theory of regularized Markov Decision Processes that generalizes these approaches in two directions: we consider a larger class of regularizers, and we consider the general modified policy iteration approach, encompassing both policy iteration and value iteration. The core building blocks of this theory are a notion of regularized Bellman operator and the Legendre-Fenchel transform, a classical tool of convex optimization. This approach allows for error propagation analyses of general algorithmic schemes of which (possibly variants of) classical algorithms such as Trust Region Policy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic Policy Programming are special cases. This also draws connections to proximal convex optimization, especially to Mirror Descent.;,citation_author=Matthieu Geist;,citation_author=Bruno Scherrer;,citation_author=Olivier Pietquin;,citation_editor=Kamalika Chaudhuri;,citation_editor=Ruslan Salakhutdinov;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://proceedings.mlr.press/v97/geist19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../stochastic-control/index.html" rel="" target="">
 <span class="menu-text">Stochastic Control</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../multi-agent-systems/index.html" rel="" target="">
 <span class="menu-text">Multi-Agent Systems</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/adityam/stochastic-control" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../pomdps/intro.html">POMDPs</a></li><li class="breadcrumb-item"><a href="../pomdps/intro.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the course</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Stochastic Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/newsvendor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The newsvendor problem</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/gambling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Optimal gambling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Inventory Management</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/monotone-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/power-delay-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/reward-shaping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reward Shaping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inf-horizon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mdp-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">MDP algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management-revisited.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Inventory management (revisted)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mobile-edge-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Service Migration in Mobile edge computing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/computational-complexity-vi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Computational complexity of value interation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/linear-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Linear programming formulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/lipschitz-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">POMDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/sequential-hypothesis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Approx DP</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/approx-DP.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Approximate dynamic programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/policy-loss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Upper bounds on policy loss</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/model-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Risk sensitive MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-utility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Risk Sensitive Utility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Risk Sensitive MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">LQ systems</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">RL</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rl/stochastic-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Stochastic approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Probability Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Convergence of random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/sub-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Sub-Gaussian random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/change-of-measure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Change of Measure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/martingales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Martingales</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/stochastic-stability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Stochastic stability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Linear Algebra Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/postive-definite-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Positive definite matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/svd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Singular value decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/rkhs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Reproducing Kernel Hilbert Space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Convexity Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/convexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Convex sets and convex functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/duality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Duality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 1</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#history-dependent-dynamic-program" id="toc-history-dependent-dynamic-program" class="nav-link active" data-scroll-target="#history-dependent-dynamic-program"><span class="header-section-number">16.1</span> History dependent dynamic program</a>
  <ul class="collapse">
  <li><a href="#performance-of-history-dependent-strategies" id="toc-performance-of-history-dependent-strategies" class="nav-link" data-scroll-target="#performance-of-history-dependent-strategies">Performance of history-dependent strategies</a></li>
  <li><a href="#history-dependent-dynamic-programming-decomposition" id="toc-history-dependent-dynamic-programming-decomposition" class="nav-link" data-scroll-target="#history-dependent-dynamic-programming-decomposition">History-dependent dynamic programming decomposition</a></li>
  </ul></li>
  <li><a href="#the-notion-of-an-information-state" id="toc-the-notion-of-an-information-state" class="nav-link" data-scroll-target="#the-notion-of-an-information-state"><span class="header-section-number">16.2</span> The notion of an information state</a></li>
  <li><a href="#examples-of-an-information-state" id="toc-examples-of-an-information-state" class="nav-link" data-scroll-target="#examples-of-an-information-state"><span class="header-section-number">16.3</span> Examples of an information state</a></li>
  <li><a href="#information-state-based-dynamic-program" id="toc-information-state-based-dynamic-program" class="nav-link" data-scroll-target="#information-state-based-dynamic-program"><span class="header-section-number">16.4</span> Information state based dynamic program</a></li>
  <li><a href="#belief-state-based-dynamic-program" id="toc-belief-state-based-dynamic-program" class="nav-link" data-scroll-target="#belief-state-based-dynamic-program"><span class="header-section-number">16.5</span> Belief state based dynamic program</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/adityam/stochastic-control/edit/quarto/pomdps/intro.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="http://www.cim.mcgill.ca/~adityam">Aditya Mahajan</a> </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="http://www.mcgill.ca/ece">
            McGill University
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 7, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>So far, we have considered a setup where the decision maker perfectly observes the state of the system. In many applications, the decision maker may not directly observe the state of the system but only observe a noisy version of it. Such systems are modeled as partially observable Markov decision processes (POMDPs). We will describe the simplest model of POMDPs, which builds upon the <a href="../mdps/intro.html">model of MDPs descibed earlier</a>.</p>
<p>We assume that the system has a state <span class="math inline">\(S_t \in \ALPHABET S\)</span>, control input <span class="math inline">\(A_t \in \ALPHABET A\)</span>, and process noise <span class="math inline">\(W_t \in \ALPHABET W\)</span>. The state evolves as <span class="math display">\[\begin{equation} \label{eq:state}
  S_{t+1} = f_t(S_t, A_t, W_t)
\end{equation}\]</span> However, unlike the MDP setup, the assumption is that the decision maker does not observe <span class="math inline">\(S_t\)</span>; rather, the observation of the decision maker at time&nbsp;<span class="math inline">\(t\)</span> is given by <span class="math display">\[\begin{equation} \label{eq:obs}
  Y_t = \ell_t(S_t, N_t)
\end{equation}\]</span> where <span class="math inline">\(Y_t \in \ALPHABET Y\)</span> is the observation and <span class="math inline">\(N_t \in \ALPHABET N\)</span> is called the observation noise. As in the case of MDPs, we assume that the <em>primitive random varaibles</em> <span class="math inline">\((S_1, W_1, \dots, W_T\)</span>, <span class="math inline">\(N_1, \dots, N_T)\)</span> are defined on a common probability space and are mutually independent. This assumption is critical for the results to go through.</p>
<p>As in the case of MDPs, we assume that the controller can be as sophisticated as we want. It can analyze the entire history of observations and control actions to choose the current control action. Thus, the control action can be written as <span class="math display">\[
  A_t = π_t(Y_{1:t}, A_{1:t-1}).
\]</span></p>
<p>At each time, the system incurs a cost <span class="math inline">\(c_t(S_t, A_t)\)</span> which depends on the current state and the current action. The system operates for a finite horizon <span class="math inline">\(T\)</span> and incurs a total cost <span class="math display">\[
  \sum_{t=1}^T c_t(S_t, A_t).
\]</span></p>
<p>Given the above system model, we want to choose a <em>control strategy</em> <span class="math inline">\(π = (π_1, \dots, π_T)\)</span> to minimize the expected total cost <span class="math display">\[
  J(π) := \EXP\Bigl[ \sum_{t=1}^T c_t(S_t, A_t) \Bigr].
\]</span> How should we proceed?</p>
<p>Note that the only difference from the MDP model is decision maker observes <span class="math inline">\(Y_t\)</span> instead of <span class="math inline">\(S_t\)</span>. Apart from this, the other modeling assumptions are the same. So, the conceptual difficulties of the model are the same as that of MDPs:</p>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<i class="bi bi-patch-question text-warning"></i> Key conceptual question
</div>
</div>
<div class="callout-body-container callout-body">
<p>The data <span class="math inline">\((Y_{1:t}, A_{1:t-1})\)</span> available at the controller is increasing with time. Therefore, the number of possible control laws at time <span class="math inline">\(t\)</span> are increasing exponentially with time. How can we search for efficiently search for optimal control strategies?</p>
</div>
</div>
<p>Recall that for MDPs, we first showed that there is no loss of optimality in restricting attention to Markov strategies. That structural result was instrumental in developing an efficient search algorithm (dynamic programming). So, what is the equivalent result for POMDPs?</p>
<section id="history-dependent-dynamic-program" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="history-dependent-dynamic-program"><span class="header-section-number">16.1</span> History dependent dynamic program</h2>
<p>Our first step to develop an efficient dynamic programming decomposition is to simply ignore efficiency and develop <em>a</em> dynamic programming decomposition. We start by deriving a recursive formula to compute the performance of a generic history dependent strategy <span class="math inline">\(π = (π_1, \dots, π_T)\)</span>.</p>
<section id="performance-of-history-dependent-strategies" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="performance-of-history-dependent-strategies">Performance of history-dependent strategies</h3>
<p>Let <span class="math inline">\(H_t = (Y_{1:t}, A_{1:t-1})\)</span> denote all the information available to the decision maker at time&nbsp;<span class="math inline">\(t\)</span>. Thus, given any history dependent strategy <span class="math inline">\(π\)</span>, we can write <span class="math inline">\(A_t = π_t(H_t)\)</span>. Define <em>the cost-to-go functions</em> as follows: <span class="math display">\[
  J_t(h_t; π) = \EXP^π\biggl[ \sum_{s=t}^T c_s(S_s, A_s) \biggm| H_t = h_t
  \biggr].
\]</span> Note that <span class="math inline">\(J_t(h_t; π)\)</span> only depends on the future strategy <span class="math inline">\((π_t, \dots, π_T)\)</span>. These functions can be computed recursively as follows: <span class="math display">\[\begin{align*}
  J_t(h_t; π) &amp;= \EXP^π\biggl[ \sum_{s=t}^T c_s(H_s, π_s(H_s)) \biggm|
    H_t = h_t \biggr] \\
    &amp;\stackrel{(a)}= \EXP^π \biggl[ c_t(h_t, π_t(h_t)) + \EXP^π\biggl[
    \sum_{s=t+1}^T c_s(S_s, π_s(S_s)) \biggm| H_{t+1} \biggr] \biggm|
    H_t = h_t \biggr]  \\
    &amp;= \EXP^π[ c_t(h_t, π_t(h_t)) + J_{t+1}(H_{t+1}; π) \mid H_t = h_t ],
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from the towering property of conditional expectation and the fact that <span class="math inline">\(H_t \subseteq H_{t+1}\)</span>.</p>
<p>Thus, we can use the following dynamic program to recursively compute the performance of a history-dependent strategy: <span class="math inline">\(J_{T+1}(h_{T+1}) = 0\)</span> and for <span class="math inline">\(t \in \{T, \dots, 1\}\)</span>, <span class="math display">\[
J_t(h_t; π) = \EXP^π [ c_t(h_t, π_t(h_t)) + J_{t+1}(H_{t+1}; π) \mid
  H_t = h_t ].
\]</span></p>
</section>
<section id="history-dependent-dynamic-programming-decomposition" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="history-dependent-dynamic-programming-decomposition">History-dependent dynamic programming decomposition</h3>
<p>We can use the above recursive formulation for performance evaluation to derive a history-dependent dynamic program.</p>
<div id="thm-pomdp-history-dp" class="theorem">
<p><span class="theorem-title"><strong>Theorem 16.1 </strong></span>Recursively define _value functions <span class="math inline">\(\{V_t\}_{t = 1}^{T+1}\)</span>, where <span class="math inline">\(V_t \colon \ALPHABET H_t \to \reals\)</span> as follows: <span class="math display">\[\begin{equation}
  V_{T+1}(h_{T+1}) = 0
\end{equation}\]</span> and for <span class="math inline">\(t \in \{T, \dots, 1\}\)</span>: <span class="math display">\[\begin{align}
  Q_t(h_t, a_t) &amp;= \EXP[ c_t(S_t, a_t) + V_{t+1}(H_{t+1}) \mid
  H_t = h_t, A_t = a_t ] \\
  V_t(h_t) &amp;= \min_{a_t \in \ALPHABET A} Q_t(h_t, a_t)
\end{align}\]</span> Then, a history-dependent policy <span class="math inline">\(π\)</span> is optimal if and only if it satisfies <span class="math display">\[\begin{equation} \label{eq:history-verification}
  π_t(h_t) \in \arg \min_{a_t \in \ALPHABET A} Q_t(h_t, a_t).
\end{equation}\]</span></p>
</div>
<p>The proof idea is similar to the proof for MDPs. Instead of proving the above result, we prove a related result.</p>
<div id="thm-pomdp-history-comparison" class="theorem">
<p><span class="theorem-title"><strong>Theorem 16.2 (The comparison principle) </strong></span>For any history-dependent strategy <span class="math inline">\(π\)</span> <span class="math display">\[ J_t(h_t; π) \ge V_t(h_t) \]</span> with equality at <span class="math inline">\(t\)</span> if and only if the <em>future</em> straegy <span class="math inline">\(π_{t:T}\)</span> satisfies the verification step&nbsp;\eqref{eq:history-verification}.</p>
</div>
<p>Note that the comparison principle immediately implies that the strategy obtained using dynamic program of <a href="#thm-pomdp-history-dp">Theorem&nbsp;<span>16.1</span></a> is optimal. The proof of the comparison principle is almost identical to the proof for MDPs.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof of the comparison principle
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof proceeds by backward induction. Consider any history dependent policy <span class="math inline">\(π = (π_1, \dots, π_T)\)</span>. For <span class="math inline">\(t = T+1\)</span>, the comparison principle is satisfied by definition and this forms the basis of induction. We assume that the result holds for time&nbsp;<span class="math inline">\(t+1\)</span>, which is the induction hypothesis. Then for time&nbsp;<span class="math inline">\(t\)</span>, we have <span class="math display">\[\begin{align*}
  V_t(h_t) &amp;= \min_{a_t \in \ALPHABET A} Q_t(h_t, a_t) \\
  &amp;\stackrel{(a)}= \min_{a_t \in \ALPHABET A}
   \EXP^π[ c_t(S_t, π_t(h_t)) + V_{t+1}(H_{t+1}) \mid
  H_t = h_t, A_t = π_t(h_t) ]
  \\
  &amp;\stackrel{(b)}\le
   \EXP^π[ c_t(S_t, π_t(h_t)) + V_{t+1}(H_{t+1}) \mid
  H_t = h_t, A_t = π_t(h_t)]
  \\
  &amp;\stackrel{(c)}\le
   \EXP^π[ c_t(S_t, π_t(h_t)) + J_{t+1}(H_{t+1}; π) \mid
  H_t = h_t, A_t = π_t(h_t)]
  \\
  &amp;= J_t(h_t, π).
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from the definition of the <span class="math inline">\(Q\)</span>-function; <span class="math inline">\((b)\)</span> follows from the definition of minimization; and <span class="math inline">\((c)\)</span> follows from the induction hyothesis. We have the equality at step <span class="math inline">\((b)\)</span> iff <span class="math inline">\(π_t\)</span> satisfies the verification step&nbsp;\eqref{eq:history-verification} and have the equality in step <span class="math inline">\((c)\)</span> iff <span class="math inline">\(π_{t+1:T}\)</span> is optimal (this is part of the induction hypothesis). Thus, the result is true for time&nbsp;<span class="math inline">\(t\)</span> and, by the principle of induction, is true for all time.</p>
</div>
</div>
</div>
</section>
</section>
<section id="the-notion-of-an-information-state" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="the-notion-of-an-information-state"><span class="header-section-number">16.2</span> The notion of an information state</h2>
<p>Now that we have obtained a dynamic programming decomposition, let’s try to simplify it. To do so, we define the notion of an <em>information state</em>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Information state
</div>
</div>
<div class="callout-body-container callout-body">
<p>A stochastic process <span class="math inline">\(\{Z_t\}_{t = 1}^T\)</span>, <span class="math inline">\(Z_t \in \ALPHABET Z\)</span>, is called an <em>information state</em> if <span class="math inline">\(Z_t\)</span> be a function of <span class="math inline">\(H_t\)</span> (which we denote by <span class="math inline">\(Z_t = φ_t(H_t)\)</span>) and satisfies the following two properties:</p>
<p><strong>P1. Sufficient for performance evaluation</strong>, i.e., <span class="math display">\[ \EXP^π[ c_t(S_t, A_t) \mid H_t = h_t, A_t = a_t]
    =  \EXP[ c_t(S_t, A_t) \mid Z_t = φ_t(h_t), A_t = a_t ] \]</span></p>
<p><strong>P2. Sufficient to predict itself</strong>, i.e., for any Borel measurable subset <span class="math inline">\(B\)</span> of <span class="math inline">\(\ALPHABET Z\)</span>, we have <span class="math display">\[ \PR^π(Z_{t+1} \in B \mid H_t = h_t, A_t = a_t) =
       \PR(Z_{t+1} \in B \mid Z_t = φ_t(h_t), A_t = a_t).
    \]</span></p>
</div>
</div>
<p>Instead of (P2), the following sufficient conditions are easier to verify in some models:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
An equivalent characterization
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>P2a. Evolves in a state-like manner</strong>, i.e., there exist measurable functions <span class="math inline">\(\{ψ_t\}_{t=1}^T\)</span> such that <span class="math display">\[ Z_{t+1} = ψ_t(Z_t, Y_{t+1}, A_t). \]</span></p>
<p><strong>P2b. Is sufficient for predicting future observations</strong>, i.e., for any Borel subset <span class="math inline">\(B\)</span> of <span class="math inline">\(\ALPHABET Y\)</span>, <span class="math display">\[ \PR^π(Y_{t+1} \in B | H_t = h_t, A_t = a_t) =
        \PR(Y_{t+1} \in B | Z_t = φ_t(h_t), A_t = a_t).
     \]</span></p>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remark
</div>
</div>
<div class="callout-body-container callout-body">
<p>The right hand sides of (P1) and (P2) as well as (P2a) and (P2b) do not depend on the choice of the policy <span class="math inline">\(π\)</span>.</p>
</div>
</div>
<div id="prp-info-state" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 16.1 </strong></span>: (P2a) and (P2b) imply (P2).</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For any Borel measurable subset <span class="math inline">\(B\)</span> of <span class="math inline">\(\ALPHABET Z\)</span>, we have <span class="math display">\[\begin{align*}
  \hskip 1em &amp; \hskip -1em
  \PR(Z_{t+1} \in B \mid H_t = h_t, A_t = a_t)  
  \stackrel{(a)}= \sum_{y_{t+1} \in \ALPHABET Y} \PR(Y_{t+1} = y_{t+1}, Z_{t+1} \in B
  \mid H_t = h_t, A_t = a_t ]
  \\
  &amp;\stackrel{(b)}= \sum_{y_{t+1} \in \ALPHABET Y} \IND\{ ψ_t(φ_t(h_t), y_{t+1}, a_t) \}
  \PR(Y_{t+1} = y_{t+1} \mid H_t = h_t, A_t = a_t)
  \\
  &amp;\stackrel{(c)}= \sum_{y_{t+1} \in \ALPHABET Y} \IND\{ ψ_t(φ_t(h_t), y_{t+1}, a_t) \}
  \PR(Y_{t+1} = y_{t+1} \mid Z_t = φ_t(h_t), A_t = a_t)
  \\
  &amp;\stackrel{(d)}=
  \PR(Z_{t+1} \in B \mid Z_t = φ_t(h_t), A_t = a_t)  
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from the law of total probability, <span class="math inline">\((b)\)</span> follows from (P2a), <span class="math inline">\((c)\)</span> follows from (P2b), and <span class="math inline">\((d)\)</span> from the law of total probability.</p>
</div>
</div>
</div>
</section>
<section id="examples-of-an-information-state" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="examples-of-an-information-state"><span class="header-section-number">16.3</span> Examples of an information state</h2>
<p>We start by define the <em>belief state</em> <span class="math inline">\(b_t \in Δ(\ALPHABET S)\)</span> as follows: for any <span class="math inline">\(s \in \ALPHABET S\)</span> <span class="math display">\[ b_t(s) = \PR^π(S_t = s \mid H_t = h_t). \]</span> The belief state is a function of the history <span class="math inline">\(h_t\)</span>. When we want to explicitly show the dependence of <span class="math inline">\(b_t\)</span> on <span class="math inline">\(h_t\)</span>, we write it as <span class="math inline">\(b_t[h_t]\)</span>.</p>
<div id="lem-pomdp-belief-independence" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 16.1 </strong></span>The belief state <span class="math inline">\(b_t\)</span> does not depend on the policy <span class="math inline">\(π\)</span>.</p>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is an extremely important result which has wide-ranging implications in stochastic control. For a general discussion of this point, see <span class="citation" data-cites="Witsenhausen1975">Witsenhausen (<a href="../references.html#ref-Witsenhausen1975" role="doc-biblioref">1975</a>)</span>.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>From the law of total probability and Bayes rule, we have <span class="math display">\[\begin{equation} \label{eq:belief}
  \PR(s_t | y_{1:t}, a_{1:t-1})
  = \sum_{s_{1:t-1}} \PR(s_{1:t} | y_{1:t}, a_{1:t-1})
  = \sum_{s_{1:t-1}}
   \frac{\PR(s_{1:t}, y_{1:t}, a_{1:t-1})}
   {\sum_{s'_{1:t}} \PR(s'_{1:t}, y_{1:t}, a_{1:t-1})}
\end{equation}\]</span></p>
<p>Now consider <span class="math display">\[\begin{align*}
  \PR(s_{1:t}, y_{1:t}, a_{1:t-1}) &amp;=
  \PR(s_1) \PR(y_1 | s_1) \IND\{ a_1 = π_1(y_1) \} \\
  &amp; \times
  \PR(s_2 | s_1, a_1) \PR(y_2 | s_2) \IND \{ a_2 = π_2(y_{1:2}, a_1)\} \\
  &amp; \times \cdots \\
  &amp; \times
  \PR(s_{t-1} | s_{t-2}, a_{t-2}) \PR(y_{t-1} | s_{t-1}) \IND \{ a_{t-1} =
  π_{t-1}(y_{1:t-1}, a_{1:t-2}) \} \\
  &amp; \times
  \PR(s_{t} | s_{t-1}, a_{t-1}) \PR(y_{t} | s_{t}).
\end{align*}\]</span> Substitute the above expression in both the numerator and the denominator of \eqref{eq:belief}. Observe that the terms of the form <span class="math inline">\(\IND\{ a_s = π_s(y_{1:s}, a_{1:s-1})\)</span> are common to both the numerator and the denominator and cancel each other. Thus, <span class="math display">\[\begin{equation} \label{eq:belief-fn}
  \PR(s_t | y_{1:t}, a_{1:t-1}) = \sum_{s_{1:t-1}}
  \frac{ \prod_{s=1}^t \PR(s_s \mid s_{s-1}, a_{s-1}) \PR(y_s \mid s_s) }
  { \sum_{s'_{1:t}} \prod_{s=1}^t \PR(s'_s \mid s'_{s-1}, a_{s-1}) \PR(y_s \mid s'_s) }.
\end{equation}\]</span> None of the terms here depend on the policy <span class="math inline">\(π\)</span>. Hence, the belief state does not depend on the policy <span class="math inline">\(π\)</span>.</p>
</div>
</div>
</div>
<div id="lem-pomdp-belief-update" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 16.2 </strong></span>The belief state <span class="math inline">\(b_t\)</span> updates in a state like manner. In particular, for any <span class="math inline">\(s_{t+1} \in \ALPHABET S\)</span>, we have <span class="math display">\[
  b_{t+1}(s_{t+1}) = \sum_{s_t \in \ALPHABET S}
  \frac{ \PR(y_{t+1} | s_{t+1}) \PR(s_{t+1} | s_t, a_t) b_t(s_t) }
   { \sum_{s'_{t:t+1}} \PR(y_{t+1} | s'_{t+1}) \PR(s'_{t+1} | s'_t, a_t) b_t(s'_t) }.
\]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For any <span class="math inline">\(s_{t+1} \in \ALPHABET S\)</span>, consider</p>
<p><span class="math display">\[\begin{align}
b_{t+1}(s_{t+1}) &amp;= \PR(s_{t+1} | y_{1:t+1}, a_{1:t}) \notag \\
&amp;= \sum_{s_t} \PR(s_{t:t+1} | y_{1:t+1}, a_{1:t}) \notag \\
&amp;= \sum_{s_t} \frac{ \PR(s_{t:t+1}, y_{t+1}, a_t | y_{1:t}, a_{1:t-1}) }
  {\sum_{s'_{t:t+1}}\PR(s'_{t:t+1}, y_{t+1}, a_t | y_{1:t}, a_{1:t-1}) }.
\label{eq:update-1}
\end{align}\]</span></p>
<p>Now consider <span class="math display">\[\begin{align}
\hskip 1em &amp; \hskip -1em
\PR(s_{t:t+1}, y_{t+1}, a_t | y_{1:t}, a_{1:t-1}) \notag \\
&amp;= \PR(y_{t+1} | s_{t+1}) \PR(s_{t+1} | s_t, a_t)
   \IND\{ a_t = π_t(y_{1:t}, a_{1:t-1}) \}
   \PR(s_t | y_{1:t}, a_{1_t-1}) \notag \\
&amp;= \PR(y_{t+1} | s_{t+1}) \PR(s_{t+1} | s_t, a_t)
   \IND\{ a_t = π_t(y_{1:t}, a_{1:t-1}) \}
   b_t(s_t). \label{eq:belief-2}
\end{align}\]</span> Substitute the above expression in both the numerator and the denominator of \eqref{eq:update-1}. Observe that <span class="math inline">\(\IND\{ a_t = π_t(y_{1:t}, a_{1:t-1}) \}\)</span> is common to both the numerator and the denominator and cancels out. Thus, we get the result of the lemma.</p>
</div>
</div>
</div>
<p>Now, we present three examples of information state here. See the <a href="#exercises">Exercises</a> for more examples.</p>
<div id="exm-pomdp-history" class="theorem example">
<p><span class="theorem-title"><strong>Example 16.1 </strong></span>The complete history <span class="math inline">\(H_t\)</span> is an information state.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We will prove that <span class="math inline">\(Z_t = H_t\)</span> satisfies properties (P1), (P2a), and (P2b).</p>
<p>P1. <span class="math inline">\(\displaystyle \EXP^π[ c_t(S_t, A_t) | H_t = h_t, A_t = a_t ] = \sum_{s_t \in \ALPHABET S} c_t(s_t, a_t) b_t[h_t](s_t)\)</span>.</p>
<p>P2a. <span class="math inline">\(H_{t+1} = (H_t, Y_{t+1}, A_t)\)</span></p>
<p>P2b. <span class="math inline">\(\displaystyle \PR^π(y_{t+1} | y_{1:t}, a_{1:t}) = \sum_{s_{t:t+1}} \PR(y_{t+1} | s_{t+1}) \PR( s_{t+1} | s_t, a_t) \PR(s_t | y_{1:t}, a_{1:t})\)</span>. Note that in the last term <span class="math inline">\(\PR^π(s_t | y_{1:t}, a_{1:t})\)</span> we can drop <span class="math inline">\(a_t\)</span> from the conditioning because it is a function of <span class="math inline">\((y_{1:t}, a_{1:t-1})\)</span>. Thus, <span class="math display">\[ \PR^π(s_t | y_{1:t}, a_{1:t}) = \PR^π(s_t | y_{1:t}, a_{1:t-1}) =
b_t[h_t](s_t).\]</span> Note that in the last step, we have used <a href="#lem-pomdp-belief-independence">Lemma&nbsp;<span>16.1</span></a>. Thus, <span class="math inline">\(\displaystyle \PR^π(y_{t+1} | y_{1:t}, a_{1:t}) = \sum_{s_{t:t+1}} \PR(y_{t+1} | s_{t+1}) \PR( s_{t+1} | s_t, a_t) b_t[h_t](s_t)\)</span>.</p>
</div>
</div>
</div>
<div id="exm-pomdp-belief" class="theorem example">
<p><span class="theorem-title"><strong>Example 16.2 </strong></span>The belief state <span class="math inline">\(b_t\)</span> is an information state.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The belief state <span class="math inline">\(b_t\)</span> is a function of the history <span class="math inline">\(h_t\)</span>. (The exact form of this function is given by \eqref{eq:belief-fn}). In the proof of <a href="#exm-pomdp-history">Example&nbsp;<span>16.1</span></a>, we have already shown that <span class="math inline">\(b_t\)</span> satisfies (P1) and (P2b). Moreover <a href="#lem-pomdp-belief-update">Lemma&nbsp;<span>16.2</span></a> implies that the belief update satisfies (P2a).</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remark
</div>
</div>
<div class="callout-body-container callout-body">
<p>Both the above information states are generic information states which work for all models. For specific models, it is possible to identify other information states as well. We present some examples of such an information state below.</p>
</div>
</div>
<div id="exm-pomdp-mdp" class="theorem example">
<p><span class="theorem-title"><strong>Example 16.3 </strong></span>An MDP is a special case of a POMDP where <span class="math inline">\(Y_t = S_t\)</span>. For an MDP <span class="math inline">\(Z_t = S_t\)</span> is an information state.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We will show that <span class="math inline">\(Z_t = S_t\)</span> satisfies (P1) and (P2).</p>
<p>(P1) is satisfied because the per-step cost is a function of the <span class="math inline">\((S_t, A_t)\)</span>. (P2) is equivalent to the control Markov property.</p>
</div>
</div>
</div>
</section>
<section id="information-state-based-dynamic-program" class="level2" data-number="16.4">
<h2 data-number="16.4" class="anchored" data-anchor-id="information-state-based-dynamic-program"><span class="header-section-number">16.4</span> Information state based dynamic program</h2>
<p>The main feature of an information state is that one can always write a dynamic program based on an information state.</p>
<div id="thm-info-state" class="theorem">
<p><span class="theorem-title"><strong>Theorem 16.3 </strong></span>Let <span class="math inline">\(\{Z_t\}_{t=1}^T\)</span> be any information state, where <span class="math inline">\(Z_t = φ_t(H_t)\)</span>. Recursively define value functions <span class="math inline">\(\{ \hat V_t \}_{t=1}^T\)</span>, where <span class="math inline">\(\hat V_t \colon \ALPHABET Z \to \reals\)</span>, as follows: <span class="math display">\[ \hat V_{T+1}(z_{T+1}) = 0 \]</span> and for <span class="math inline">\(t \in \{T, \dots, 1\}\)</span>: <span class="math display">\[\begin{align}
  \hat Q_t(z_t, a_t) &amp;= \EXP[ c_t(S_t, A_t) + \hat V_{t+1}(Z_{t+1}) \mid
  Z_t = z_t, A_t = a_t] \\
  \hat V_t(z_t) &amp;= \min_{a_t \in \ALPHABET A} \hat Q_t(z_t, a_t).
\end{align}\]</span> Then, we have the following: for any <span class="math inline">\(h_t\)</span> and <span class="math inline">\(a_t\)</span>, <span class="math display">\[\begin{equation} \label{eq:history-info}
  Q_t(h_t, a_t) = \hat Q_t(φ_t(h_t), a_t)
  \quad\text{and}\quad
  V_t(h_t) = \hat V_t(φ_t(h_t)).
\end{equation}\]</span> Any strategy <span class="math inline">\(\hat π = (\hat π_1, \dots, \hat π_T)\)</span>, where <span class="math inline">\(\hat π_t \colon \ALPHABET Z \to \ALPHABET A\)</span>, is optimal if and only if <span class="math display">\[\begin{equation}\label{eq:info-verification}
    \hat π_t(z_t) \in \arg\min_{a_t \in \ALPHABET A} \hat Q_t(z_t, a_t).
\end{equation}\]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>As usual, we prove the result by backward induction. By construction, Eq.&nbsp;\eqref{eq:history-info} is true at time <span class="math inline">\(T+1\)</span>. This forms the basis of induction. Now assume that&nbsp;\eqref{eq:history-info} is true at time <span class="math inline">\(t+1\)</span> and consider the system at time <span class="math inline">\(t\)</span>. Then, <span class="math display">\[\begin{align*}
Q_t(h_t, a_t) &amp;= \EXP[ c_t(S_t, A_t) + V_{t+1}(H_{t+1}) | H_t = h_t, A_t = a_t
] \\
&amp;\stackrel{(a)}= \EXP[ c_t(S_t, A_t) + \hat V_{t+1}( φ_t(H_{t+1}) ) | H_t =
h_t, A_t = a_t ]  \\
&amp;\stackrel{(b)}= \EXP[ c_t(S_t, A_t) + \hat V_{t+1}( φ_t(H_{t+1}) ) | Z_t =
φ_t(h_t), A_t = a_t ]  \\
&amp;\stackrel{(c)}= \hat Q_t(φ_t(h_t), a_t),
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from the induction hypothesis, <span class="math inline">\((b)\)</span> follows from the properties (P1) and (P2) of the information state, and <span class="math inline">\((c)\)</span> follows from the definition of <span class="math inline">\(\hat Q_t\)</span>. This shows that the action value functions are equal. By minimizing over the actions, we get that the value functions are also equal.</p>
</div>
</div>
</div>
</section>
<section id="belief-state-based-dynamic-program" class="level2" data-number="16.5">
<h2 data-number="16.5" class="anchored" data-anchor-id="belief-state-based-dynamic-program"><span class="header-section-number">16.5</span> Belief state based dynamic program</h2>
<p>As shown in <a href="#exm-pomdp-belief">Example&nbsp;<span>16.2</span></a>, the belief state <span class="math inline">\(b_t\)</span> is an information state. Therefore, <a href="#thm-info-state">Theorem&nbsp;<span>16.3</span></a> implies that we can write a dynamic program based on <span class="math inline">\(b_t\)</span>. This is an important and commonly used formulation, so we study it separately and present some properties of the value functions. The belief state based dynamic program is given by: <span class="math inline">\(V_{T+1}(b_{T+1}) = 0\)</span> and for <span class="math inline">\(t \in \{T, \dots, 1\}\)</span>, <span class="math display">\[
  Q_t(b_t, a_t) =
  \EXP [ c_t(S_t, A_t) + V_{t+1}(B_{t+1}) \mid B_t = b_t, A_t = a_t ].
\]</span> and <span class="math display">\[ V_t(b_t) = \min_{a_t \in \ALPHABET A} Q_t(b_t, a_t). \]</span></p>
<p>Define <span class="math display">\[ \PR(y_{t+1} | b_t, a_t) =
   \sum_{s_{t:t+1}} \PR(y_{t+1} | s_{t+1}) \PR(s_{t+1} | s_t, a_t) b_t(s_t).
\]</span> Then, the belief update expression in <a href="#lem-pomdp-belief-update">Lemma&nbsp;<span>16.2</span></a> can be written as: <span class="math display">\[
  b_{t+1}(s_{t+1}) =
  \frac{ \PR(y_{t+1} | s_{t+1}) \sum_{s_t} \PR(s_{t+1} | s_t, a_t) b_t(s_t) }
  { \PR(y_{t+1} | b_t, a_t) }.
\]</span> For the ease of notation, we write this expression as <span class="math inline">\(b_{t+1} = ψ(b_t, y_{t+1}, a_t)\)</span>.<br>
<span class="math display">\[\begin{align*}
  Q_t(b_t, a_t) &amp;= \sum_{s_t \in \ALPHABET S} c_t(s_t, a_t) b_t(s_t) \\
  &amp; \quad +  \sum_{y_{t+1} \in \ALPHABET Y} \PR(y_{t+1} | b_t, a_t)
  V_{t+1}( φ(b_t, y_{t+1}, a_t) ).
\end{align*}\]</span></p>
<p>A key property of the belief-state based value functions is the following.</p>
<div id="thm-belief-PWLC" class="theorem">
<p><span class="theorem-title"><strong>Theorem 16.4 </strong></span>The belief-state based value functions are piecewise linear and concave.</p>
</div>
<figure class="figure">
<div id="applet_container" style="width:800px;height:600px;display:block">

</div>
<figcaption class="figure-caption">
An illustration of a piecewise linear and concave function. Move the points around to see how the shape of the function changes.
</figcaption>
</figure>
<script type="text/javascript">
      var params = {
        filename: "../www/geogebra/pomdp-pwlc.ggb",
        enableShiftDragZoom: false,
        width: 800,
        height: 600,
      }

      var applet = new GGBApplet(params, true);

      window.onload = function() {
          applet.inject('applet_container');
      }
  </script>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>As usual, we prove the result using backward induction. For any <span class="math inline">\(a_T\)</span>, <span class="math display">\[ Q_T(b_T, a_T) = \sum_{s_T \in \ALPHABET S} c_T(s_T, a_T) b_T(s_T) \]</span> is linear in <span class="math inline">\(b_T\)</span>. Therefore, <span class="math display">\[ V_T(b_T) = \min_{a_T \in \ALPHABET A} Q_T(b_T, a_T) \]</span> is the minimum of a finite number of linear functions. Hence <span class="math inline">\(V_T(b_T)\)</span> is piecewise linear and concave.</p>
<p>Now assume that <span class="math inline">\(V_{t+1}(b_{t+1})\)</span> is piecewise linear and concave (PWLC). Any PWLC function can be represented as a minimum of a finite number of hyperplanes. Therefore, we can find a finite set of vectors <span class="math inline">\(\{ A_i \}_{i \in I}\)</span> indexed by finite set <span class="math inline">\(I\)</span> such that <span class="math display">\[
  V_{t+1}(b) = \min_{i \in I} \langle A_i, b \rangle.
\]</span></p>
<p>We need to show that <span class="math inline">\(V_t(b_t)\)</span> is piecewise linear and concave (PWLC). We first show that <span class="math inline">\(Q_t(b_t, a_t)\)</span> is PWLC. For any fixed <span class="math inline">\(a_t\)</span>, the first term <span class="math inline">\(\sum_{s_t} c_t(s_t, a_t) b_t(s_t)\)</span> is linear in <span class="math inline">\(b_t\)</span>. Now consider the second term: <span class="math display">\[\begin{align*}
  \hskip 1em &amp; \hskip -1em
  \sum_{y_{t+1} \in \ALPHABET Y} \PR(y_{t+1} | b_t, a_t)
  V_{t+1}( φ(b_t, y_{t+1}, a_t) ) \\
  &amp;=
  \sum_{y_{t+1} \in \ALPHABET Y} \PR(y_{t+1} | b_t, a_t)
  \min_{i \in I}
  \left\langle A_i,
  \frac{ \PR(y_{t+1} | s_{t+1}) \sum_{s_t} \PR(s_{t+1} | s_t, a_t) b_t(s_t) }
  { \PR(y_{t+1} | b_t, a_t) } \right\rangle \\
  &amp;=
  \sum_{y_{t+1} \in \ALPHABET Y}
  \min_{i \in I}
  \Big\langle A_i,
   \PR(y_{t+1} | s_{t+1}) \sum_{s_t} \PR(s_{t+1} | s_t, a_t) b_t(s_t)
   \Big\rangle
\end{align*}\]</span> which is the sum of PWLC functions of <span class="math inline">\(b_t\)</span> and therefore PWLC in <span class="math inline">\(b_t\)</span>.</p>
<p>Thus, <span class="math inline">\(Q_t(b_t, a_t)\)</span> is PWLC. Hence, <span class="math inline">\(V_t(b_t)\)</span> which is the pointwise minimum of PWLC functions is PWLC. Hence, the result holds due to principle of induction.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remark
</div>
</div>
<div class="callout-body-container callout-body">
<p>Since the value function is PWLC, we can identify a finite index set <span class="math inline">\(I_t\)</span>, and a set of vectors <span class="math inline">\(\{ A^i_t \}_{i \in I_t}\)</span> such that <span class="math display">\[
    V_t(b) = \min_{i \in I_t} \langle A^i_t, b \rangle.
\]</span> <span class="citation" data-cites="Smallwood1973">Smallwood and Sondik (<a href="../references.html#ref-Smallwood1973" role="doc-biblioref">1973</a>)</span> presented a “one-pass” algorithm to recursively compute <span class="math inline">\(I_t\)</span> and <span class="math inline">\(\{ A^i_t \}_{i \in I_t}\)</span> which allows us to exactly compute the value function. Various efficient refinements of these algorithms have been presented in the literature, e.π., the linear-support algorithm <span class="citation" data-cites="Cheng1988">(<a href="../references.html#ref-Cheng1988" role="doc-biblioref">Cheng 1988</a>)</span>, the witness algorithm <span class="citation" data-cites="Cassandra1994">(<a href="../references.html#ref-Cassandra1994" role="doc-biblioref">Cassandra et al. 1994</a>)</span>, incremental pruning <span class="citation" data-cites="Zhang1996 Cassandra1997">(<a href="../references.html#ref-Zhang1996" role="doc-biblioref">Zhang and Liu 1996</a>; <a href="../references.html#ref-Cassandra1997" role="doc-biblioref">Cassandra et al. 1997</a>)</span>, duality based approach <span class="citation" data-cites="Zhang2009">(<a href="../references.html#ref-Zhang2009" role="doc-biblioref">Zhang 2009</a>)</span>, and others. See <a href="http://pomdp.org">https://pomdp.org/</a> for an accessible introduction to these algorithms.</p>
</div>
</div>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div id="exr-info-state-folding" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 16.1 </strong></span>Consider an MDP where the state space <span class="math inline">\(\ALPHABET S\)</span> is a symmetric subset of integers of the form <span class="math inline">\(\{-L, -L + 1, \dots, L -1 , L\}\)</span> and the action space <span class="math inline">\(\ALPHABET A\)</span> is discrete. Suppose the transition matrix <span class="math inline">\(P(a)\)</span> and the cost function <span class="math inline">\(c_t(s,a)\)</span> satisfy properties (A1) and (A2) of <a href="../mdps/monotone-mdps.html#exr-folded-monotonicity">Exercise&nbsp;<span>6.6</span></a>. Show that <span class="math inline">\(Z_t = |S_t|\)</span> is an information state.</p>
</div>
<div id="exr-info-state-lqg" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 16.2 </strong></span>Consider a linear system with state <span class="math inline">\(x_t \in \reals^n\)</span>, observations <span class="math inline">\(y_t \in \reals^p\)</span>, and action <span class="math inline">\(u_t \in \reals^m\)</span>. Note that we will follow the standard notation of linear systems and denote the system variables by lower case letters <span class="math inline">\((x,u)\)</span> rather than upper case letter <span class="math inline">\((S,A)\)</span>. The dynamics of the system are given by <span class="math display">\[\begin{align*}
  x_{t+1} &amp;= A x_t + B u_t + w_t  \\
  y_t &amp;= C x_t + n_t
\end{align*}\]</span> where <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> are matrices of appropriate dimensions. The per-step cost is given by <span class="math display">\[
  c(x_t, u_t) = x_t^\TRANS Q x_t + u_t^\TRANS R u_t,
\]</span> where <span class="math inline">\(Q\)</span> is a positive semi-definite matrix and <span class="math inline">\(R\)</span> is a positive definite matrix. We make the standard assumption that the primitive random variables <span class="math inline">\(\{s_1, w_1, \dots, w_T, n_1, \dots, n_T \}\)</span> are independent.</p>
<p>Show that if the primitive variables are Guassian, then the conditional estimate of the state <span class="math display">\[
  \hat x_t = \EXP[ x_t | y_{1:t}, u_{1:t-1} ]
\]</span> is an information state.</p>
</div>
<div id="exr-machine-repair" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 16.3 </strong></span>Consider a machine which can be in one of <span class="math inline">\(n\)</span> ordered state where the first state is the best and the last state is the worst. The production cost increases with the state of the machine. The state evolves in a Markovian manner. At each time, an agent has the option to either run the machine or stop and inspect it for a cost. After inspection, the agent may either repair the machine (at a cost that depends on the state) or replace it (at a fixed cost). The objective is to identify a maintenance policy to minimize the cost of production, inspection, repair, and replacement.</p>
<p>Let <span class="math inline">\(τ\)</span> denote the time of last inspection and <span class="math inline">\(S_τ\)</span> denote the state of the machine after inspection, repair, or replacement. Show that <span class="math inline">\((S_τ, t-τ)\)</span> is an information state.</p>
</div>
</section>
<section id="notes" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="notes">Notes</h2>
<p>The discussion in this section is taken from <span class="citation" data-cites="Subramanian2022">Subramanian et al. (<a href="../references.html#ref-Subramanian2022" role="doc-biblioref">2022</a>)</span>. Information state may be viewed as a generalization of the traditional notion of state <span class="citation" data-cites="Nerode1958">Nerode (<a href="../references.html#ref-Nerode1958" role="doc-biblioref">1958</a>)</span>, which is defined as a statistic (i.e., a function of the observations) sufficient for input-output mapping. In contrast, we define an information state as a statistic sufficient for performance evaluation (and, therefore, for dynamic programming). Such a definition is hinted in <span class="citation" data-cites="Witsenhausen1976">Witsenhausen (<a href="../references.html#ref-Witsenhausen1976" role="doc-biblioref">1976</a>)</span>. The notion of information state is also related to sufficient statistics for optimal control defined in <span class="citation" data-cites="Striebel1965">Striebel (<a href="../references.html#ref-Striebel1965" role="doc-biblioref">1965</a>)</span> for systems with state space models.</p>
<p>As far as we are aware, the informal definition of information state was first proposed by <span class="citation" data-cites="Kwakernaak1965">Kwakernaak (<a href="../references.html#ref-Kwakernaak1965" role="doc-biblioref">1965</a>)</span> for adaptive control systems. Formal definitions for linear control systems were given by <span class="citation" data-cites="Bohlin1970">Bohlin (<a href="../references.html#ref-Bohlin1970" role="doc-biblioref">1970</a>)</span> for discrete time systems and by <span class="citation" data-cites="DavisVaraiya1972">Davis and Varaiya (<a href="../references.html#ref-DavisVaraiya1972" role="doc-biblioref">1972</a>)</span> for continuous time systems. <span class="citation" data-cites="KumarVaraiya1986">Kumar and Varaiya (<a href="../references.html#ref-KumarVaraiya1986" role="doc-biblioref">1986</a>)</span> define an information state as a compression of past history which satisfies property (P2a) but do not formally show that such an information state always leads to a dynamic programming decomposition.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Bohlin1970" class="csl-entry" role="listitem">
<span class="smallcaps">Bohlin, T.</span> 1970. Information pattern for linear discrete-time models with stochastic coefficients. <em>IEEE Transactions on Automatic Control (TAC)</em> <em>15</em>, 1, 104–106.
</div>
<div id="ref-Cassandra1997" class="csl-entry" role="listitem">
<span class="smallcaps">Cassandra, A., Littman, M.L., and Zhang, N.L.</span> 1997. Incremental pruning: A simple, fast, exact method for partially observable <span>M</span>arkov decision processes. <em><span>P</span>roceedings of the thirteenth conference on uncertainty in artificial intelligence</em>.
</div>
<div id="ref-Cassandra1994" class="csl-entry" role="listitem">
<span class="smallcaps">Cassandra, A.R., Kaelbling, L.P., and Littman, M.L.</span> 1994. Acting optimally in partially observable stochastic domains. <em>AAAI</em>, 1023–1028.
</div>
<div id="ref-Cheng1988" class="csl-entry" role="listitem">
<span class="smallcaps">Cheng, H.-T.</span> 1988. Algorithms for partially observable markov decision processes.
</div>
<div id="ref-DavisVaraiya1972" class="csl-entry" role="listitem">
<span class="smallcaps">Davis, M.H.A. and Varaiya, P.P.</span> 1972. Information states for linear stochastic systems. <em>Journal of Mathematical Analysis and Applications</em> <em>37</em>, 2, 384–402.
</div>
<div id="ref-KumarVaraiya1986" class="csl-entry" role="listitem">
<span class="smallcaps">Kumar, P.R. and Varaiya, P.</span> 1986. <em>Stochastic systems: Estimation identification and adaptive control</em>. Prentice Hall.
</div>
<div id="ref-Kwakernaak1965" class="csl-entry" role="listitem">
<span class="smallcaps">Kwakernaak, H.</span> 1965. Theory of self-adaptive control systems. In: Springer, 14–18.
</div>
<div id="ref-Nerode1958" class="csl-entry" role="listitem">
<span class="smallcaps">Nerode, A.</span> 1958. Linear automaton transformations. <em><span>P</span>roceedings of American Mathematical Society</em> <em>9</em>, 541–544.
</div>
<div id="ref-Smallwood1973" class="csl-entry" role="listitem">
<span class="smallcaps">Smallwood, R.D. and Sondik, E.J.</span> 1973. The optimal control of partially observable markov processes over a finite horizon. <em>Operations Research</em> <em>21</em>, 5, 1071–1088. DOI: <a href="https://doi.org/10.1287/opre.21.5.1071">10.1287/opre.21.5.1071</a>.
</div>
<div id="ref-Striebel1965" class="csl-entry" role="listitem">
<span class="smallcaps">Striebel, C.</span> 1965. Sufficient statistics in the optimal control of stochastic systems. <em>Journal of Mathematical Analysis and Applications</em> <em>12</em>, 576–592.
</div>
<div id="ref-Subramanian2022" class="csl-entry" role="listitem">
<span class="smallcaps">Subramanian, J., Sinha, A., Seraj, R., and Mahajan, A.</span> 2022. Approximate information state for approximate planning and reinforcement learning in partially observed systems. <em>Journal of Machine Learning Research</em> <em>23</em>, 12, 1–83. Available at: <a href="http://jmlr.org/papers/v23/20-1165.html">http://jmlr.org/papers/v23/20-1165.html</a>.
</div>
<div id="ref-Witsenhausen1975" class="csl-entry" role="listitem">
<span class="smallcaps">Witsenhausen, H.S.</span> 1975. On policy independence of conditional expectation. <em>Information and Control</em> <em>28</em>, 65–75.
</div>
<div id="ref-Witsenhausen1976" class="csl-entry" role="listitem">
<span class="smallcaps">Witsenhausen, H.S.</span> 1976. Some remarks on the concept of state. In: Y.C. Ho and S.K. Mitter, eds., <em>Directions in large-scale systems</em>. Plenum, 69–75.
</div>
<div id="ref-Zhang2009" class="csl-entry" role="listitem">
<span class="smallcaps">Zhang, H.</span> 2009. Partially observable <span>Markov</span> decision processes: A geometric technique and analysis. <em>Operations Research</em>.
</div>
<div id="ref-Zhang1996" class="csl-entry" role="listitem">
<span class="smallcaps">Zhang, N. and Liu, W.</span> 1996. <em>Planning in stochastic domains: Problem characteristics and approximation</em>. Hong Kong Univeristy of Science; Technology.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../mdps/lipschitz-mdps.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../pomdps/sequential-hypothesis.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>