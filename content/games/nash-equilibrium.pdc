---
title: "Theory: Nash Equilibrium"
weight: 21
categories:
  - games
tags:
  - Nash equilibrium
---

So far, we have looked at two solution concepts: (i) rationalizable
strategies, which don't exist for all games, and (ii) optimal or minimax
strategies for zero-sum games. Now, we look at the most popular solution
concept in games, known as **Nash Equilibrium**. 

::: highlight :::

Definition

: A **Nash equilibrium** (in pure strategies) of a strategic game $\mathscr{G}
= \langle \ALPHABET N, (\ALPHABET A_i)_{i \in \ALPHABET N}, (u_i)_{i \in
\ALPHABET N} \rangle$ is a strategy profile $a^* = (a^*_1, \dots, a^*_n) \in
\ALPHABET A$ such that for each player $i \in \ALPHABET N$, and each strategy
$a_i \in \ALPHABET A_i$, we have
$$ u_i(a_i^*, a_{-i}^*) \ge u_i(a_i, a_{-i}^*).$$

    The payoff vector $(u_1(a^*), \dots, u_n(a^*))$ is called the **equilibrium
    payoff** corresponding to the Nash equilibrium $a^*$. 

:::

A concise way of stating this definition is:

 
: A strategy profile is a Nash equilibrium if unilateral deviations by any
player does not improve performance. 

There is an equivalent way of defining Nash equilibrium. Recall that the
**best response correspondence** $B_i \colon \ALPHABET A_{-i}
\rightrightarrows \ALPHABET A_i$ is defined as 
$$
  B_i(a_{-i}) = \{ a_i \in \ALPHABET A_i : 
      u_i(a_i, a_{-i}) \ge u_i(a_i', a_{-i}), 
      \space \forall a'_i \in \ALPHABET A_i \}.
$$

::: highlight :::

Definition

: A strategy profile $a^* \in \ALPHABET A$ is a Nash equilibrium if $a^*_i \in
B_i(a_{-i}^*)$ for all players $i \in \ALPHABET N$.

:::

Or, more concisely,

 
: A strategy profile is a Nash equilibrium if each player is playing a best
response to the strategy profile of other players. 

# Relationship with previous solution concepts

## Dominant Strategies

::: highlight :::

Proposition #prop:dominant

: Any equilibrium in strongly or weakly dominant strategies is also a Nash
equilibrium. 

:::

As an illustration, consider the prisoner's dilemma game.

<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{A}$</td>
    <td colspan="2">$\mathsf{R}$</td>
  </tr>
  <tr>
    <td>$\mathsf{A}$</td>
    <td>$-2$</td>
    <td>$-2$</td>
    <td>$0$</td>
    <td>$-3$</td>
  </tr>
  <tr>
    <td>$\mathsf{R}$</td>
    <td>$-3$</td>
    <td>$0$</td>
    <td>$-1$</td>
    <td>$-1$</td>
  </tr>
</table>

Recall that $(\mathsf{A}, \mathsf{A})$ is an equilibrium in strongly dominant
strategy. It is easy to verify that it is also a Nash equilibrium.

<details>
<summary>
#### Proof {-}
</summary>
<div>
Suppose $a^* \in \ALPHABET A$ is an equilibrium in strongly or weakly dominant
strategy. Then, by definition, for all $i \in \ALPHABET N$, 
$$
  u_i(a_i^*, a_{-i}) \ge u_i(a_i, a_{-i}),
  \quad \forall a_i \in \ALPHABET A_i, 
  \forall a_{-i} \in \ALPHABET A_{-i}.
$$
For $a_{-i} = a_{-i}^*$, we have that for $i \in \ALPHABET N$, 
$$
  u_i(a_i^*, a_{-i}^*) \ge u_i(a_i, a_{-i}^*),
  \quad \forall a_i \in \ALPHABET A_i.
$$
Thus, $a^*$ is a Nash equilibrium. 
</div>
</details>

::: highlight :::

Proposition #prop:rationalizable

: Any rationalizable outcome of IEDS, IEWDS, or IENBRS is a Nash equilibrium.

:::

An an illustration, consider the game below:

<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{L}$</td>
    <td colspan="2">$\mathsf{M}$</td>
    <td colspan="2">$\mathsf{R}$</td>
  </tr>
  <tr>
    <td>$\mathsf{T}$</td>
    <td>$1$</td>
    <td>$0$</td>
    <td>$1$</td>
    <td>$2$</td>
    <td>$0$</td>
    <td>$1$</td>
  </tr>
  <tr>
    <td>$\mathsf{B}$</td>
    <td>$0$</td>
    <td>$3$</td>
    <td>$0$</td>
    <td>$1$</td>
    <td>$2$</td>
    <td>$0$</td>
  </tr>
</table>

As discussed in the [notes on strategic
games](../strategic-games#rationalizable-equilibrium),
$(\mathsf{T}, \mathsf{M})$ was a rationalizable strategy obtained by IEDS. It
is easy to verify that $(\mathsf{T}, \mathsf{M})$ is also a Nash equilibrium. 

<details>
<summary>
#### Proof {-}
</summary>
<div>
Note that at each step of IEDS or IENBRS, we are removing strategies that are
never best response. Therefore, IEDS or IENBRS cannot remove a Nash
equilibrium.

For IEWDS, we may remove some BRs, but anything which survives has to be a
best response pair. 
</div>
</details>

Thus, the concept of Nash equilibrium is equivalent to that of a
rationalizable strategy, whenever one exists. The main advantage of Nash
equilibrium is that it exists for games which do not have a rationalizable
strategy. 

For example, consider the two games which did not have a rationalizable
strategy:

* **Battle of sexes**:

    ```{=html}
    <table class="game" align="center">
      <tr>
        <td></td>
        <td colspan="2">$\mathsf{F}$</td>
        <td colspan="2">$\mathsf{O}$</td>
      </tr>
      <tr>
        <td>$\mathsf{F}$</td>
        <td>$2$</td>
        <td>$1$</td>
        <td>$0$</td>
        <td>$0$</td>
      </tr>
      <tr>
        <td>$\mathsf{O}$</td>
        <td>$0$</td>
        <td>$0$</td>
        <td>$1$</td>
        <td>$2$</td>
      </tr>
    </table>
    ```

    It can be verified that both $(\mathsf{F}, \mathsf{F})$ and $(\mathsf{O},
    \mathsf{O})$ are Nash equilibrium.

* **Chicken**:
    
    ```{=html}
    <table class="game" align="center">
      <tr>
        <td></td>
        <td colspan="2">$\mathsf{C}$</td>
        <td colspan="2">$\mathsf{H}$</td>
      </tr>
      <tr>
        <td>$\mathsf{C}$</td>
        <td>$3$</td>
        <td>$3$</td>
        <td>$1$</td>
        <td>$10$</td>
      </tr>
      <tr>
        <td>$\mathsf{H}$</td>
        <td>$10$</td>
        <td>$1$</td>
        <td>$0$</td>
        <td>$0$</td>
      </tr>
    </table>
    ```

    It can be verified that both $(\mathsf{C}, \mathsf{H})$ and $(\mathsf{H},
    \mathsf{C})$ are Nash equilibrium.

However, note that a game may not have an equilibrium in pure strategies. For
example, consider the game of matching pennies. 

<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{H}$</td>
    <td colspan="2">$\mathsf{T}$</td>
  </tr>
  <tr>
    <td>$\mathsf{H}$</td>
    <td>$1$</td>
    <td>$-1$</td>
    <td>$-1$</td>
    <td>$1$</td>
  </tr>
  <tr>
    <td>$\mathsf{T}$</td>
    <td>$-1$</td>
    <td>$1$</td>
    <td>$1$</td>
    <td>$-1$</td>
  </tr>
</table>

So, an important question is: _When does a game have a Nash equilibrium._ This
question was answered by @Nash1950, who showed that any finite game has a
solution in mixed strategies. We will come to that proof later. 

## Zero-sum games

Let's revisit the matching pennies example. Note that this is a two player
zero sum game and the optimal strategy of this game is $α^* = ( (\tfrac 12, \tfrac
12)), (\tfrac 12, \tfrac 12))$. We can verify that $α^*$ is also a Nash
equilibrium. In fact, we have the following general result. 

::: highlight :::

Proposition #prop:ZSG

: For two player zero-sum game, any optimal strategy is also a Nash
equilibrium and vice versa. 

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
Suppose $a^*$ is an optimal solution in pure strategies. Recall that a
strategy profile is an optimal strategy if and only if it is the saddle point
of the payoff function, i.e., 
\begin{align*}
  u(a_1^*, a_2^*) &\ge u(a_1, a_2^*), 
  \quad a_1 \in \ALPHABET A_1; \\
  u(a_1^*, a_2^*) &\le u(a_1^*, a_2), 
  \quad a_2 \in \ALPHABET A_2.
\end{align*}
Or, equivalently, 
\begin{align*}
  u_1(a_1^*, a_2^*) &\ge u_1(a_1, a_2^*), 
  \quad a_1 \in \ALPHABET A_1; \\
  u_2(a_1^*, a_2^*) &\ge u_2(a_1^*, a_2), 
  \quad a_2 \in \ALPHABET A_2.
\end{align*}
Thus, $(a_1^*, a_2^*)$ is also a Nash equilibrium. 

Note that each step aove is an if and only if statement. Thus, the reverse
implication is also true. 

The above result also extends to mixed strategies if we recall that an
optimal strategy in mixed strategies is just an optimal strategy in pure
strategies of the mixed extension of the game. 
</div>
</details>

# Computing Nash equilibrium 

## An illustration of the main idea

We now present a brute force method to compute the Nash equilibrium of a $2 ×
2$ game. Note that this method is just to illustrate the main ideas; we never
follow it in practice.


# Proof of the existence of Nash Equilibrium

We take a slightly round about approach to prove the existence of Nash
equilibrium in mixed strategies for finite games. The main tool for our proof
is **Kakutani's fixed point theorem.** 

::: highlight :::

Theorem #thm:Kakutani

: Let $\ALPHABET X$ be a compact and convex subset of $\reals^n$ and $f \colon
  \ALPHABET X \rightrightarrows \ALPHABET X$ be a set valued correspondence
  which satisfies:

      * For all $x \in \ALPHABET X$, the set $f(x)$ is non-empty and convex.
      * The graph of $f(x)$ is closed (which means that if we consider any two
        converging sequences $\{x_n\}_{n \ge 1}$ and $\{y_n\}_{n \ge 1}$ such
        that $y_n \in f(x_n)$ for all $n$. Then, $x_n \to x^*$ and $y_n \to
        y^*$ implies that $y^* \in f(x^*)$. 

      Then, $f$ has a fixed point $x^*$ such that $x^* \in f(x^*)$.

:::

Using Kakutani's fixed point theorem, we can provide a sufficient condition
for a game to have a Nash equilibrium. 

::: highlight :::

Theorem #thm:sufficient

: A strategic game $\mathscr{G} = \langle \ALPHABET N, (\ALPHABET A_i)_{i \in
\ALPHABET N}, (u_i)_{i \in \ALPHABET N} \rangle$ has a Nash equilibrium in
pure strategies if for all $i \in \ALPHABET N$:

    * $\ALPHABET A_i$ is a non-empty, compact, and convex subset of a
      Euclidean space.
    * The utility function $u_i \colon \ALPHABET A \to \reals$ is continuous
      on $\ALPHABET A$ and quasi-concave on $\ALPHABET A_i$.

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
Consider the set valued map $B \colon \ALPHABET A \rightrightarrows A$ defined
by 
$$
  B(a) = \begin{bmatrix}
    B_1(a_{-1|) \\ B_2(a_{-2} \\ \vdots \\ B_n(a_{-n}) \end{bmatrix}.
$$
Now, we verify that $B$ satisfies the conditions of Kakutani's fixed point
theorem.

* For all $i \in \ALPHABET N$ and $a_{-i} \in \ALPHABET A_{-i}$, 
  $B_i(a_{-i})$ is non-empty because $u_i$ is continuous and $\ALPHABET A_i$
  is compact. 

* $B_i(a_{-i})$ is convex because $u_i$ is quasi-concave in $\ALPHABET A_i$.

* $B(a)$ has a closed graph because each $B_i(a_{-i})$ is closed because $u_i$
  is continuous. 

Then, by Kakutani's fixed point theorem (@thm:Kakutani), $B(a)$ has a fixed
point $a^*$, i., $a^* \in B(a^*)$. By definition, such an $a^*$ is a Nash
equilibrium. 
</div>
</details>

The next result is due to @Nash1950

::: highlight :::

Theorem #thm:Nash

: Every finite strategic game has a Nash equilibrium in mixed strategies.

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
For any game $\mathscr{G}$, consider its mixed extension $\mathscr{G}^*$. If
$\mathscr{G}$ is finite, then

* $Δ(\ALPHABET A_i)$ is non-empty, compact, and convex subset of a Euclidean
  space. 

* $U_i$ is a continuous on $Δ(\ALPHABET A_1) × \cdots × Δ(\ALPHABET A_n)$ and
  linear (and therefore, quasi-concave) on $Δ(\ALPHABET A_i)$. 

Hence, by @thm:sufficient, the mixed extension $\mathscr{G}^*$ has a Nash
equilibrium in pure stratgies. Thus, the original game $\mathscr{G}$ has a
Nash equilibrium in mixed strategies. 
</div>
</details>

Remark

: The proof of @thm:Nash on the existence of a Nash equilibrium is
non-constructive. As was illustrated by the examples above, computing Nash
equilibrium when each player has more than two pure strategies is
computationally difficult. 

A generalization of the above result is due to @Glicksberg1952. We state it for
completeness but do not provide a proof here.

::: highlight :::

Theorem #thm:mixed

: A strategic game $\mathscr{G} = \langle \ALPHABET N, (\ALPHABET A_i)_{i \in
\ALPHABET N}, (u_i)_{i \in \ALPHABET N} \rangle$ has a mixed strategy Nash
equilibrium if for all $i \in \ALPHABET N$, 

    * $\ALPHABET A_i$ is non-empty, convex, and compact subset of a Euclidean
      space.

    * The utility function $u_i$ is continuous in $\ALPHABET A$. 

:::

Note that @thm:sufficient shows that if the utility function $u_i$ is also
quasi-concave in $\ALPHABET A_i$, then the game has a pure strategy Nash
equilibrium. 

# Interpretation of Nash equilibrium

## Nash equilibrium as randomization

Consider a  guessing game. There are two players with $\ALPHABET A_1 =
\ALPHABET A_2 = \{1,\dots,k\}$. The utility function of the players is
$$
  u(a_1,a_2) = \begin{cases}
    (1, -1), & \text{if $a_1 = a_2$} \\
    (0, 0),  & \text{otherwise}
  \end{cases}
$$
Let $p = (p_1,\dots,p_k)$ and $q = (q_1, \dots, q_k)$ be a mixed strategy
equilibrium. Consider an $\ell$ such that $p_\ell > 0$. Then, by the
indifference principle, for any $\ell' \neq \ell$, we have
\begin{equation}\label{eq:q}
U_1(\ell, q) \ge U_1(\ell', q) \iff q_\ell \ge q_{\ell'}. 
\end{equation}
Therefore, $q_\ell > 0$ (otherwise the elements won't add to $1$), and

Furthermore, since $q_\ell > 0$, by the indifference
principle, for any $\ell' \neq \ell$, we have
\begin{equation}\label{eq:p}
U_2(p, \ell) \ge U_2(p, \ell') \iff  -p_{\ell} \ge -p{\ell'}. 
\end{equation}
Therefore, for all $\ell' \neq \ell$, 
$$ p_{\ell'} \ge p_{\ell} > 0. $$
Thus, $p$ must have positive support on all options and, by the first
property, $q$ must have positive support on all options. 

Since $p$ has positive support on all options, \\eqref{eq:q} must hold for all
$\ell$. Thus, $q = (\tfrac 1k, \dots, \tfrac 1k)$.

By a symmetric argument, since $q$ has positive support on all options,
\\eqref{eq:p} must hold for all $\ell$. Thus, $p = (\tfrac 1k, \dots, \tfrac
1k)$. 

---

In this example, the Nash equilibrium can be interpreted as randomization. The
players are randomizing their actions to confuse each other. 

## Nash equilibrium as beliefs

Consider the mixed equilibrium in the battle of sexes game. Assume that the
players do not talk before the game and each player goes to Football or Opera
depending on their "mood". 

Then, the column player's strategy $α_2$ corresponds to the row player's
belief about the mood of the column player. $α_1$ has a similar
interpretation.

Thus, a mixed strategy equilibrium may be interpreted as follows: Player $i$
is playing a strategy $α_i$ such that each action with positive weight under
$α_i$ is the best response to player $i$'s belief $α_{-i}$ of how other
players are playing. 

Therefore, mixed strategy equilibrium is an equilibrium of beliefs. See
Sec. 3.2 of Osborne and Rubinstein for a more detailed discussion.

## Nash equilibrium as fraction of population playing a particular action

Consider the following game of taxation and auditing. Let's assume that there
are two types of tax payers: Honest $\mathsf{H}$ and cheaters $\mathsf{C}$.
The auditor looks at each filed return and has the option to audit
$\mathsf{A}$ or not audit $\mathsf{N}$ the return. The payoff matrix for this
setting is shown below:


<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{H}$</td>
    <td colspan="2">$\mathsf{C}$</td>
  </tr>
  <tr>
    <td>$\mathsf{A}$</td>
    <td>$2$</td>
    <td>$0$</td>
    <td>$3$</td>
    <td>$-10$</td>
  </tr>
  <tr>
    <td>$\mathsf{T}$</td>
    <td>$4$</td>
    <td>$0$</td>
    <td>$0$</td>
    <td>$4$</td>
  </tr>
</table>

It is easy to check that there is no Nash equilibrium in pure strategies. We
can find a Nash equilibrium in mixed strategies as follows. Let $α_1 =
(p,1-p)$ and $α_2 = (q, 1-q)$ be a Nash equilibrium. Then, by the indifference
principle, for player 2:
$$
  0 = -10 p + 4 (1-p) \implies p = \tfrac 27.
$$
Similarly, by the indifference principle for player 1:
$$
  2q + 4(1-q) = 4q \implies q = \tfrac 23.
$$
Thus,
$$
  α = \Bigl( \bigl(\tfrac 27, \tfrac 57), (\tfrac 23, \tfrac 13) \Bigr)
  \qquad
  v = \bigl(\tfrac 83,0\bigr).
$$

In this case, we can interpret player 2 (tax payer's) strategy as $\tfrac 23$
of the population is honest while $\tfrac 13$ of the population cheats. 

This also has interesting implications when it comes to policy design. Suppose
the tax department decides to increase the penalty for getting caught while
cheating to $-20$ (from the original $-10$). Then, the new payoff matrix is:


<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{H}$</td>
    <td colspan="2">$\mathsf{C}$</td>
  </tr>
  <tr>
    <td>$\mathsf{A}$</td>
    <td>$2$</td>
    <td>$0$</td>
    <td>$3$</td>
    <td>$-20$</td>
  </tr>
  <tr>
    <td>$\mathsf{T}$</td>
    <td>$4$</td>
    <td>$0$</td>
    <td>$0$</td>
    <td>$4$</td>
  </tr>
</table>

The new Nash equilibrium is  
$$
  α = \Bigl( \bigl(\tfrac 16, \tfrac 56), (\tfrac 23, \tfrac 13) \Bigr)
  \qquad
  v = \bigl(\tfrac 83,0\bigr).
$$
Note that changing the payoff for the column player has no affect on the mixed
strategy of the column player!

If we increase the benefit of not getting caught when cheating from say $4$ to
$8$, then $q$ will remain the same but $p$ will go up! This explains why rich
people are audited more (not because they are more likely to cheat!)

# Some applications

## Robotics

Consider two robots who are removing obstacles from a room. There are two
types of obstacles: small $\mathsf{S}$ and big $\mathsf{B}$. Removing a small
obstacle gives a reward of $r_s$ and removing a big obstacle gives a reward of
$r_b$, where $r_b > r_s$. If both robots work together on removing an
obstacle, the reward is halved. Find a symmetric Nash equilibrium of the game.

The bi-matrix representation of the game is as follows:

<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{B}$</td>
    <td colspan="2">$\mathsf{S}$</td>
  </tr>
  <tr>
    <td>$\mathsf{B}$</td>
    <td>$\tfrac {1}{2}r_b$</td>
    <td>$\tfrac {1}{2}r_b$</td>
    <td>$r_b$</td>
    <td>$r_s$</td>
  </tr>
  <tr>
    <td>$\mathsf{S}$</td>
    <td>$r_s$</td>
    <td>$r_b$</td>
    <td>$\tfrac {1}{2}r_s$</td>
    <td>$\tfrac {1}{2}r_s$</td>
  </tr>
</table>

We characterize the Nash equilibrium in terms of $r_b$ and $r_s$. 

Note that when $r_b/2 > r_s$, $(\mathsf{B}, \mathsf{B})$ is a dominant
strategy equilibrium (weakly dominant when $r_b/2 = r_s$). So, we assume that
$r_b/2 < r_s$. In this case, there is no pure strategy Nash equilibrium, so we
search for a mixed strategy Nash equilibrium. 

Since we are looking for a symmetric equilibrium, we assume that 
$$
  α_1 = α_2 = ( p, 1-p).
$$

From the indifference principle, we get that $α_1$ is a Nash equilibrium iff
$$
  p \cdot \frac{r_b}{2} + (1-p) r_b = p r_s + (1-p) \frac{r_s}{2}.
$$
Solving for $p$, we get that 
$$
  p = \frac{2r_b - r_s}{r_b + r_s}.
$$

Thus, the Nash equilibrium strategy is 
$$
  α_1 = α_2 = \left( \frac{2r_b - r_s}{r_b + r_s}, \frac{2r_s - r_b}{r_b +
  r_s} \right)
$$ 
which gives the payoff
$$
  \left( \frac{3r_b r_s}{2 (r_b + r_s)}, \frac{3r_b r_s}{2 (r_b + r_s)} \right).
$$

## Medium access control

Consider two wireless devices which are transmitting to the same destination.
Transmitting costs $c$ units and, if successful, provides a value of $v$
utils. However, if both units transmit at the same time, then there is a
collision and the transmission is not successful. Each transmitter has two
options: transmit $\mathsf{T}$ or don't transmit $\mathsf{D}$. What is the
Nash equilibrium in symmetric policies.

We model the above as the follows:

<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{T}$</td>
    <td colspan="2">$\mathsf{D}$</td>
  </tr>
  <tr>
    <td>$\mathsf{T}$</td>
    <td>$-c$</td>
    <td>$-c$</td>
    <td>$v-c$</td>
    <td>$0$</td>
  </tr>
  <tr>
    <td>$\mathsf{D}$</td>
    <td>$0$</td>
    <td>$v-c$</td>
    <td>$0$</td>
    <td>$0$</td>
  </tr>
</table>

By inspection, we know that $(\mathsf{T}, \mathsf{D})$ and $(\mathsf{D},
\mathsf{T})$ are pure strategy Nash equilibrium. But these are not symmetric.

Since we are looking for a symmetric equilibrium, we assume that 
$$
  α_1 = α_2 = (p, 1-p)
$$

From the indifference principle, we get that $α_1$ is Nash equilibrium iff
$$
  -p c + (v-c)(1-p) = 0.
$$

Solving for $p$ we get that
$$
  p = 1 - \frac{c}{v}.
$$
Thus, each user should transmit with probability $1 - c/v$. 

## Medium access control with lost opportunity cost

Suppose we modify the last example to include the lost opportunity cost with
the strategy $(\mathsf{D}, \mathsf{D})$ is played. 

<table class="game" align="center">
  <tr>
    <td></td>
    <td colspan="2">$\mathsf{T}$</td>
    <td colspan="2">$\mathsf{D}$</td>
  </tr>
  <tr>
    <td>$\mathsf{T}$</td>
    <td>$-c$</td>
    <td>$-c$</td>
    <td>$v-c$</td>
    <td>$0$</td>
  </tr>
  <tr>
    <td>$\mathsf{D}$</td>
    <td>$0$</td>
    <td>$v-c$</td>
    <td>$-d$</td>
    <td>$-d$</td>
  </tr>
</table>

In this case, the mixed strategy symmetric Nash equilibrium is $(p, 1-p)$
where
$$
  p = 1 - \frac{c}{v+d}.
$$
Thus, adding a penalty for lost opportunity cost is the same as increasing the
value of successful communication.

# References {-}
