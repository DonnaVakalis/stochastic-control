---
title: Poisson processes
weight: 1000
category: probability
tags: 
  - Bernoulli process
  - Poisson process
---

# Prelude: Bernoulli process

A Bernoulli process is a sequence $\{Z_n\}_{n \ge 1}$ of i.i.d. binary random
variables. Let $p = \PR(Z_n = 1)$ and $q = 1 - p = \PR(Z_n = 0)$. 

An example would be i.i.d. coin tosses where we can think of $\{Z_n = 1\}$ as
the event that the $h$-th outcome is a head and $\{Z_n = 0\}$ to be the event
that the $n$-th outcome is a tail.

Given a Bernoulli process, define $X_1$ to be the first time $n$ such that
$Z_n = 1$; $X_2$ to be the first time $n$ after $X_1$ such that $Z_n = 1$,
etc. The sequence $\{X_n\}_{n \ge 1}$ is called _inter-arrival times_. It is
easy to see that
$$
  P_{X_1}(k) = (1 - p)^{k-1} p.
$$
Due to the independence of the outcomes, we can also argue that 
$$
  P_{X_2}(k) = (1-p)^{k-1} p,
$$
and so on for all $X_n$. Thus, $X_n \sim \text{Geo}(p)$. 

Now consider the partial sums 
$$
  N(n) = \sum_{i=1}^n Z_i
$$
which denote the number of arrivals up to and including time $n$. From
elementary probability, we know that $N(n) \sim \text{Binomial}(n,p)$. 


An alternative way to view the Bernoulli process is as follows. Define
$$
  S_n = \sum_{i=1}^n X_i
$$
to be the time of the $n$-th arrival. Note that the process $\{S_n\}_{n \ge
1}$ is a sequence of increasing random variables. Such a sequence is called an
_arrival process_. Given an arrival process, we can construct inter-arrival
times as $X_n = S_n - S_{n-1}$. Then, the Bernoulli process is an arrival
process with geometric (or, equivalently, memoryless) interarrival times.

Note that the arrival times $\{S_n\}_{n \ge 1}$ take integer values. If we
allow the arrival times to take continuous values, we get a Poisson process.

# Poisson Processes

A Poisson process is an arrival process $\{S_n\}_{n \ge 1}$ (i.e., an
increasing sequence of random variables) such that the inter-arrival times
$\{X_n\}_{n \ge 1}$, where $X_n = S_n - S_{n-1}$, are independent and
memoryless. Since a non-negative continuous time random variable which is
memoryless must have an exponential distribution (see @ex:poisson below), we
can equivalently say that a Poisson process is an arrival process where the
inter-arrival times are independent and have an exponential distribution.

Exercise #ex:poisson 

:   Let $X$ be a non-negative and continous random variable which is
    memoryless, i.e., for any $t, τ > 0$, 
    $$
        \PR(X > t + τ \mid X > τ) = \PR(X > t).
    $$
    Then, $X$ has an exponential distribution.


<details><!--{{{ Solution -->
<summary>
#### Solution {-}
</summary>
<div>
  The definition of memoryless random variable implies that
  $$    
      \PR(X > t + τ) = \PR(X > t) \PR(X > τ).
  $$
  Let $\bar F_X(t)$ denote the complementary CDF of $X$, i.e., $\bar F_X(t) = 1
  - F_X(t)$. Then, the above equation says that
  $$
    \bar F_X(t + τ) = \bar F_X(t) \bar F_X(τ).
  $$
  Taking logs of both sides, we have
  $$ 
    \log (\bar F_X(t + τ)) = \log(\bar F_X(t)) + \log(\bar F_X(τ)).
  $$
  Thus, $\log(\bar F_X(t))$ is linear function of $t$, say $-λt$ (we use $-λ$
  instead of $λ$ because we know that $\log(\bar F_X(t)) < 0$). Thus,
  $$
    \bar F_X(t) = e^{-λt}
    \quad\text{or}\quad
    F_X(t) = 1 - e^{-λt}.
  $$
  Thus, $X$ is an exponential random variable. 
</div>
</details><!--}}}-->

Thus, we say that a Poisson process $\{S_n\}_{n \ge 1}$ has a _rate_ $λ$ to
mean that the inter-arrival times $\{X_n\}_{n \ge 1}$ have
$\text{Exponential}(λ)$ distribution.

As for the Bernoulli process, we define the counting process $N(t)$ as the
total number of arrivals until time $t$, i.e., the event $\{N(t) \ge n \}$ is
the same as the event $\{S_n \le t\}$. It can be shown that $N(t)$ is has a
$\text{Poisson}(λt)$ distribution, i.e.,
$$
    P_{N(t)}(n) = \frac{ (λt)^n \exp(-λ t)}{n!}.
$$

# Adding and splitting of Poisson processes

Suppose we have two poisson processes, process 1 with rate $λ_1$ and process 2
with rate $λ_2$. Consider a new process formed by adding the two processes.
This means that the new process has an arrival whenever either of process 1 or
process 2 has an arrival, i.e., $N(t) = N_1(t) + N_2(t)$. Then, the combined
process is Poisson with rate $λ_1 + λ_2$.

To prove this property recall that $N_1(t)$ and
$N_2(t)$ are Poisson and the sum of two Poisson random variables is Poisson.
Therefore, $N(t)$ is also Poisson. 

Now, consider a Poisson process. Suppose, we split the arrival into $k$
streams as follows. When an arrival comes, it goes into streams $i$ with
probability $p_i$. Then, each of the streams are also Poisson, with stream $i$
being Poisson with rate $p_i λ$. 

We provide a proof of this when $k=2$, and each arrival is split into stream 1
with probability $p$ and stream 2 with probability $1-p$. Let $N(t)$ denote
the number of arrivals in the original process and $N_1(t)$ and $N_2(t)$
denote the number of arrivals in output processes 1 and 2. 

Suppose $N(t) = m + k$ and during the splitting processes $m$ arrivals are
sent to steam 1 and $k$ are sent to stream 2. From a basic counting argument,
we should have
$$
  \PR(N_1(t) = m, N_2(t) = k \mid N(t) = m + k) 
  = 
  \frac{(m+k)!}{m!k!} p^m (1-p)^k.
$$
Thus,
\begin{align*}
  \PR(N_1(t) = m, N_2(t) = k) 
  &=
  \PR(N_1(t) = m, N_2(t) = k \mid N(t) = m + k) 
  \PR(N(t) = m + k)
  \\
  &= 
  \frac{(m+k)!}{m!k!} p^m (1-p)^k
  \frac{(λt)^{m+k} e^{-λt}}{(m+k)!}
  \\
  &=
  \frac{(pλt)^m}{m!} e^{-λpt} \,
  \frac{((1-p)λt)^m}{m!} e^{-λ(1-p)t}.
\end{align*}
Separately marginalizing over $N_1(t)$ and $N_2(t)$, we get that
$$
  \PR(N_1(t) = m) 
  =
  \frac{(pλt)^m}{m!} e^{-λpt} 
  \quad\text{and}\quad
  \PR(N_2(t) = k)
  = 
  \frac{((1-p)λt)^m}{m!} e^{-λ(1-p)t}
$$
Thus, $N_1(t)$ has $\text{Poisson}(λp)$ distribution and $N_2(t)$ has
$\text{Poisson}(λ(1-p))$ distribition. Moreover, 
$$
  \PR(N_1(t) = m, N_2(t) = k) = \PR(N_1(t) = m) \PR(N_2(t) = k),
$$
so the two processes are independent. 

# Exercises {-}

1. Suppose requests arrive at a web-server at rate $λ = 10$ per minute. 

   (a) What is the expected time at which the 100-th request arrives?

   (b) What is the probability that the time elapsed between the 100-th and
   the 101-st request exceeds 1 minute?

   (c) If each request is from Canada with probability $\tfrac 15$, what is
   the probability that there is no request from Canada in the next two
   minutes?

   <details><!--{{{ Solution -->
   <summary>
   #### Solution {-}
   </summary>
   <div>
   (a) The expected time for the 100-th request is given by 
   \begin{align*}
   \EXP[X_1 + \cdots + X_{100}] 
   &= \EXP[X_1] + \cdots + \EXP[X_{100}]
   \\
   &= \frac{100}{λ} = 10~\text{minutes}.
   \end{align*}

   (b) We know that $X_{101}$ has a $\text{Goemetric}(λ)$ distribution.
   Therefore,
   $$
     \PR(X_{101} > 1) = e^{-λ} = e^{-10} \approx 4.54 × 10^{-5}.
   $$

   (c) Let $N_c(t)$ denote the number of arrivals from Canada. We know that $N_c$
   is a Poisson process with rate $λ/5 = 2$ per minute. Therefore,
   $$  
     \PR(N(2) = 0) = e^{2 \cdot 2} \approx 0.0183.
   $$
   </div>
   </details><!--}}}-->

2. Suppose there is only one arrival in a Poisson process in the interval
   $[0,t]$. Conditioned on this event, what is the conditional distribution of
   $X_1$ (the time of the first arrival)?

   <details><!--{{{ Solution -->
   <summary>
   #### Solution {-}
   </summary>
   <div>
   We will compute the CDF of $X_1$. We know that $X_1 \le t$. So, for any
   $τ < t$, consider $\PR(X_1 < τ \mid N(t) = 1)$. We have
   \begin{align*}
     \PR(X_1 < τ \mid N(t) = 1) &= 
     \frac{\PR(X_1 < τ, N(t) = 1)}{\PR(N(t) = 1)}
     \\
     &=
     \frac{ \PR(N(s) = 1, N(t) - N(s) = 0) }{ \PR(N(t) = 1) }
     \\
     &\stackrel{(a)}=
     \frac{ \PR(N(s) = 1)\PR(N(t) - N(s) = 0) }{ \PR(N(t) = 1) }
     \\
     &= \frac{ (λs) e^{-λs}}{1!} \cdot e^{λ(t-s)} \cdot \frac{1}{(λt)e^{-λt}}
     \\
     &= \frac{s}{t},
   \end{align*}
   where $(a)$ uses the fact that a Poisson process has independent increments.
   Thus, the conditional density of $X_1$ given $N(t)$ is given by
   $$
     f_{X_1 | N(t)}(s|1) = \frac{1}{t}, \quad 0 \le s \le t.
   $$
   Thus, $X_1$ given $N(t) = 1$ is uniform in $[0,t]$.
   </div>
   </details><!--}}}-->


3. Consider two independent poisson processes with rates $λ_1$ and $λ_2$. What
   is the probability of having an arrival from process 1 before an arrival
   from process 2?

   <details><!--{{{ Solution -->
   <summary>
   #### Solution {-}
   </summary>
   <div>
   The probability that there is an arrival from process 1 before an arrival from
   process 2 is given by $\PR(X_1 < X_2)$. We have
   \begin{align*}
   \PR(X_1 < X_2) &= \int_{0}^∞ \PR(X_1 < X_2 \mid X_2 = t) f_{X_2}(t) dt 
   \\
   &= \int_{0}^∞ \PR(X_1 < t \mid X_2 = t) f_{X_2}(t) dt 
   \\
   &\stackrel{(a)}= \int_{0}^∞ \PR(X_1 < t) f_{X_2}(t) dt
   \\
   &= \int_0^∞ (1 - e^{-λ_1t}) λ_2 e^{-λ_2 t} dt
   \\
   &= λ_2 \biggl[ \frac{e^{-λ_2 t}}{λ_2} - \frac{e^{-(λ_1 + λ_2) t} }{λ_1 + λ_2}
   \biggr] \biggr|_{0}^∞
   \\
   &= \frac{λ_1}{λ_1 + λ_2},
   \end{align*}
   where $(a)$ follows from the fact that the two processes are independent.
   </div>
   </details><!--}}}-->

4. Consider the following network where the inputs are indepedent Poisson
   processes. Show that the outputs are also Poisson processes and find their
   rates.


   <figure style='max-width:20em;' id="fig1">
   <img src="splitting.png" />
   </figure>


   <details><!--{{{ Solution -->
   <summary>
   #### Solution {-}
   </summary>
   <div>
   We know that splitting a Poisson process gives independent Poisson
   processes and adding independent Poisson processes gives a Poisson process.
   Therefore, the output processes are Poisson. We can find their rates as
   follows:
   \begin{align*}
      μ_1 &= 0.25 λ_1 + 0.75 λ_2, \\
      μ_2 &= 0.75 λ_1 + 0.25 λ_2.
   \end{align*}
   </div>
   </details><!--}}}-->

5. Consider the following network where the input is a Poisson process. 
   Find the rate of the output process.

   <figure style='max-width:20em;' id="fig2">
   <img src="feedback.png" />
   </figure>


   <details><!--{{{ Solution -->
   <summary>
   #### Solution {-}
   </summary>
   <div>
   Let $\tilde λ$ denote the rate of the process between the two nodes. Then,
   \begin{align*}
      \tilde λ &= λ + 0.25 \tilde λ, \\
      μ &= 0.75 \tilde λ.
   \end{align*}
   Thus, $\tilde λ = λ/0.75$. Hence, $μ = 0.75 \tilde λ = λ$. 

   This makes sense since all the input arrival must depart the system, so the
   output rate has to be the same as the input rate. 
   </div>
   </details><!--}}}-->
